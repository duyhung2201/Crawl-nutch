2020-05-02 11:36:22,516 INFO  crawl.Injector - Injector: starting at 2020-05-02 11:36:22
2020-05-02 11:36:22,518 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 11:36:22,521 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 11:36:22,521 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 11:36:22,720 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:36:23,400 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 11:36:24,884 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:24,888 INFO  mapreduce.Job - Running job: job_local2028664375_0001
2020-05-02 11:36:25,815 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 11:36:25,899 INFO  mapreduce.Job - Job job_local2028664375_0001 running in uber mode : false
2020-05-02 11:36:25,901 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:36:25,998 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 11:36:25,998 INFO  crawl.Injector - Injector: update: false
2020-05-02 11:36:26,903 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:36:26,904 INFO  mapreduce.Job - Job job_local2028664375_0001 completed successfully
2020-05-02 11:36:26,931 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2971837
		FILE: Number of bytes written=4665997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=187
		Map output records=187
		Map output bytes=36004
		Map output materialized bytes=36502
		Input split bytes=592
		Combine input records=0
		Combine output records=0
		Reduce input groups=187
		Reduce shuffle bytes=36502
		Reduce input records=187
		Reduce output records=187
		Spilled Records=374
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=913833984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=38530
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 11:36:27,052 INFO  crawl.Injector - Injector: finished at 2020-05-02 11:36:26, elapsed: 00:00:04
2020-05-02 11:36:28,294 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:36:29,395 INFO  crawl.Generator - Generator: starting at 2020-05-02 11:36:29
2020-05-02 11:36:29,395 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 11:36:29,396 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 11:36:29,396 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 11:36:29,399 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 11:36:30,417 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:30,418 INFO  mapreduce.Job - Running job: job_local1320640094_0001
2020-05-02 11:36:30,976 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:36:30,976 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:36:30,976 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:36:30,991 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 11:36:31,202 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 11:36:31,276 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 11:36:31,426 INFO  mapreduce.Job - Job job_local1320640094_0001 running in uber mode : false
2020-05-02 11:36:31,427 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:36:31,428 INFO  mapreduce.Job - Job job_local1320640094_0001 completed successfully
2020-05-02 11:36:31,449 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2905431
		FILE: Number of bytes written=4513173
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=187
		Map output records=76
		Map output bytes=10182
		Map output materialized bytes=2193
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=2193
		Reduce input records=76
		Reduce output records=0
		Spilled Records=152
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=739770368
	Generator
		SCHEDULE_REJECTED=111
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=38234
	File Output Format Counters 
		Bytes Written=16
2020-05-02 11:36:31,449 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 11:36:31,454 INFO  crawl.Generator - Generator:    111  SCHEDULE_REJECTED
2020-05-02 11:36:31,456 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 11:36:32,458 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502113632
2020-05-02 11:36:32,725 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:32,726 INFO  mapreduce.Job - Running job: job_local1387946928_0002
2020-05-02 11:36:33,730 INFO  mapreduce.Job - Job job_local1387946928_0002 running in uber mode : false
2020-05-02 11:36:33,731 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:36:33,731 INFO  mapreduce.Job - Job job_local1387946928_0002 completed successfully
2020-05-02 11:36:33,735 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5737760
		FILE: Number of bytes written=9046090
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=76
		Map output records=76
		Map output bytes=15652
		Map output materialized bytes=2454
		Input split bytes=366
		Combine input records=0
		Combine output records=0
		Reduce input groups=76
		Reduce shuffle bytes=2454
		Reduce input records=76
		Reduce output records=76
		Spilled Records=152
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1340080128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11214
	File Output Format Counters 
		Bytes Written=10440
2020-05-02 11:36:33,831 INFO  crawl.Generator - Generator: finished at 2020-05-02 11:36:33, elapsed: 00:00:04
2020-05-02 11:36:34,832 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 11:36:34
2020-05-02 11:36:34,832 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502113632
2020-05-02 11:36:34,833 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588404994833  (2020-05-02 14:36:34)
2020-05-02 11:36:35,118 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:36:36,287 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:36,288 INFO  mapreduce.Job - Running job: job_local1816575884_0001
2020-05-02 11:36:36,478 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 11:36:36,478 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 11:36:36,479 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 11:36:36,502 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 76 records hit by time limit : 0
2020-05-02 11:36:36,781 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:36,808 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:36,809 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.raywenderlich.com/8241072-ios-tutorial-collection-view-and-diffable-data-source (queue crawl delay=1ms)
2020-05-02 11:36:36,810 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,052 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 11:36:37,053 INFO  http.Http - http.proxy.host = null
2020-05-02 11:36:37,053 INFO  http.Http - http.proxy.port = 8080
2020-05-02 11:36:37,053 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 11:36:37,053 INFO  http.Http - http.timeout = 30000
2020-05-02 11:36:37,053 INFO  http.Http - http.content.limit = -1
2020-05-02 11:36:37,053 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 11:36:37,053 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 11:36:37,053 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 11:36:37,054 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 11:36:37,055 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,055 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 11:36:37,056 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,056 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,057 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,057 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,058 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,058 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,059 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,060 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,060 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,061 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,062 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,063 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,069 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,069 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,070 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,071 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,072 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,074 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,076 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,077 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,080 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,081 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,081 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,082 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,082 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,084 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,084 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,085 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,086 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,086 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,088 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,091 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,092 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,092 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,093 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,094 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,095 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,104 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,106 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,106 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,111 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,117 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,118 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,119 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,122 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,123 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,124 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,124 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,125 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,130 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,135 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,135 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,136 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,139 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,140 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,140 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,141 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,142 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,142 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,143 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,144 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,144 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,149 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,150 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,150 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,151 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,152 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,153 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,158 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,260 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,261 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,262 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,262 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,263 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,263 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,264 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,271 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,272 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,272 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,273 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,273 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,274 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,274 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,275 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,275 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,277 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,280 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,280 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,281 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,282 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,283 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,283 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,284 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,284 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,285 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 11:36:37,285 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 11:36:37,285 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 11:36:37,299 INFO  mapreduce.Job - Job job_local1816575884_0001 running in uber mode : false
2020-05-02 11:36:37,301 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 11:36:38,288 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=74, fetchQueues.getQueueCount=2
2020-05-02 11:36:38,847 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 11:36:39,292 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=73, fetchQueues.getQueueCount=2
2020-05-02 11:36:40,292 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=73, fetchQueues.getQueueCount=1
2020-05-02 11:36:41,293 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=73, fetchQueues.getQueueCount=1
2020-05-02 11:36:42,296 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=73, fetchQueues.getQueueCount=1
2020-05-02 11:36:42,365 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.raywenderlich.com/176876/rwdevcon-2018-schedule-now-available (queue crawl delay=1ms)
2020-05-02 11:36:43,297 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=72, fetchQueues.getQueueCount=1
2020-05-02 11:36:43,969 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:43,970 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.raywenderlich.com/147687/introduction-unity-getting-started-part-12 (queue crawl delay=1ms)
2020-05-02 11:36:44,302 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=71, fetchQueues.getQueueCount=1
2020-05-02 11:36:45,306 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=71, fetchQueues.getQueueCount=1
2020-05-02 11:36:45,825 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/151018/unreal-engine-4-tutorial-beginners (queue crawl delay=1ms)
2020-05-02 11:36:46,306 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=70, fetchQueues.getQueueCount=1
2020-05-02 11:36:47,311 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=70, fetchQueues.getQueueCount=1
2020-05-02 11:36:47,503 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:47,503 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/66062/procedural-level-generation-games-using-cellular-automaton-part-1 (queue crawl delay=1ms)
2020-05-02 11:36:48,314 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=69, fetchQueues.getQueueCount=1
2020-05-02 11:36:48,979 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/185264/rwdevcon-2018-student-scholarships-apply-now (queue crawl delay=1ms)
2020-05-02 11:36:49,317 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=68, fetchQueues.getQueueCount=1
2020-05-02 11:36:49,337 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-02 11:36:50,321 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=68, fetchQueues.getQueueCount=1
2020-05-02 11:36:50,619 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/173813/unreal-engine-4-audio-tutorial (queue crawl delay=1ms)
2020-05-02 11:36:51,325 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=67, fetchQueues.getQueueCount=1
2020-05-02 11:36:52,330 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=67, fetchQueues.getQueueCount=1
2020-05-02 11:36:52,360 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/138939/getting-started-mobile-analytics (queue crawl delay=1ms)
2020-05-02 11:36:53,334 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=66, fetchQueues.getQueueCount=1
2020-05-02 11:36:54,115 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/146804/dependency-injection-dagger-2 (queue crawl delay=1ms)
2020-05-02 11:36:54,334 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=65, fetchQueues.getQueueCount=1
2020-05-02 11:36:55,337 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=65, fetchQueues.getQueueCount=1
2020-05-02 11:36:55,841 INFO  fetcher.FetcherThread - FetcherThread 77 fetching https://www.raywenderlich.com/161314/spritekit-animations-texture-atlases-swift (queue crawl delay=1ms)
2020-05-02 11:36:56,338 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=64, fetchQueues.getQueueCount=1
2020-05-02 11:36:57,340 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=64, fetchQueues.getQueueCount=1
2020-05-02 11:36:57,489 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:57,649 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.raywenderlich.com/167015/learning-techniques-programmers (queue crawl delay=1ms)
2020-05-02 11:36:58,341 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=63, fetchQueues.getQueueCount=1
2020-05-02 11:36:59,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:59,223 INFO  fetcher.FetcherThread - FetcherThread 69 fetching https://www.raywenderlich.com/82022/make-game-like-cut-rope-using-spritekit-swift (queue crawl delay=1ms)
2020-05-02 11:36:59,341 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=62, fetchQueues.getQueueCount=1
2020-05-02 11:37:00,342 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=62, fetchQueues.getQueueCount=1
2020-05-02 11:37:00,856 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:37:00,862 INFO  fetcher.FetcherThread - FetcherThread 75 fetching https://www.raywenderlich.com/168916/android-an-introduction-to-material-design (queue crawl delay=1ms)
2020-05-02 11:37:01,346 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=61, fetchQueues.getQueueCount=1
2020-05-02 11:37:02,347 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=61, fetchQueues.getQueueCount=1
2020-05-02 11:37:02,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:37:02,597 INFO  fetcher.FetcherThread - FetcherThread 75 fetching https://www.raywenderlich.com/135380/using-framer-prototype-ios-animations (queue crawl delay=1ms)
2020-05-02 11:37:03,348 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=60, fetchQueues.getQueueCount=1
2020-05-02 11:37:04,257 INFO  fetcher.FetcherThread - FetcherThread 74 fetching https://www.raywenderlich.com/167227/unreal-engine-4-ui-tutorial (queue crawl delay=1ms)
2020-05-02 11:37:04,351 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=59, fetchQueues.getQueueCount=1
2020-05-02 11:37:05,352 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=59, fetchQueues.getQueueCount=1
2020-05-02 11:37:05,773 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:37:05,773 INFO  fetcher.FetcherThread - FetcherThread 74 fetching https://www.raywenderlich.com/175401/custom-downloadable-fonts-android (queue crawl delay=1ms)
2020-05-02 11:37:06,355 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=58, fetchQueues.getQueueCount=1
2020-05-02 11:37:27,632 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:37:28,014 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 11:37:28
2020-05-02 11:37:28,015 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502113632
2020-05-02 11:37:28,377 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113632/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:261)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:308)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:280)

2020-05-02 11:37:49,031 INFO  crawl.Injector - Injector: starting at 2020-05-02 11:37:49
2020-05-02 11:37:49,035 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 11:37:49,035 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 11:37:49,035 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 11:37:49,241 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:37:49,674 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 11:37:50,760 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:37:50,761 INFO  mapreduce.Job - Running job: job_local1996525723_0001
2020-05-02 11:37:51,302 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 11:37:51,502 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 11:37:51,502 INFO  crawl.Injector - Injector: update: false
2020-05-02 11:37:51,772 INFO  mapreduce.Job - Job job_local1996525723_0001 running in uber mode : false
2020-05-02 11:37:51,774 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:37:51,775 INFO  mapreduce.Job - Job job_local1996525723_0001 completed successfully
2020-05-02 11:37:51,787 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855256
		FILE: Number of bytes written=2987973
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=136
		Map output materialized bytes=146
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=146
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=493
2020-05-02 11:37:51,798 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 11:37:51,799 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 11:37:51,799 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 11:37:51,799 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 11:37:51,817 INFO  crawl.Injector - Injector: finished at 2020-05-02 11:37:51, elapsed: 00:00:02
2020-05-02 11:37:52,862 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: starting at 2020-05-02 11:37:53
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 11:37:53,294 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 11:37:54,410 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:37:54,413 INFO  mapreduce.Job - Running job: job_local1311664073_0001
2020-05-02 11:37:54,965 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:37:54,966 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:37:54,966 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:37:54,974 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 11:37:55,181 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 11:37:55,421 INFO  mapreduce.Job - Job job_local1311664073_0001 running in uber mode : false
2020-05-02 11:37:55,422 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:37:55,423 INFO  mapreduce.Job - Job job_local1311664073_0001 completed successfully
2020-05-02 11:37:55,437 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783168
		FILE: Number of bytes written=4493978
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=194
		Map output materialized bytes=116
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=116
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=250
	File Output Format Counters 
		Bytes Written=16
2020-05-02 11:37:55,438 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 11:37:55,443 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 11:37:56,444 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502113756
2020-05-02 11:37:56,703 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:37:56,703 INFO  mapreduce.Job - Running job: job_local1334452178_0002
2020-05-02 11:37:57,708 INFO  mapreduce.Job - Job job_local1334452178_0002 running in uber mode : false
2020-05-02 11:37:57,709 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:37:57,710 INFO  mapreduce.Job - Job job_local1334452178_0002 completed successfully
2020-05-02 11:37:57,714 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3711250
		FILE: Number of bytes written=5987424
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=264
		Map output materialized bytes=106
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=106
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=330
	File Output Format Counters 
		Bytes Written=292
2020-05-02 11:37:57,734 INFO  crawl.Generator - Generator: finished at 2020-05-02 11:37:57, elapsed: 00:00:04
2020-05-02 11:37:58,746 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 11:37:58
2020-05-02 11:37:58,746 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502113756
2020-05-02 11:37:58,747 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588405078747  (2020-05-02 14:37:58)
2020-05-02 11:37:59,024 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:00,109 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:00,110 INFO  mapreduce.Job - Running job: job_local633290412_0001
2020-05-02 11:38:00,308 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 11:38:00,308 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 11:38:00,309 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 11:38:00,318 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records hit by time limit : 0
2020-05-02 11:38:00,604 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,630 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,631 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,631 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 11:38:00,842 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 11:38:00,844 INFO  http.Http - http.proxy.host = null
2020-05-02 11:38:00,844 INFO  http.Http - http.proxy.port = 8080
2020-05-02 11:38:00,844 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 11:38:00,844 INFO  http.Http - http.timeout = 30000
2020-05-02 11:38:00,844 INFO  http.Http - http.content.limit = -1
2020-05-02 11:38:00,844 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 11:38:00,844 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 11:38:00,844 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 11:38:00,844 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 11:38:00,849 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,850 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,850 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,851 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,851 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,852 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,853 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,853 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,854 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,855 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,856 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,873 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,876 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,926 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,927 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,928 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,928 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,929 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,930 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,931 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,932 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,064 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,065 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,066 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,067 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,068 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,069 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,069 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,070 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,071 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,071 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,072 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,073 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,073 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,074 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,075 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,075 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,076 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,077 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,077 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,079 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,080 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,091 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,092 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,093 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,094 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,096 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,097 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,098 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,099 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,099 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,100 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,100 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,101 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,101 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,102 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,103 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,103 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,104 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,104 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,105 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,107 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,108 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,111 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,111 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,112 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,114 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,115 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,115 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,116 INFO  mapreduce.Job - Job job_local633290412_0001 running in uber mode : false
2020-05-02 11:38:01,117 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,118 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 11:38:01,118 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,120 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,120 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,121 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,122 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,122 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,123 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,124 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,125 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,126 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,127 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,127 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,128 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,129 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,130 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,131 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,131 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,143 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,144 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,147 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,148 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,151 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,153 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,154 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,156 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,157 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,158 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,159 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 11:38:01,160 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 11:38:01,160 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 11:38:01,801 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=47
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 11:38:01,858 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=46
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=48
2020-05-02 11:38:01,858 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=45
2020-05-02 11:38:01,868 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 11:38:01,868 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 11:38:01,932 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 11:38:01,933 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=43
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=42
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=41
2020-05-02 11:38:01,935 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 11:38:01,935 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=40
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=39
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=38
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=37
2020-05-02 11:38:02,074 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=35
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=36
2020-05-02 11:38:02,074 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=34
2020-05-02 11:38:02,074 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 11:38:02,076 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=33
2020-05-02 11:38:02,084 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=32
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=31
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=30
2020-05-02 11:38:02,091 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 11:38:02,091 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=29
2020-05-02 11:38:02,098 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 11:38:02,098 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=28
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=27
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=26
2020-05-02 11:38:02,105 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 11:38:02,105 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=25
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=23
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=22
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=21
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=20
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=19
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 11:38:02,116 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=18
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 11:38:02,118 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=17
2020-05-02 11:38:02,124 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 11:38:02,124 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=16
2020-05-02 11:38:02,124 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 11:38:02,125 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=15
2020-05-02 11:38:02,130 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 11:38:02,130 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=14
2020-05-02 11:38:02,135 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 11:38:02,135 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=13
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=12
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=11
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=10
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=9
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 11:38:02,142 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=8
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=5
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=4
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=3
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 11:38:02,168 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=2
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=6
2020-05-02 11:38:02,168 INFO  fetcher.Fetcher - -activeThreads=3, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 11:38:02,150 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 11:38:02,172 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=1
2020-05-02 11:38:02,150 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 11:38:02,172 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=0
2020-05-02 11:38:02,146 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=7
2020-05-02 11:38:03,176 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 11:38:03,176 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 11:38:04,131 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:04,131 INFO  mapreduce.Job - Job job_local633290412_0001 completed successfully
2020-05-02 11:38:04,152 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2869167
		FILE: Number of bytes written=4667897
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=235541
		Map output materialized bytes=39059
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=39059
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=135
		Total committed heap usage (bytes)=976748544
	FetcherStatus
		bytes_downloaded=233595
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=292
	File Output Format Counters 
		Bytes Written=41236
2020-05-02 11:38:04,152 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 11:38:04, elapsed: 00:00:05
2020-05-02 11:38:05,342 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:05,690 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 11:38:05
2020-05-02 11:38:05,691 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502113756
2020-05-02 11:38:06,660 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:06,661 INFO  mapreduce.Job - Running job: job_local830552255_0001
2020-05-02 11:38:07,669 INFO  mapreduce.Job - Job job_local830552255_0001 running in uber mode : false
2020-05-02 11:38:07,670 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 11:38:07,828 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 11:38:08,094 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 11:38:08,098 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 11:38:08,110 INFO  parse.ParseSegment - Parsed (928ms):https://www.apple.com/iphone-11/specs/
2020-05-02 11:38:08,195 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 11:38:08,196 INFO  parse.ParseSegment - Parsed (80ms):https://www.apple.com/iphone-se/specs/
2020-05-02 11:38:08,409 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:08,533 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:08,606 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 11:38:08,673 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 11:38:09,678 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:09,679 INFO  mapreduce.Job - Job job_local830552255_0001 completed successfully
2020-05-02 11:38:09,694 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3921778
		FILE: Number of bytes written=6108630
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=21709
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=21709
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=70
		Total committed heap usage (bytes)=1597505536
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39776
	File Output Format Counters 
		Bytes Written=0
2020-05-02 11:38:09,706 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 11:38:09, elapsed: 00:00:04
2020-05-02 11:38:10,952 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 11:38:11
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502113756]
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 11:38:11,405 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 11:38:12,324 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:12,325 INFO  mapreduce.Job - Running job: job_local1458095609_0001
2020-05-02 11:38:13,345 INFO  mapreduce.Job - Job job_local1458095609_0001 running in uber mode : false
2020-05-02 11:38:13,347 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:38:13,534 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:38:13,535 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:38:13,535 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:38:13,624 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:38:13,624 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:38:13,624 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:38:14,352 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:14,354 INFO  mapreduce.Job - Job job_local1458095609_0001 completed successfully
2020-05-02 11:38:14,372 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6630864
		FILE: Number of bytes written=10487211
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=206
		Map output records=206
		Map output bytes=15039
		Map output materialized bytes=1476
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=1476
		Reduce input records=206
		Reduce output records=134
		Spilled Records=412
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16736
	File Output Format Counters 
		Bytes Written=11780
2020-05-02 11:38:14,393 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 11:38:14, elapsed: 00:00:02
2020-05-02 11:38:15,602 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:15,961 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 11:38:15
2020-05-02 11:38:15,961 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 11:38:15,961 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 11:38:15,962 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 11:38:15,962 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 11:38:15,962 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502113756
2020-05-02 11:38:16,967 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:16,969 INFO  mapreduce.Job - Running job: job_local305705106_0001
2020-05-02 11:38:17,493 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 11:38:17,979 INFO  mapreduce.Job - Job job_local305705106_0001 running in uber mode : false
2020-05-02 11:38:17,980 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:17,981 INFO  mapreduce.Job - Job job_local305705106_0001 completed successfully
2020-05-02 11:38:17,997 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2790505
		FILE: Number of bytes written=4475393
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=332
		Combine input records=1
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2440
	File Output Format Counters 
		Bytes Written=486
2020-05-02 11:38:18,017 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 11:38:17, elapsed: 00:00:02
2020-05-02 11:38:19,075 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 11:38:19
2020-05-02 11:38:19,355 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:20,483 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:20,484 INFO  mapreduce.Job - Running job: job_local1397497342_0001
2020-05-02 11:38:21,492 INFO  mapreduce.Job - Job job_local1397497342_0001 running in uber mode : false
2020-05-02 11:38:21,493 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:21,494 INFO  mapreduce.Job - Job job_local1397497342_0001 completed successfully
2020-05-02 11:38:21,507 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2812628
		FILE: Number of bytes written=4485870
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=2
		Map output bytes=526
		Map output materialized bytes=544
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=544
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11307
	File Output Format Counters 
		Bytes Written=98
2020-05-02 11:38:21,512 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 11:38:21,512 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 11:38:21,801 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:21,801 INFO  mapreduce.Job - Running job: job_local1571383815_0002
2020-05-02 11:38:22,807 INFO  mapreduce.Job - Job job_local1571383815_0002 running in uber mode : false
2020-05-02 11:38:22,807 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:22,808 INFO  mapreduce.Job - Job job_local1571383815_0002 completed successfully
2020-05-02 11:38:22,812 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7533952
		FILE: Number of bytes written=12014357
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10163
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10163
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11405
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 11:38:22,836 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 11:38:22, elapsed: 00:00:03
2020-05-02 11:38:23,962 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:24,474 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502113756.
2020-05-02 11:38:24,477 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 11:38:24
2020-05-02 11:38:24,493 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 11:38:24,494 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 11:38:24,494 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 11:38:24,499 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 11:38:24,499 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 11:38:24,499 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502113756
2020-05-02 11:38:25,542 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:25,542 INFO  mapreduce.Job - Running job: job_local117106698_0001
2020-05-02 11:38:26,551 INFO  mapreduce.Job - Job job_local117106698_0001 running in uber mode : false
2020-05-02 11:38:26,552 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:38:26,997 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 11:38:27,027 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 11:38:27,321 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 11:38:27,882 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 11:38:27,903 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 11:38:27,921 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 11:38:27,928 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 11:38:27,929 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 11:38:28,559 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:28,559 INFO  mapreduce.Job - Job job_local117106698_0001 completed successfully
2020-05-02 11:38:28,577 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10918865
		FILE: Number of bytes written=17314217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=343
		Map output records=343
		Map output bytes=77719
		Map output materialized bytes=78477
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=78477
		Reduce input records=343
		Reduce output records=2
		Spilled Records=686
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=260
		Total committed heap usage (bytes)=4905762816
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47829
	File Output Format Counters 
		Bytes Written=0
2020-05-02 11:38:28,577 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 11:38:28,585 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 11:38:28,613 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 11:38:28, elapsed: 00:00:04
2020-05-02 11:38:29,693 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 11:38:29
2020-05-02 11:38:29,977 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:31,151 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:31,152 INFO  mapreduce.Job - Running job: job_local1855450426_0001
2020-05-02 11:38:31,769 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 11:38:31,797 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 11:38:32,161 INFO  mapreduce.Job - Job job_local1855450426_0001 running in uber mode : false
2020-05-02 11:38:32,162 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:38:32,201 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 11:38:33,166 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:33,167 INFO  mapreduce.Job - Job job_local1855450426_0001 completed successfully
2020-05-02 11:38:33,183 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1877012
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=478150656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=0
2020-05-02 11:38:33,203 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 11:38:33, elapsed: 00:00:03
2020-05-02 12:14:35,802 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:14:36,309 WARN  parse.ParseSegment - Segment: crawl/segments/20200502113756 already parsed!! Skipped parsing this segment!!
2020-05-02 12:14:54,233 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:14:54,588 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:14:54
2020-05-02 12:14:54,589 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502113756
2020-05-02 12:14:55,656 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:14:55,657 INFO  mapreduce.Job - Running job: job_local1619690207_0001
2020-05-02 12:14:56,674 INFO  mapreduce.Job - Job job_local1619690207_0001 running in uber mode : false
2020-05-02 12:14:56,675 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:14:56,945 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 12:14:57,217 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:14:57,221 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:14:57,231 INFO  parse.ParseSegment - Parsed (1053ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:14:57,308 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:14:57,309 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:14:57,524 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:14:57,656 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:14:57,677 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:14:58,683 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:14:58,684 INFO  mapreduce.Job - Job job_local1619690207_0001 completed successfully
2020-05-02 12:14:58,704 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3047840
		FILE: Number of bytes written=4807122
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=72779
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=72779
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=79
		Total committed heap usage (bytes)=1176502272
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39776
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:14:58,717 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:14:58, elapsed: 00:00:04
2020-05-02 12:15:07,425 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:15:07,883 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:15:07
2020-05-02 12:15:07,883 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502113756]
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:15:07,886 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:15:09,373 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:09,380 INFO  mapreduce.Job - Running job: job_local2128912528_0001
2020-05-02 12:15:10,399 INFO  mapreduce.Job - Job job_local2128912528_0001 running in uber mode : false
2020-05-02 12:15:10,400 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:15:10,540 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:15:10,541 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:15:10,541 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:15:11,402 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:11,402 INFO  mapreduce.Job - Job job_local2128912528_0001 completed successfully
2020-05-02 12:15:11,418 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=4821174
		FILE: Number of bytes written=7621596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=338
		Map output records=338
		Map output bytes=24778
		Map output materialized bytes=25482
		Input split bytes=643
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=25482
		Reduce input records=338
		Reduce output records=134
		Spilled Records=676
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=2290614272
	CrawlDB status
		db_notmodified=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27568
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:15:11,441 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:15:11, elapsed: 00:00:03
2020-05-02 12:15:13,889 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:15:14,494 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:15:14
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:15:14,496 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:15:15,548 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:15,578 INFO  mapreduce.Job - Running job: job_local1793762423_0001
2020-05-02 12:15:16,595 INFO  mapreduce.Job - Job job_local1793762423_0001 running in uber mode : false
2020-05-02 12:15:16,600 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:16,604 INFO  mapreduce.Job - Job job_local1793762423_0001 completed successfully
2020-05-02 12:15:16,645 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2795004
		FILE: Number of bytes written=4481642
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=332
		Combine input records=2
		Combine output records=2
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4600
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:15:16,645 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:15:17,234 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:17,234 INFO  mapreduce.Job - Running job: job_local438898206_0002
2020-05-02 12:15:17,920 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:15:17,958 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:15:18,236 INFO  mapreduce.Job - Job job_local438898206_0002 running in uber mode : false
2020-05-02 12:15:18,237 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:18,237 INFO  mapreduce.Job - Job job_local438898206_0002 completed successfully
2020-05-02 12:15:18,242 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5583031
		FILE: Number of bytes written=8957480
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=242
		Total committed heap usage (bytes)=1360527360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:15:18,267 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:15:18, elapsed: 00:00:03
2020-05-02 12:15:20,586 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:15:20,960 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502113756.
2020-05-02 12:15:20,963 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:15:20
2020-05-02 12:15:21,019 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:15:21,021 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:15:21,022 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:15:21,024 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:15:21,024 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:15:21,024 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502113756
2020-05-02 12:15:22,087 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:22,088 INFO  mapreduce.Job - Running job: job_local1047893186_0001
2020-05-02 12:15:22,635 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:22,728 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:22,832 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:22,990 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,100 INFO  mapreduce.Job - Job job_local1047893186_0001 running in uber mode : false
2020-05-02 12:15:23,101 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:15:23,118 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,215 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,275 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,320 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,459 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:15:23,489 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:15:23,985 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 12:15:24,622 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 12:15:24,640 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:15:24,647 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:15:24,650 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:15:24,651 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:15:25,112 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:25,112 INFO  mapreduce.Job - Job job_local1047893186_0001 completed successfully
2020-05-02 12:15:25,147 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10162457
		FILE: Number of bytes written=16209591
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130235
		Map output materialized bytes=131003
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131003
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=6191841280
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:15:25,148 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:15:25,156 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:15:25,171 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:15:25, elapsed: 00:00:04
2020-05-02 12:17:43,602 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:17:44,089 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:17:44
2020-05-02 12:17:44,089 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:17:44,089 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502113756]
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:17:44,092 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:17:45,335 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:45,336 INFO  mapreduce.Job - Running job: job_local2078728313_0001
2020-05-02 12:17:46,322 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:17:46,323 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:17:46,323 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:17:46,346 INFO  mapreduce.Job - Job job_local2078728313_0001 running in uber mode : false
2020-05-02 12:17:46,347 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:17:47,351 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:47,352 INFO  mapreduce.Job - Job job_local2078728313_0001 completed successfully
2020-05-02 12:17:47,368 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=4821174
		FILE: Number of bytes written=7621596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=338
		Map output records=338
		Map output bytes=24778
		Map output materialized bytes=25482
		Input split bytes=643
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=25482
		Reduce input records=338
		Reduce output records=134
		Spilled Records=676
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=2290614272
	CrawlDB status
		db_notmodified=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27568
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:17:47,386 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:17:47, elapsed: 00:00:03
2020-05-02 12:17:48,707 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:17:49
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:17:50,060 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:50,061 INFO  mapreduce.Job - Running job: job_local404785557_0001
2020-05-02 12:17:51,067 INFO  mapreduce.Job - Job job_local404785557_0001 running in uber mode : false
2020-05-02 12:17:51,068 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:51,070 INFO  mapreduce.Job - Job job_local404785557_0001 completed successfully
2020-05-02 12:17:51,088 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2795004
		FILE: Number of bytes written=4473476
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=332
		Combine input records=2
		Combine output records=2
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4600
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:17:51,089 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:17:51,395 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:51,395 INFO  mapreduce.Job - Running job: job_local1284229186_0002
2020-05-02 12:17:51,727 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:17:51,818 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:17:52,398 INFO  mapreduce.Job - Job job_local1284229186_0002 running in uber mode : false
2020-05-02 12:17:52,399 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:52,399 INFO  mapreduce.Job - Job job_local1284229186_0002 completed successfully
2020-05-02 12:17:52,404 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5583036
		FILE: Number of bytes written=8957501
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:17:52,429 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:17:52, elapsed: 00:00:03
2020-05-02 12:17:53,592 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:17:54,094 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502113756.
2020-05-02 12:17:54,098 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:17:54
2020-05-02 12:17:54,113 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:17:54,113 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:17:54,113 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:17:54,117 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:17:54,117 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:17:54,117 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502113756
2020-05-02 12:17:55,056 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:55,057 INFO  mapreduce.Job - Running job: job_local120317803_0001
2020-05-02 12:17:55,528 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:55,622 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:55,700 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:55,985 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,062 INFO  mapreduce.Job - Job job_local120317803_0001 running in uber mode : false
2020-05-02 12:17:56,063 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:17:56,114 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,162 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,362 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,410 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,551 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:17:56,582 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:17:57,053 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 12:17:57,651 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 12:17:57,663 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:17:57,671 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:17:57,679 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:17:57,680 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:17:58,068 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:58,069 INFO  mapreduce.Job - Job job_local120317803_0001 completed successfully
2020-05-02 12:17:58,095 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10162457
		FILE: Number of bytes written=16182251
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130235
		Map output materialized bytes=131003
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131003
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=6241124352
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:17:58,095 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:17:58,102 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:17:58,121 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:17:58, elapsed: 00:00:04
2020-05-02 12:24:18,530 INFO  crawl.Injector - Injector: starting at 2020-05-02 12:24:18
2020-05-02 12:24:18,531 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 12:24:18,531 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 12:24:18,531 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 12:24:18,673 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:19,092 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 12:24:20,057 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:20,061 INFO  mapreduce.Job - Running job: job_local1460635078_0001
2020-05-02 12:24:20,518 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 12:24:20,715 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 12:24:20,715 INFO  crawl.Injector - Injector: update: false
2020-05-02 12:24:21,115 INFO  mapreduce.Job - Job job_local1460635078_0001 running in uber mode : false
2020-05-02 12:24:21,116 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:21,118 INFO  mapreduce.Job - Job job_local1460635078_0001 completed successfully
2020-05-02 12:24:21,130 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1854978
		FILE: Number of bytes written=2987608
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=53
		Map output materialized bytes=61
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=61
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=387
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total new urls injected: 1
2020-05-02 12:24:21,159 INFO  crawl.Injector - Injector: finished at 2020-05-02 12:24:21, elapsed: 00:00:02
2020-05-02 12:24:22,433 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:23,441 INFO  crawl.Generator - Generator: starting at 2020-05-02 12:24:23
2020-05-02 12:24:23,441 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 12:24:23,442 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 12:24:23,442 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 12:24:23,445 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 12:24:24,361 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:24,362 INFO  mapreduce.Job - Running job: job_local227309630_0001
2020-05-02 12:24:25,307 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:24:25,308 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:24:25,312 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:24:25,332 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 12:24:25,372 INFO  mapreduce.Job - Job job_local227309630_0001 running in uber mode : false
2020-05-02 12:24:25,373 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:24:25,689 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 12:24:26,380 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:26,381 INFO  mapreduce.Job - Job job_local227309630_0001 completed successfully
2020-05-02 12:24:26,396 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2782807
		FILE: Number of bytes written=4485108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=82
		Map output materialized bytes=94
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=94
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=159
	File Output Format Counters 
		Bytes Written=16
2020-05-02 12:24:26,396 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 12:24:26,401 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 12:24:27,402 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502122427
2020-05-02 12:24:27,728 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:27,728 INFO  mapreduce.Job - Running job: job_local1840225848_0002
2020-05-02 12:24:28,731 INFO  mapreduce.Job - Job job_local1840225848_0002 running in uber mode : false
2020-05-02 12:24:28,731 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:28,732 INFO  mapreduce.Job - Job job_local1840225848_0002 completed successfully
2020-05-02 12:24:28,735 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3710816
		FILE: Number of bytes written=5981397
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=102
		Map output materialized bytes=79
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=79
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=210
	File Output Format Counters 
		Bytes Written=180
2020-05-02 12:24:28,751 INFO  crawl.Generator - Generator: finished at 2020-05-02 12:24:28, elapsed: 00:00:05
2020-05-02 12:24:29,971 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 12:24:29
2020-05-02 12:24:29,972 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502122427
2020-05-02 12:24:29,972 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588407869972  (2020-05-02 15:24:29)
2020-05-02 12:24:30,290 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:31,578 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:31,583 INFO  mapreduce.Job - Running job: job_local1334054942_0001
2020-05-02 12:24:31,804 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 12:24:31,805 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 12:24:31,808 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 12:24:31,818 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 1 records hit by time limit : 0
2020-05-02 12:24:32,160 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,181 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,181 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,182 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.google.com/ (queue crawl delay=1ms)
2020-05-02 12:24:32,425 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 12:24:32,429 INFO  http.Http - http.proxy.host = null
2020-05-02 12:24:32,429 INFO  http.Http - http.proxy.port = 8080
2020-05-02 12:24:32,429 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 12:24:32,429 INFO  http.Http - http.timeout = 30000
2020-05-02 12:24:32,429 INFO  http.Http - http.content.limit = -1
2020-05-02 12:24:32,429 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 12:24:32,429 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 12:24:32,429 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 12:24:32,429 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 12:24:32,430 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,431 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 12:24:32,431 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,431 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,432 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,432 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 12:24:32,432 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,432 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,433 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,434 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 12:24:32,434 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,434 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,436 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,437 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 12:24:32,437 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,437 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,438 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,441 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 12:24:32,441 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,441 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,444 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,444 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 12:24:32,445 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,445 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,446 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,446 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 12:24:32,447 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,447 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,448 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,451 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 12:24:32,451 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,452 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,454 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,454 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,454 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 12:24:32,455 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,455 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,456 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,456 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 12:24:32,457 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,460 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,460 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,460 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 12:24:32,460 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,461 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,462 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 12:24:32,462 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,462 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,464 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,465 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,465 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 12:24:32,466 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,466 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,467 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 12:24:32,467 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,468 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,470 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,470 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 12:24:32,470 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,471 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,472 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 12:24:32,472 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,472 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,473 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,473 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 12:24:32,473 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,474 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,474 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,475 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 12:24:32,475 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,475 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,477 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 12:24:32,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,477 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,481 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 12:24:32,481 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,482 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,483 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 12:24:32,483 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,483 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,484 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,484 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 12:24:32,485 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,485 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,486 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,488 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 12:24:32,488 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,489 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,489 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,490 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 12:24:32,491 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,491 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,492 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 12:24:32,492 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,492 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,493 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 12:24:32,494 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,494 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,495 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,495 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 12:24:32,495 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,496 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,501 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 12:24:32,501 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,501 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,502 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,503 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 12:24:32,503 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,503 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,504 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,505 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 12:24:32,505 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,505 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,506 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,509 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 12:24:32,509 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,513 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,514 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,514 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 12:24:32,514 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,515 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,515 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,516 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 12:24:32,516 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,517 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,518 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,518 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 12:24:32,518 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,519 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,520 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 12:24:32,520 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,520 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,521 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,522 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 12:24:32,522 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,522 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,523 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,523 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 12:24:32,523 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,529 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,531 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 12:24:32,532 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,535 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,536 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 12:24:32,536 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,536 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,537 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,537 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 12:24:32,537 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,537 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,538 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,538 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 12:24:32,538 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,539 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,539 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,540 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 12:24:32,540 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,540 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,541 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,541 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,543 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,543 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,544 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,544 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 12:24:32,547 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,547 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,548 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 12:24:32,548 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,548 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,549 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,550 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,550 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 12:24:32,550 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,550 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,551 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 12:24:32,551 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,551 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,551 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,552 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 12:24:32,552 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 12:24:32,552 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,552 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 12:24:32,554 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 12:24:32,591 INFO  mapreduce.Job - Job job_local1334054942_0001 running in uber mode : false
2020-05-02 12:24:32,593 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:24:33,341 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 12:24:33,341 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=0
2020-05-02 12:24:33,556 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 12:24:33,557 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 12:24:34,602 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:34,602 INFO  mapreduce.Job - Job job_local1334054942_0001 completed successfully
2020-05-02 12:24:34,619 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2808742
		FILE: Number of bytes written=4526130
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=2
		Map output bytes=14807
		Map output materialized bytes=6556
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=6556
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=92
		Total committed heap usage (bytes)=973602816
	FetcherStatus
		bytes_downloaded=13612
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=180
	File Output Format Counters 
		Bytes Written=7953
2020-05-02 12:24:34,619 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 12:24:34, elapsed: 00:00:04
2020-05-02 12:24:35,803 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:36,155 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:24:36
2020-05-02 12:24:36,156 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502122427
2020-05-02 12:24:36,981 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:36,982 INFO  mapreduce.Job - Running job: job_local513757716_0001
2020-05-02 12:24:37,512 WARN  parse.ParserFactory - ParserFactory: Plugin: ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParser mapped to contentType text/html via parse-plugins.xml, but not enabled via plugin.includes in nutch-default.xml
2020-05-02 12:24:37,991 INFO  mapreduce.Job - Job job_local513757716_0001 running in uber mode : false
2020-05-02 12:24:37,998 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:24:38,344 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:24:38,346 INFO  parse.ParseSegment - Parsed (853ms):https://www.google.com/
2020-05-02 12:24:38,548 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:38,648 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:24:38,677 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:39,005 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:39,005 INFO  mapreduce.Job - Job job_local513757716_0001 completed successfully
2020-05-02 12:24:39,019 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3744572
		FILE: Number of bytes written=5978283
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=3099
		Map output materialized bytes=1634
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1634
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=68
		Total committed heap usage (bytes)=1587019776
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6757
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:24:39,037 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:24:39, elapsed: 00:00:02
2020-05-02 12:24:40,319 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:40,815 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:24:40
2020-05-02 12:24:40,815 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:24:40,816 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502122427]
2020-05-02 12:24:40,816 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:24:40,834 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:24:40,835 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:24:40,835 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:24:40,837 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:24:41,771 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:41,772 INFO  mapreduce.Job - Running job: job_local515730108_0001
2020-05-02 12:24:42,725 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:24:42,725 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:24:42,726 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:24:42,779 INFO  mapreduce.Job - Job job_local515730108_0001 running in uber mode : false
2020-05-02 12:24:42,780 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 12:24:42,790 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:24:42,790 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:24:42,790 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:24:43,786 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:43,787 INFO  mapreduce.Job - Job job_local515730108_0001 completed successfully
2020-05-02 12:24:43,804 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6519318
		FILE: Number of bytes written=10444489
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=613
		Map output materialized bytes=550
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=550
		Reduce input records=7
		Reduce output records=5
		Spilled Records=14
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=1
		db_unfetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1277
	File Output Format Counters 
		Bytes Written=1195
2020-05-02 12:24:43,822 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:24:43, elapsed: 00:00:03
2020-05-02 12:24:44,962 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:24:45
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:24:45,321 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502122427
2020-05-02 12:24:46,157 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:46,158 INFO  mapreduce.Job - Running job: job_local860915945_0001
2020-05-02 12:24:47,168 INFO  mapreduce.Job - Job job_local860915945_0001 running in uber mode : false
2020-05-02 12:24:47,170 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:47,171 INFO  mapreduce.Job - Job job_local860915945_0001 completed successfully
2020-05-02 12:24:47,184 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2786546
		FILE: Number of bytes written=4472650
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1179
	File Output Format Counters 
		Bytes Written=279
2020-05-02 12:24:47,184 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:24:47,457 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:47,457 INFO  mapreduce.Job - Running job: job_local1513967988_0002
2020-05-02 12:24:47,788 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:24:48,463 INFO  mapreduce.Job - Job job_local1513967988_0002 running in uber mode : false
2020-05-02 12:24:48,463 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:48,464 INFO  mapreduce.Job - Job job_local1513967988_0002 completed successfully
2020-05-02 12:24:48,468 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5571331
		FILE: Number of bytes written=8955560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=378
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:24:48,486 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:24:48, elapsed: 00:00:03
2020-05-02 12:24:49,508 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 12:24:49
2020-05-02 12:24:49,840 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:51,154 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:51,155 INFO  mapreduce.Job - Running job: job_local991775611_0001
2020-05-02 12:24:52,165 INFO  mapreduce.Job - Job job_local991775611_0001 running in uber mode : false
2020-05-02 12:24:52,167 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:52,168 INFO  mapreduce.Job - Job job_local991775611_0001 completed successfully
2020-05-02 12:24:52,182 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785363
		FILE: Number of bytes written=4477037
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=1
		Map output bytes=236
		Map output materialized bytes=251
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=251
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=727
	File Output Format Counters 
		Bytes Written=98
2020-05-02 12:24:52,187 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 12:24:52,187 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 12:24:52,515 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:52,515 INFO  mapreduce.Job - Running job: job_local842725531_0002
2020-05-02 12:24:53,516 INFO  mapreduce.Job - Job job_local842725531_0002 running in uber mode : false
2020-05-02 12:24:53,516 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:53,516 INFO  mapreduce.Job - Job job_local842725531_0002 completed successfully
2020-05-02 12:24:53,521 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7432738
		FILE: Number of bytes written=11935978
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=491
		Map output materialized bytes=520
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=520
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=825
	File Output Format Counters 
		Bytes Written=861
2020-05-02 12:24:53,546 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 12:24:53, elapsed: 00:00:04
2020-05-02 12:24:54,733 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:55,212 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502122427.
2020-05-02 12:24:55,217 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:24:55
2020-05-02 12:24:55,234 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 12:24:55,234 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 12:24:55,235 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 12:24:55,239 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:24:55,239 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:24:55,239 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502122427
2020-05-02 12:24:56,218 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:56,219 INFO  mapreduce.Job - Running job: job_local515226845_0001
2020-05-02 12:24:57,225 INFO  mapreduce.Job - Job job_local515226845_0001 running in uber mode : false
2020-05-02 12:24:57,226 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:24:57,725 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:24:57,755 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:24:58,176 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 12:24:58,752 INFO  solr.SolrIndexWriter - Indexing 1/1 documents
2020-05-02 12:24:58,752 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:24:59,231 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:59,232 INFO  mapreduce.Job - Job job_local515226845_0001 completed successfully
2020-05-02 12:24:59,250 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10325838
		FILE: Number of bytes written=16475726
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=2870
		Map output materialized bytes=2964
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=2964
		Reduce input records=14
		Reduce output records=1
		Spilled Records=28
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=298
		Total committed heap usage (bytes)=4911529984
	IndexerStatus
		indexed (add/update)=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3739
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:24:59,250 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:24:59,258 INFO  indexer.IndexingJob - Indexer:      1  indexed (add/update)
2020-05-02 12:24:59,280 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:24:59, elapsed: 00:00:04
2020-05-02 12:25:00,375 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 12:25:00
2020-05-02 12:25:00,630 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:25:02,082 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:25:02,083 INFO  mapreduce.Job - Running job: job_local422061482_0001
2020-05-02 12:25:02,684 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:25:02,706 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:25:03,091 INFO  mapreduce.Job - Job job_local422061482_0001 running in uber mode : false
2020-05-02 12:25:03,092 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:25:03,111 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 12:25:04,098 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:25:04,099 INFO  mapreduce.Job - Job job_local422061482_0001 completed successfully
2020-05-02 12:25:04,124 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1855820
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=91
		Total committed heap usage (bytes)=481820672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=633
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:25:04,144 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 12:25:04, elapsed: 00:00:03
2020-05-02 12:26:28,931 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:26:29,342 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:26:29
2020-05-02 12:26:29,342 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:26:29,343 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502122427]
2020-05-02 12:26:29,343 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:26:29,344 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:26:29,344 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:26:29,344 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:26:29,346 INFO  crawl.CrawlDb -  - adding fetched but unparsed segment crawl/segments/20200502122427
2020-05-02 12:26:29,346 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:26:30,372 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:30,374 INFO  mapreduce.Job - Running job: job_local631989259_0001
2020-05-02 12:26:31,091 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:26:31,092 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:26:31,092 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:26:31,382 INFO  mapreduce.Job - Job job_local631989259_0001 running in uber mode : false
2020-05-02 12:26:31,384 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:31,385 INFO  mapreduce.Job - Job job_local631989259_0001 completed successfully
2020-05-02 12:26:31,400 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3718281
		FILE: Number of bytes written=5966539
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=692
		Map output materialized bytes=724
		Input split bytes=481
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=724
		Reduce input records=6
		Reduce output records=5
		Spilled Records=12
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=1600651264
	CrawlDB status
		db_fetched=1
		db_unfetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1091
	File Output Format Counters 
		Bytes Written=845
2020-05-02 12:26:31,420 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:26:31, elapsed: 00:00:02
2020-05-02 12:26:32,489 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:26:33,006 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:26:33
2020-05-02 12:26:33,006 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:26:33,006 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:26:33,007 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:26:33,007 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:26:33,007 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:26:33,010 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502122427
2020-05-02 12:26:33,934 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:33,935 INFO  mapreduce.Job - Running job: job_local1447631549_0001
2020-05-02 12:26:34,944 INFO  mapreduce.Job - Job job_local1447631549_0001 running in uber mode : false
2020-05-02 12:26:34,946 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:34,947 INFO  mapreduce.Job - Job job_local1447631549_0001 completed successfully
2020-05-02 12:26:34,963 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4669915
		FILE: Number of bytes written=7471947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=200
		Input split bytes=664
		Combine input records=2
		Combine output records=2
		Reduce input groups=1
		Reduce shuffle bytes=200
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2290614272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5779
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:26:34,963 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:26:35,247 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:35,248 INFO  mapreduce.Job - Running job: job_local1954468760_0002
2020-05-02 12:26:35,728 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:26:35,879 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:26:36,253 INFO  mapreduce.Job - Job job_local1954468760_0002 running in uber mode : false
2020-05-02 12:26:36,253 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:36,253 INFO  mapreduce.Job - Job job_local1954468760_0002 completed successfully
2020-05-02 12:26:36,273 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5593038
		FILE: Number of bytes written=8967536
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2235564032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:26:36,292 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:26:36, elapsed: 00:00:03
2020-05-02 12:26:38,246 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:26:38,724 WARN  segment.SegmentChecker - Skipping segment: crawl/segments/20200502122427. Missing sub directories: crawl_parse
2020-05-02 12:26:38,729 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:26:38
2020-05-02 12:26:38,754 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:26:38,754 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:26:38,754 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:26:38,758 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:26:38,758 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:26:39,898 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:39,904 INFO  mapreduce.Job - Running job: job_local731371177_0001
2020-05-02 12:26:40,551 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:26:40,786 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:26:40,901 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:26:40,916 INFO  mapreduce.Job - Job job_local731371177_0001 running in uber mode : false
2020-05-02 12:26:40,918 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:26:40,936 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:26:41,381 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 12:26:42,924 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:42,925 INFO  mapreduce.Job - Job job_local731371177_0001 completed successfully
2020-05-02 12:26:42,944 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2786445
		FILE: Number of bytes written=4480113
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=567
		Map output materialized bytes=592
		Input split bytes=293
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=592
		Reduce input records=6
		Reduce output records=0
		Spilled Records=12
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=89
		Total committed heap usage (bytes)=855113728
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=857
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:26:42,944 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:26:42,974 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:26:42, elapsed: 00:00:04
2020-05-02 12:30:28,234 INFO  crawl.Injector - Injector: starting at 2020-05-02 12:30:28
2020-05-02 12:30:28,235 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 12:30:28,236 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 12:30:28,236 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 12:30:28,399 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:28,862 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 12:30:29,884 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:29,885 INFO  mapreduce.Job - Running job: job_local260904640_0001
2020-05-02 12:30:30,344 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 12:30:30,557 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 12:30:30,557 INFO  crawl.Injector - Injector: update: false
2020-05-02 12:30:30,891 INFO  mapreduce.Job - Job job_local260904640_0001 running in uber mode : false
2020-05-02 12:30:30,892 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:30,894 INFO  mapreduce.Job - Job job_local260904640_0001 completed successfully
2020-05-02 12:30:30,907 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855256
		FILE: Number of bytes written=2982521
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=136
		Map output materialized bytes=146
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=146
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=493
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 12:30:30,934 INFO  crawl.Injector - Injector: finished at 2020-05-02 12:30:30, elapsed: 00:00:02
2020-05-02 12:30:31,955 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: starting at 2020-05-02 12:30:32
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 12:30:32,335 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 12:30:33,127 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:33,127 INFO  mapreduce.Job - Running job: job_local1473169222_0001
2020-05-02 12:30:33,591 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:30:33,591 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:30:33,591 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:30:33,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 12:30:33,786 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 12:30:34,138 INFO  mapreduce.Job - Job job_local1473169222_0001 running in uber mode : false
2020-05-02 12:30:34,139 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:34,140 INFO  mapreduce.Job - Job job_local1473169222_0001 completed successfully
2020-05-02 12:30:34,156 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783168
		FILE: Number of bytes written=4493978
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=194
		Map output materialized bytes=116
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=116
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=250
	File Output Format Counters 
		Bytes Written=16
2020-05-02 12:30:34,156 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 12:30:34,163 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 12:30:35,169 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502123035
2020-05-02 12:30:35,396 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:35,396 INFO  mapreduce.Job - Running job: job_local1558588550_0002
2020-05-02 12:30:36,399 INFO  mapreduce.Job - Job job_local1558588550_0002 running in uber mode : false
2020-05-02 12:30:36,399 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:36,400 INFO  mapreduce.Job - Job job_local1558588550_0002 completed successfully
2020-05-02 12:30:36,404 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3711250
		FILE: Number of bytes written=5987420
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=264
		Map output materialized bytes=106
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=106
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=330
	File Output Format Counters 
		Bytes Written=292
2020-05-02 12:30:36,422 INFO  crawl.Generator - Generator: finished at 2020-05-02 12:30:36, elapsed: 00:00:04
2020-05-02 12:30:37,421 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 12:30:37
2020-05-02 12:30:37,422 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502123035
2020-05-02 12:30:37,423 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588408237422  (2020-05-02 15:30:37)
2020-05-02 12:30:37,639 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:38,690 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:38,691 INFO  mapreduce.Job - Running job: job_local1675202230_0001
2020-05-02 12:30:38,900 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 12:30:38,901 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 12:30:38,901 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 12:30:38,917 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records hit by time limit : 0
2020-05-02 12:30:39,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,226 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,227 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,227 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 12:30:39,450 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 12:30:39,452 INFO  http.Http - http.proxy.host = null
2020-05-02 12:30:39,452 INFO  http.Http - http.proxy.port = 8080
2020-05-02 12:30:39,452 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 12:30:39,452 INFO  http.Http - http.timeout = 30000
2020-05-02 12:30:39,452 INFO  http.Http - http.content.limit = -1
2020-05-02 12:30:39,452 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 12:30:39,452 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 12:30:39,452 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 12:30:39,452 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 12:30:39,453 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,453 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,454 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,455 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,456 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,456 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,457 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,458 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,459 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,462 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,462 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,463 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,464 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,465 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,466 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,467 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,468 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,468 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,469 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,469 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,470 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,474 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,474 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,475 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,475 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,478 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,478 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,481 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,483 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,483 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,486 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,486 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,487 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,487 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,489 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,489 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,491 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,491 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,492 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,492 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,498 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,499 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,499 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,500 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,501 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,502 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,502 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,503 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,504 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,507 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,508 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,508 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,509 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,509 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,510 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,511 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,511 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,514 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,515 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,515 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,516 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,517 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,517 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,520 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,521 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,521 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,522 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,523 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,524 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,524 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,525 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,525 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,526 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,526 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,527 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,530 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,531 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,531 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,532 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,533 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,534 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,535 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 12:30:39,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 12:30:39,537 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 12:30:39,701 INFO  mapreduce.Job - Job job_local1675202230_0001 running in uber mode : false
2020-05-02 12:30:39,701 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:30:40,383 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=49
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=48
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=47
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=46
2020-05-02 12:30:40,466 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 12:30:40,466 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 12:30:40,466 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=45
2020-05-02 12:30:40,467 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=44
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=43
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 12:30:40,474 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=41
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 12:30:40,474 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=40
2020-05-02 12:30:40,474 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=42
2020-05-02 12:30:40,478 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 12:30:40,478 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=39
2020-05-02 12:30:40,481 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=35
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 12:30:40,483 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=33
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=38
2020-05-02 12:30:40,483 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=34
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=37
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=32
2020-05-02 12:30:40,491 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=31
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 12:30:40,492 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=30
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 12:30:40,492 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=29
2020-05-02 12:30:40,498 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 12:30:40,498 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 12:30:40,498 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=28
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=25
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=26
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=27
2020-05-02 12:30:40,504 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 12:30:40,504 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=23
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 12:30:40,507 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=20
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=21
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=22
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=19
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 12:30:40,517 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=18
2020-05-02 12:30:40,518 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=17
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 12:30:40,518 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=16
2020-05-02 12:30:40,519 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 12:30:40,520 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=15
2020-05-02 12:30:40,519 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 12:30:40,519 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 12:30:40,520 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=14
2020-05-02 12:30:40,520 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=13
2020-05-02 12:30:40,527 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 12:30:40,527 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=12
2020-05-02 12:30:40,528 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 12:30:40,528 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=11
2020-05-02 12:30:40,527 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 12:30:40,528 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=10
2020-05-02 12:30:40,529 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 12:30:40,529 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=7
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=8
2020-05-02 12:30:40,529 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=9
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 12:30:40,531 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=6
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 12:30:40,531 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=5
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=4
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=3
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=2
2020-05-02 12:30:40,542 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 12:30:40,542 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:30:40,543 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 12:30:41,107 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 12:30:41,108 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=0
2020-05-02 12:30:41,548 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 12:30:41,548 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 12:30:41,708 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:30:42,711 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:42,711 INFO  mapreduce.Job - Job job_local1675202230_0001 completed successfully
2020-05-02 12:30:42,730 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2869181
		FILE: Number of bytes written=4676107
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=235541
		Map output materialized bytes=39066
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=39066
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=975175680
	FetcherStatus
		bytes_downloaded=233595
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=292
	File Output Format Counters 
		Bytes Written=41240
2020-05-02 12:30:42,730 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 12:30:42, elapsed: 00:00:05
2020-05-02 12:30:43,783 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:44,122 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:30:44
2020-05-02 12:30:44,122 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123035
2020-05-02 12:30:44,840 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:44,840 INFO  mapreduce.Job - Running job: job_local274137970_0001
2020-05-02 12:30:45,846 INFO  mapreduce.Job - Job job_local274137970_0001 running in uber mode : false
2020-05-02 12:30:45,847 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:30:45,882 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 12:30:46,120 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:30:46,124 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:30:46,134 INFO  parse.ParseSegment - Parsed (851ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:30:46,210 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:30:46,211 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:30:46,410 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:46,540 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:46,612 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:30:46,850 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:46,851 INFO  mapreduce.Job - Job job_local274137970_0001 completed successfully
2020-05-02 12:30:46,869 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3921794
		FILE: Number of bytes written=6108643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=21711
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=21711
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1595408384
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39779
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:30:46,884 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:30:46, elapsed: 00:00:02
2020-05-02 12:30:47,987 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:48,451 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:30:48
2020-05-02 12:30:48,451 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:30:48,451 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502123035]
2020-05-02 12:30:48,452 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:30:48,453 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:30:48,454 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:30:48,454 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:30:48,464 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:30:49,378 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:49,383 INFO  mapreduce.Job - Running job: job_local1960616636_0001
2020-05-02 12:30:50,397 INFO  mapreduce.Job - Job job_local1960616636_0001 running in uber mode : false
2020-05-02 12:30:50,399 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:30:50,495 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:30:50,495 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:30:50,495 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:30:50,565 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:30:50,565 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:30:50,565 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:30:51,403 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:51,404 INFO  mapreduce.Job - Job job_local1960616636_0001 completed successfully
2020-05-02 12:30:51,429 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6630865
		FILE: Number of bytes written=10487185
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=206
		Map output records=206
		Map output bytes=15039
		Map output materialized bytes=1473
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=1473
		Reduce input records=206
		Reduce output records=134
		Spilled Records=412
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16738
	File Output Format Counters 
		Bytes Written=11780
2020-05-02 12:30:51,456 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:30:51, elapsed: 00:00:03
2020-05-02 12:30:52,724 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:53,138 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:30:53
2020-05-02 12:30:53,138 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:30:53,138 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:30:53,139 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:30:53,139 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:30:53,139 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502123035
2020-05-02 12:30:53,917 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:53,918 INFO  mapreduce.Job - Running job: job_local1892626895_0001
2020-05-02 12:30:54,924 INFO  mapreduce.Job - Job job_local1892626895_0001 running in uber mode : false
2020-05-02 12:30:54,926 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:54,927 INFO  mapreduce.Job - Job job_local1892626895_0001 completed successfully
2020-05-02 12:30:54,940 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2790511
		FILE: Number of bytes written=4481375
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=332
		Combine input records=1
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2442
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:30:54,941 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:30:55,225 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:55,225 INFO  mapreduce.Job - Running job: job_local947088815_0002
2020-05-02 12:30:55,540 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:30:55,617 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:30:56,230 INFO  mapreduce.Job - Job job_local947088815_0002 running in uber mode : false
2020-05-02 12:30:56,230 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:56,231 INFO  mapreduce.Job - Job job_local947088815_0002 completed successfully
2020-05-02 12:30:56,235 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5576026
		FILE: Number of bytes written=8956949
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:30:56,256 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:30:56, elapsed: 00:00:03
2020-05-02 12:30:57,220 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 12:30:57
2020-05-02 12:30:57,478 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:58,799 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:58,800 INFO  mapreduce.Job - Running job: job_local1223872680_0001
2020-05-02 12:30:59,805 INFO  mapreduce.Job - Job job_local1223872680_0001 running in uber mode : false
2020-05-02 12:30:59,806 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:59,807 INFO  mapreduce.Job - Job job_local1223872680_0001 completed successfully
2020-05-02 12:30:59,823 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2812628
		FILE: Number of bytes written=4485870
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=2
		Map output bytes=526
		Map output materialized bytes=544
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=544
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11307
	File Output Format Counters 
		Bytes Written=98
2020-05-02 12:30:59,829 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 12:30:59,829 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 12:31:00,131 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:31:00,131 INFO  mapreduce.Job - Running job: job_local1351690861_0002
2020-05-02 12:31:01,131 INFO  mapreduce.Job - Job job_local1351690861_0002 running in uber mode : false
2020-05-02 12:31:01,132 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:31:01,132 INFO  mapreduce.Job - Job job_local1351690861_0002 completed successfully
2020-05-02 12:31:01,137 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7533952
		FILE: Number of bytes written=12014349
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10163
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10163
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11405
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:31:01,160 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 12:31:01, elapsed: 00:00:03
2020-05-02 12:31:02,336 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:31:02,805 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123035.
2020-05-02 12:31:02,812 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:31:02
2020-05-02 12:31:02,839 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 12:31:02,843 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 12:31:02,843 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 12:31:02,845 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:31:02,845 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:31:02,845 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123035
2020-05-02 12:31:03,846 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:31:03,846 INFO  mapreduce.Job - Running job: job_local278292428_0001
2020-05-02 12:31:04,854 INFO  mapreduce.Job - Job job_local278292428_0001 running in uber mode : false
2020-05-02 12:31:04,856 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:31:05,437 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:31:05,468 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:31:05,789 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 12:31:06,406 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 12:31:06,419 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:31:06,427 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:31:06,431 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:31:06,432 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:31:06,866 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:31:06,866 INFO  mapreduce.Job - Job job_local278292428_0001 completed successfully
2020-05-02 12:31:06,891 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10918898
		FILE: Number of bytes written=17314239
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=343
		Map output records=343
		Map output bytes=77719
		Map output materialized bytes=78477
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=78477
		Reduce input records=343
		Reduce output records=2
		Spilled Records=686
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=249
		Total committed heap usage (bytes)=4905762816
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47833
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:31:06,892 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:31:06,898 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:31:06,936 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:31:06, elapsed: 00:00:04
2020-05-02 12:31:08,233 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 12:31:08
2020-05-02 12:31:08,490 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:31:09,647 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:31:09,647 INFO  mapreduce.Job - Running job: job_local691215537_0001
2020-05-02 12:31:10,536 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:31:10,563 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:31:10,654 INFO  mapreduce.Job - Job job_local691215537_0001 running in uber mode : false
2020-05-02 12:31:10,656 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:31:11,139 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 12:31:11,662 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:31:11,662 INFO  mapreduce.Job - Job job_local691215537_0001 completed successfully
2020-05-02 12:31:11,677 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1877012
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=109
		Total committed heap usage (bytes)=485490688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:31:11,697 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 12:31:11, elapsed: 00:00:03
2020-05-02 12:32:28,857 INFO  crawl.Injector - Injector: starting at 2020-05-02 12:32:28
2020-05-02 12:32:28,858 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 12:32:28,859 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 12:32:28,859 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 12:32:29,077 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:29,553 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 12:32:30,720 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:30,721 INFO  mapreduce.Job - Running job: job_local814469525_0001
2020-05-02 12:32:31,156 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 12:32:31,326 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 12:32:31,326 INFO  crawl.Injector - Injector: update: false
2020-05-02 12:32:31,731 INFO  mapreduce.Job - Job job_local814469525_0001 running in uber mode : false
2020-05-02 12:32:31,733 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:31,734 INFO  mapreduce.Job - Job job_local814469525_0001 completed successfully
2020-05-02 12:32:31,746 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855256
		FILE: Number of bytes written=2982521
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=136
		Map output materialized bytes=146
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=146
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=493
2020-05-02 12:32:31,756 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 12:32:31,756 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 12:32:31,756 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 12:32:31,757 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 12:32:31,777 INFO  crawl.Injector - Injector: finished at 2020-05-02 12:32:31, elapsed: 00:00:02
2020-05-02 12:32:32,781 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:33,158 INFO  crawl.Generator - Generator: starting at 2020-05-02 12:32:33
2020-05-02 12:32:33,158 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 12:32:33,158 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 12:32:33,159 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 12:32:33,161 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 12:32:34,678 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:34,679 INFO  mapreduce.Job - Running job: job_local582083460_0001
2020-05-02 12:32:35,540 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:32:35,542 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:32:35,542 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:32:35,548 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 12:32:35,682 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 12:32:35,707 INFO  mapreduce.Job - Job job_local582083460_0001 running in uber mode : false
2020-05-02 12:32:35,709 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:32:36,712 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:36,713 INFO  mapreduce.Job - Job job_local582083460_0001 completed successfully
2020-05-02 12:32:36,727 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783168
		FILE: Number of bytes written=4485734
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=194
		Map output materialized bytes=116
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=116
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=250
	File Output Format Counters 
		Bytes Written=16
2020-05-02 12:32:36,727 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 12:32:36,732 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 12:32:37,738 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502123237
2020-05-02 12:32:37,989 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:37,989 INFO  mapreduce.Job - Running job: job_local792648426_0002
2020-05-02 12:32:38,995 INFO  mapreduce.Job - Job job_local792648426_0002 running in uber mode : false
2020-05-02 12:32:38,995 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:38,996 INFO  mapreduce.Job - Job job_local792648426_0002 completed successfully
2020-05-02 12:32:39,011 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3711250
		FILE: Number of bytes written=5976444
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=264
		Map output materialized bytes=106
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=106
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=330
	File Output Format Counters 
		Bytes Written=292
2020-05-02 12:32:39,030 INFO  crawl.Generator - Generator: finished at 2020-05-02 12:32:39, elapsed: 00:00:05
2020-05-02 12:32:40,156 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 12:32:40
2020-05-02 12:32:40,158 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502123237
2020-05-02 12:32:40,160 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588408360159  (2020-05-02 15:32:40)
2020-05-02 12:32:40,368 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:41,443 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:41,443 INFO  mapreduce.Job - Running job: job_local694669425_0001
2020-05-02 12:32:41,631 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 12:32:41,631 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 12:32:41,631 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 12:32:41,641 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records hit by time limit : 0
2020-05-02 12:32:41,892 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:41,916 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:41,916 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:41,917 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 12:32:42,132 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 12:32:42,134 INFO  http.Http - http.proxy.host = null
2020-05-02 12:32:42,134 INFO  http.Http - http.proxy.port = 8080
2020-05-02 12:32:42,135 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 12:32:42,135 INFO  http.Http - http.timeout = 30000
2020-05-02 12:32:42,135 INFO  http.Http - http.content.limit = -1
2020-05-02 12:32:42,135 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 12:32:42,135 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 12:32:42,135 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 12:32:42,135 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 12:32:42,135 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,147 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,148 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,148 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,149 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,150 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,151 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,152 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,154 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,154 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,155 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,156 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,156 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,157 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,158 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,159 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,160 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,161 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,162 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,163 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,164 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,165 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,165 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,166 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,168 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,168 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,169 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,169 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,170 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,170 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,171 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,172 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,172 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,173 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,173 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,175 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,176 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,177 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,177 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,178 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,180 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,181 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,182 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,182 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,183 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,183 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,184 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,184 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,185 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,186 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,186 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,187 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,188 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,189 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,190 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,192 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,194 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,195 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,197 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,198 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,198 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,200 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,201 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,202 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,203 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,207 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,207 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,209 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,209 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,210 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,211 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,211 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,214 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,214 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,215 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,215 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,216 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,217 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,218 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,219 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,220 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,220 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,221 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,222 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,222 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,223 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,223 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 12:32:42,224 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 12:32:42,224 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 12:32:42,453 INFO  mapreduce.Job - Job job_local694669425_0001 running in uber mode : false
2020-05-02 12:32:42,454 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:32:43,228 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588397561640
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   now           = 1588397563229
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-se/specs/
2020-05-02 12:32:43,770 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=49
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=48
2020-05-02 12:32:44,161 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=47
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=45
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=41
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=43
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=46
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=42
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=39
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=38
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 12:32:44,181 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 12:32:44,181 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=35
2020-05-02 12:32:44,181 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=36
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=40
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 12:32:44,182 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=34
2020-05-02 12:32:44,183 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 12:32:44,183 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=33
2020-05-02 12:32:44,190 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 12:32:44,190 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=32
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=30
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=29
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 12:32:44,193 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=28
2020-05-02 12:32:44,193 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=27
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=31
2020-05-02 12:32:44,193 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=26
2020-05-02 12:32:44,200 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=24
2020-05-02 12:32:44,200 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 12:32:44,200 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=23
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=25
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=22
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 12:32:44,209 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=20
2020-05-02 12:32:44,209 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=19
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=21
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=18
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=17
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=15
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=16
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=14
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=13
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 12:32:44,220 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=12
2020-05-02 12:32:44,223 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=10
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=8
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=9
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=11
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=7
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=6
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 12:32:44,227 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=5
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 12:32:44,227 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=4
2020-05-02 12:32:44,230 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 12:32:44,230 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 12:32:44,231 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=2
2020-05-02 12:32:44,231 INFO  fetcher.Fetcher - -activeThreads=2, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 12:32:44,230 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 12:32:44,231 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:32:44,231 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=3
2020-05-02 12:32:44,921 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 12:32:44,921 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=0
2020-05-02 12:32:45,234 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 12:32:45,234 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 12:32:45,465 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 12:32:46,466 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:46,467 INFO  mapreduce.Job - Job job_local694669425_0001 completed successfully
2020-05-02 12:32:46,491 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2869161
		FILE: Number of bytes written=4667882
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=235541
		Map output materialized bytes=39056
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=39056
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=967311360
	FetcherStatus
		bytes_downloaded=233595
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=292
	File Output Format Counters 
		Bytes Written=41233
2020-05-02 12:32:46,492 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 12:32:46, elapsed: 00:00:06
2020-05-02 12:32:47,505 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:47,854 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:32:47
2020-05-02 12:32:47,863 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 12:32:48,712 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:48,713 INFO  mapreduce.Job - Running job: job_local1163383892_0001
2020-05-02 12:32:49,721 INFO  mapreduce.Job - Job job_local1163383892_0001 running in uber mode : false
2020-05-02 12:32:49,722 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:32:50,143 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:32:50,149 INFO  parse.ParseSegment - Parsed (964ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:32:50,246 INFO  parse.ParseSegment - Parsed (91ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:32:50,430 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:50,546 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:50,630 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:32:50,725 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:50,726 INFO  mapreduce.Job - Job job_local1163383892_0001 completed successfully
2020-05-02 12:32:50,745 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3922372
		FILE: Number of bytes written=6121332
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=73509
		Map output materialized bytes=22016
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=22016
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=1599602688
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:32:50,760 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:32:50, elapsed: 00:00:02
2020-05-02 12:32:51,854 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:52,286 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:32:52
2020-05-02 12:32:52,286 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:32:52,286 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502123237]
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:32:52,289 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:32:53,115 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:53,116 INFO  mapreduce.Job - Running job: job_local1976587974_0001
2020-05-02 12:32:54,092 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:32:54,092 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:32:54,092 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:32:54,122 INFO  mapreduce.Job - Job job_local1976587974_0001 running in uber mode : false
2020-05-02 12:32:54,123 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:54,161 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:32:54,161 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:32:54,161 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:32:55,128 INFO  mapreduce.Job - Job job_local1976587974_0001 completed successfully
2020-05-02 12:32:55,145 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6630934
		FILE: Number of bytes written=10487358
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=206
		Map output records=206
		Map output bytes=15039
		Map output materialized bytes=1492
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=1492
		Reduce input records=206
		Reduce output records=134
		Spilled Records=412
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16738
	File Output Format Counters 
		Bytes Written=11780
2020-05-02 12:32:55,161 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:32:55, elapsed: 00:00:02
2020-05-02 12:32:56,274 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:56,626 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:32:56
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502123237
2020-05-02 12:32:57,427 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:57,428 INFO  mapreduce.Job - Running job: job_local1984024131_0001
2020-05-02 12:32:58,435 INFO  mapreduce.Job - Job job_local1984024131_0001 running in uber mode : false
2020-05-02 12:32:58,436 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:58,438 INFO  mapreduce.Job - Job job_local1984024131_0001 completed successfully
2020-05-02 12:32:58,450 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2791318
		FILE: Number of bytes written=4481375
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=332
		Combine input records=1
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2711
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:32:58,451 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:32:58,718 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:58,718 INFO  mapreduce.Job - Running job: job_local235983396_0002
2020-05-02 12:32:59,057 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:32:59,136 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:32:59,724 INFO  mapreduce.Job - Job job_local235983396_0002 running in uber mode : false
2020-05-02 12:32:59,724 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:59,725 INFO  mapreduce.Job - Job job_local235983396_0002 completed successfully
2020-05-02 12:32:59,728 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5576833
		FILE: Number of bytes written=8956943
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:32:59,748 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:32:59, elapsed: 00:00:03
2020-05-02 12:33:00,811 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 12:33:00
2020-05-02 12:33:01,079 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:33:02,308 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:02,309 INFO  mapreduce.Job - Running job: job_local975607059_0001
2020-05-02 12:33:03,318 INFO  mapreduce.Job - Job job_local975607059_0001 running in uber mode : false
2020-05-02 12:33:03,319 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:03,320 INFO  mapreduce.Job - Job job_local975607059_0001 completed successfully
2020-05-02 12:33:03,337 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2812628
		FILE: Number of bytes written=4477680
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=2
		Map output bytes=526
		Map output materialized bytes=544
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=544
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11307
	File Output Format Counters 
		Bytes Written=98
2020-05-02 12:33:03,342 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 12:33:03,342 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 12:33:03,624 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:03,625 INFO  mapreduce.Job - Running job: job_local1590328680_0002
2020-05-02 12:33:04,625 INFO  mapreduce.Job - Job job_local1590328680_0002 running in uber mode : false
2020-05-02 12:33:04,626 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:04,626 INFO  mapreduce.Job - Job job_local1590328680_0002 completed successfully
2020-05-02 12:33:04,631 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7533952
		FILE: Number of bytes written=12003437
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10163
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10163
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11405
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:33:04,659 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 12:33:04, elapsed: 00:00:03
2020-05-02 12:33:05,855 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:33:06,257 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 12:33:06,261 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:33:06
2020-05-02 12:33:06,277 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 12:33:06,278 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 12:33:06,278 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 12:33:06,279 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:33:06,279 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:33:06,279 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 12:33:07,203 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:07,204 INFO  mapreduce.Job - Running job: job_local1345408470_0001
2020-05-02 12:33:08,211 INFO  mapreduce.Job - Job job_local1345408470_0001 running in uber mode : false
2020-05-02 12:33:08,212 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:33:08,818 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:33:08,853 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:33:09,212 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 12:33:09,765 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:33:09,765 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:33:10,219 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:10,219 INFO  mapreduce.Job - Job job_local1345408470_0001 completed successfully
2020-05-02 12:33:10,243 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10922547
		FILE: Number of bytes written=17351041
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=343
		Map output records=343
		Map output bytes=78469
		Map output materialized bytes=79227
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=79227
		Reduce input records=343
		Reduce output records=2
		Spilled Records=686
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=258
		Total committed heap usage (bytes)=4902617088
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=48102
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:33:10,243 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:33:10,251 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:33:10,270 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:33:10, elapsed: 00:00:03
2020-05-02 12:33:11,343 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 12:33:11
2020-05-02 12:33:11,556 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:33:12,729 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:12,730 INFO  mapreduce.Job - Running job: job_local1698280545_0001
2020-05-02 12:33:13,288 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:33:13,310 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:33:13,641 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 12:33:13,737 INFO  mapreduce.Job - Job job_local1698280545_0001 running in uber mode : false
2020-05-02 12:33:13,738 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:13,739 INFO  mapreduce.Job - Job job_local1698280545_0001 completed successfully
2020-05-02 12:33:13,756 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1877012
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=64
		Total committed heap usage (bytes)=480247808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:33:13,773 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 12:33:13, elapsed: 00:00:02
2020-05-02 12:34:54,673 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:34:55,001 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:34:54
2020-05-02 12:34:55,016 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 12:34:55,973 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:34:55,974 INFO  mapreduce.Job - Running job: job_local2091542275_0001
2020-05-02 12:34:56,994 INFO  mapreduce.Job - Job job_local2091542275_0001 running in uber mode : false
2020-05-02 12:34:56,995 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:34:57,495 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:34:57,512 INFO  parse.ParseSegment - Parsed (1077ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:34:57,594 INFO  parse.ParseSegment - Parsed (73ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:34:57,790 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:34:57,891 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:34:58,001 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:34:58,002 INFO  mapreduce.Job - Job job_local2091542275_0001 completed successfully
2020-05-02 12:34:58,021 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051485
		FILE: Number of bytes written=4815453
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74589
		Map output materialized bytes=74609
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74609
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=70
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:34:58,039 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:34:58, elapsed: 00:00:03
2020-05-02 12:34:59,135 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:34:59
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502123237]
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:34:59,523 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:35:00,310 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:00,310 INFO  mapreduce.Job - Running job: job_local818564524_0001
2020-05-02 12:35:01,176 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:35:01,177 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:35:01,177 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:35:01,319 INFO  mapreduce.Job - Job job_local818564524_0001 running in uber mode : false
2020-05-02 12:35:01,320 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:01,321 INFO  mapreduce.Job - Job job_local818564524_0001 completed successfully
2020-05-02 12:35:01,336 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=4821180
		FILE: Number of bytes written=7607986
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=338
		Map output records=338
		Map output bytes=24778
		Map output materialized bytes=25482
		Input split bytes=643
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=25482
		Reduce input records=338
		Reduce output records=134
		Spilled Records=676
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=2290614272
	CrawlDB status
		db_notmodified=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27570
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:35:01,358 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:35:01, elapsed: 00:00:01
2020-05-02 12:35:02,542 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:35:03,054 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:35:03
2020-05-02 12:35:03,054 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:35:03,054 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:35:03,055 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:35:03,055 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:35:03,055 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502123237
2020-05-02 12:35:03,057 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502123035
2020-05-02 12:35:03,058 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:35:03,058 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502122427
2020-05-02 12:35:03,923 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:03,924 INFO  mapreduce.Job - Running job: job_local1609115478_0001
2020-05-02 12:35:04,932 INFO  mapreduce.Job - Job job_local1609115478_0001 running in uber mode : false
2020-05-02 12:35:04,934 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:35:05,936 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:05,936 INFO  mapreduce.Job - Job job_local1609115478_0001 completed successfully
2020-05-02 12:35:05,959 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8494100
		FILE: Number of bytes written=13461278
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=5
		Map output bytes=430
		Map output materialized bytes=488
		Input split bytes=1328
		Combine input records=5
		Combine output records=5
		Reduce input groups=1
		Reduce shuffle bytes=488
		Reduce input records=5
		Reduce output records=1
		Spilled Records=10
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=126
		Total committed heap usage (bytes)=3997696000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14103
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:35:05,959 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:35:06,322 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:06,323 INFO  mapreduce.Job - Running job: job_local1707203967_0002
2020-05-02 12:35:06,569 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:35:06,647 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:35:07,325 INFO  mapreduce.Job - Job job_local1707203967_0002 running in uber mode : false
2020-05-02 12:35:07,326 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:07,326 INFO  mapreduce.Job - Job job_local1707203967_0002 completed successfully
2020-05-02 12:35:07,331 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5636847
		FILE: Number of bytes written=8972789
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1003487232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:35:07,349 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:35:07, elapsed: 00:00:04
2020-05-02 12:35:08,594 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:35:09,022 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 12:35:09,026 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:35:09
2020-05-02 12:35:09,046 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:35:09,049 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:35:09,049 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:35:09,051 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:35:09,052 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:35:09,052 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 12:35:09,968 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:09,968 INFO  mapreduce.Job - Running job: job_local136365703_0001
2020-05-02 12:35:10,486 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,590 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,709 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,843 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,945 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,978 INFO  mapreduce.Job - Job job_local136365703_0001 running in uber mode : false
2020-05-02 12:35:10,980 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:35:11,044 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:11,126 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:11,169 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:11,316 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:35:11,344 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:35:11,767 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 12:35:12,356 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:35:12,357 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:35:12,985 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:12,986 INFO  mapreduce.Job - Job job_local136365703_0001 completed successfully
2020-05-02 12:35:13,021 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10175046
		FILE: Number of bytes written=16199521
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132815
		Map output materialized bytes=133583
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133583
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=158
		Total committed heap usage (bytes)=6192365568
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68280
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:35:13,021 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:35:13,032 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:35:13,057 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:35:13, elapsed: 00:00:04
2020-05-02 13:51:21,083 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:51:21,540 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 13:51:21
2020-05-02 13:51:21,553 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 13:51:22,766 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:51:22,767 INFO  mapreduce.Job - Running job: job_local1584879996_0001
2020-05-02 13:51:23,776 INFO  mapreduce.Job - Job job_local1584879996_0001 running in uber mode : false
2020-05-02 13:51:23,778 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 13:51:24,511 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
org.jsoup.select.Selector$SelectorParseException: Could not parse query 'li:nth-child': unexpected token at ':nth-child'
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:196)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:65)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.QueryParser.combinator(QueryParser.java:81)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:61)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 13:51:24,517 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 13:51:24,527 INFO  parse.ParseSegment - Parsed (1238ms):https://www.apple.com/iphone-11/specs/
2020-05-02 13:51:24,653 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
org.jsoup.select.Selector$SelectorParseException: Could not parse query 'li:nth-child': unexpected token at ':nth-child'
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:196)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:65)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.QueryParser.combinator(QueryParser.java:81)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:61)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 13:51:24,654 INFO  parse.ParseSegment - Parsed (121ms):https://www.apple.com/iphone-se/specs/
2020-05-02 13:51:24,781 INFO  mapreduce.Job -  map 50% reduce 0%
2020-05-02 13:51:24,910 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 13:51:25,030 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 13:51:25,784 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:51:25,785 INFO  mapreduce.Job - Job job_local1584879996_0001 completed successfully
2020-05-02 13:51:25,807 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3047825
		FILE: Number of bytes written=4806997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=72779
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=72779
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=93
		Total committed heap usage (bytes)=1094713344
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:51:25,827 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 13:51:25, elapsed: 00:00:04
2020-05-02 13:51:30,058 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:51:30,470 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 13:51:30,473 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 13:51:30
2020-05-02 13:51:30,490 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 13:51:30,491 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 13:51:30,491 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 13:51:30,494 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 13:51:30,494 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 13:51:30,494 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 13:51:31,417 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:51:31,418 INFO  mapreduce.Job - Running job: job_local1354606022_0001
2020-05-02 13:51:31,880 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:31,968 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,053 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,308 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,406 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,427 INFO  mapreduce.Job - Job job_local1354606022_0001 running in uber mode : false
2020-05-02 13:51:32,429 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 13:51:32,479 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,561 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,599 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,745 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 13:51:32,771 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 13:51:33,190 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 13:51:33,793 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 13:51:33,794 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 13:51:34,437 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:51:34,438 INFO  mapreduce.Job - Job job_local1354606022_0001 completed successfully
2020-05-02 13:51:34,457 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10164606
		FILE: Number of bytes written=16214801
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130985
		Map output materialized bytes=131753
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131753
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=151
		Total committed heap usage (bytes)=6202851328
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=67144
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:51:34,458 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 13:51:34,470 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 13:51:34,491 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 13:51:34, elapsed: 00:00:04
2020-05-02 13:55:27,978 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:55:28,376 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 13:55:28
2020-05-02 13:55:28,377 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 13:55:29,515 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:55:29,516 INFO  mapreduce.Job - Running job: job_local561342441_0001
2020-05-02 13:55:30,524 INFO  mapreduce.Job - Job job_local561342441_0001 running in uber mode : false
2020-05-02 13:55:30,526 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 13:55:31,677 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 13:55:31,685 INFO  parse.ParseSegment - Parsed (1342ms):https://www.apple.com/iphone-11/specs/
2020-05-02 13:55:31,823 INFO  parse.ParseSegment - Parsed (132ms):https://www.apple.com/iphone-se/specs/
2020-05-02 13:55:32,098 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 13:55:32,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 13:55:32,535 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:55:32,536 INFO  mapreduce.Job - Job job_local561342441_0001 completed successfully
2020-05-02 13:55:32,551 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051477
		FILE: Number of bytes written=4807251
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74585
		Map output materialized bytes=74605
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74605
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=85
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:55:32,565 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 13:55:32, elapsed: 00:00:04
2020-05-02 13:55:34,937 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:55:35,287 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 13:55:35,290 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 13:55:35
2020-05-02 13:55:35,300 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 13:55:35,300 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 13:55:35,300 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 13:55:35,302 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 13:55:35,302 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 13:55:35,302 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 13:55:36,213 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:55:36,213 INFO  mapreduce.Job - Running job: job_local1727010_0001
2020-05-02 13:55:36,673 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:36,775 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:36,944 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,175 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,219 INFO  mapreduce.Job - Job job_local1727010_0001 running in uber mode : false
2020-05-02 13:55:37,220 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 13:55:37,381 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,443 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,587 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,629 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,782 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 13:55:37,819 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 13:55:38,249 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 13:55:38,832 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 13:55:38,833 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 13:55:39,227 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:55:39,228 INFO  mapreduce.Job - Job job_local1727010_0001 completed successfully
2020-05-02 13:55:39,248 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10174864
		FILE: Number of bytes written=16144813
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132811
		Map output materialized bytes=133579
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133579
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=152
		Total committed heap usage (bytes)=6239551488
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68266
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:55:39,248 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 13:55:39,256 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 13:55:39,274 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 13:55:39, elapsed: 00:00:03
2020-05-02 14:12:07,926 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:12:08,451 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:12:08
2020-05-02 14:12:08,451 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:12:09,625 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:12:09,626 INFO  mapreduce.Job - Running job: job_local980336322_0001
2020-05-02 14:12:10,636 INFO  mapreduce.Job - Job job_local980336322_0001 running in uber mode : false
2020-05-02 14:12:10,637 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:12:11,647 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleEndElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.endElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.endElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.endElement(ValidatingUnmarshaller.java:106)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.endElement(SAXConnector.java:160)
	at org.apache.xerces.parsers.AbstractSAXParser.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 14:12:11,928 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 14:12:11,932 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:12:11,941 INFO  parse.ParseSegment - Parsed (1648ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:12:12,011 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 14:12:12,016 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:12:12,260 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:12:12,390 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:12:12,648 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:12:12,649 INFO  mapreduce.Job - Job job_local980336322_0001 completed successfully
2020-05-02 14:12:12,668 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3047825
		FILE: Number of bytes written=4798851
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=72779
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=72779
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=118
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:12:12,686 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:12:12, elapsed: 00:00:04
2020-05-02 14:12:14,608 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:12:15,018 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:12:15,021 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:12:15
2020-05-02 14:12:15,030 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:12:15,030 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:12:15,030 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:12:15,031 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:12:15,031 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:12:15,031 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:12:15,887 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:12:15,888 INFO  mapreduce.Job - Running job: job_local1180867473_0001
2020-05-02 14:12:16,345 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,433 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,509 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,749 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,865 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,894 INFO  mapreduce.Job - Job job_local1180867473_0001 running in uber mode : false
2020-05-02 14:12:16,896 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:12:17,032 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:17,107 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:17,144 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:17,262 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:12:17,288 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:12:17,683 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 14:12:18,175 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleEndElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.endElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.endElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.endElement(ValidatingUnmarshaller.java:106)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.endElement(SAXConnector.java:160)
	at org.apache.xerces.parsers.AbstractSAXParser.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 14:12:18,187 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 14:12:18,194 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 14:12:18,198 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:12:18,201 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:12:18,901 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:12:18,901 INFO  mapreduce.Job - Job job_local1180867473_0001 completed successfully
2020-05-02 14:12:18,923 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10164814
		FILE: Number of bytes written=16214821
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130985
		Map output materialized bytes=131753
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131753
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=171
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=67170
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:12:18,924 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:12:18,930 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:12:18,946 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:12:18, elapsed: 00:00:03
2020-05-02 14:13:05,302 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:13:05,637 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:13:05
2020-05-02 14:13:05,638 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:13:06,404 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:13:06,405 INFO  mapreduce.Job - Running job: job_local1171411644_0001
2020-05-02 14:13:07,411 INFO  mapreduce.Job - Job job_local1171411644_0001 running in uber mode : false
2020-05-02 14:13:07,412 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:13:07,891 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:13:07,898 INFO  parse.ParseSegment - Parsed (1037ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:13:08,041 INFO  parse.ParseSegment - Parsed (137ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:13:08,251 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:13:08,361 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:13:08,415 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:13:09,422 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:13:09,422 INFO  mapreduce.Job - Job job_local1171411644_0001 completed successfully
2020-05-02 14:13:09,436 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051437
		FILE: Number of bytes written=4815187
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74565
		Map output materialized bytes=74585
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74585
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:13:09,453 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:13:09, elapsed: 00:00:03
2020-05-02 14:13:12,006 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:13:12,340 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:13:12,346 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:13:12
2020-05-02 14:13:12,365 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:13:12,369 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:13:12,369 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:13:12,370 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:13:12,370 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:13:12,371 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:13:13,315 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:13:13,316 INFO  mapreduce.Job - Running job: job_local144629722_0001
2020-05-02 14:13:13,765 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:13,857 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:13,943 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,170 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,267 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,327 INFO  mapreduce.Job - Job job_local144629722_0001 running in uber mode : false
2020-05-02 14:13:14,327 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:13:14,351 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,409 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,447 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,597 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:13:14,627 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:13:15,052 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 14:13:15,692 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:13:15,706 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:13:16,334 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:13:16,335 INFO  mapreduce.Job - Job job_local144629722_0001 completed successfully
2020-05-02 14:13:16,362 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10173574
		FILE: Number of bytes written=16199373
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132791
		Map output materialized bytes=133559
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133559
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=167
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68110
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:13:16,362 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:13:16,369 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:13:16,388 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:13:16, elapsed: 00:00:04
2020-05-02 14:16:41,512 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:16:41,993 WARN  parse.ParseSegment - Segment: crawl/segments/20200502123237 already parsed!! Skipped parsing this segment!!
2020-05-02 14:16:57,891 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:16:58,264 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:16:58
2020-05-02 14:16:58,265 INFO  parse.ParseSegment - ParseSegment: segment: -h
2020-05-02 14:16:58,617 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/-h/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:261)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:308)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:280)

2020-05-02 14:18:01,756 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:18:02,086 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:18:02
2020-05-02 14:18:02,087 INFO  parse.ParseSegment - ParseSegment: segment: -h
2020-05-02 14:18:02,532 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/-h/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:261)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:308)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:280)

2020-05-02 14:18:19,943 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:18:20,303 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:18:20
2020-05-02 14:18:20,303 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:18:21,173 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:18:21,175 INFO  mapreduce.Job - Running job: job_local1591981312_0001
2020-05-02 14:18:22,181 INFO  mapreduce.Job - Job job_local1591981312_0001 running in uber mode : false
2020-05-02 14:18:22,182 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:18:22,740 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:18:22,758 INFO  parse.ParseSegment - Parsed (1118ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:18:22,912 INFO  parse.ParseSegment - Parsed (147ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:18:23,130 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:18:23,185 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:18:23,244 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:18:24,188 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:18:24,189 INFO  mapreduce.Job - Job job_local1591981312_0001 completed successfully
2020-05-02 14:18:24,204 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051437
		FILE: Number of bytes written=4815188
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74565
		Map output materialized bytes=74585
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74585
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=73
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:18:24,221 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:18:24, elapsed: 00:00:03
2020-05-02 14:18:26,506 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:18:26,872 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:18:26,875 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:18:26
2020-05-02 14:18:26,886 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:18:26,886 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:18:26,886 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:18:26,890 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:18:26,890 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:18:26,890 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:18:27,758 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:18:27,759 INFO  mapreduce.Job - Running job: job_local747192086_0001
2020-05-02 14:18:28,218 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,315 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,422 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,621 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,728 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,765 INFO  mapreduce.Job - Job job_local747192086_0001 running in uber mode : false
2020-05-02 14:18:28,766 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:18:28,842 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,918 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,966 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:29,114 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:18:29,142 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:18:29,597 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 14:18:30,248 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:18:30,249 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:18:30,780 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:18:30,780 INFO  mapreduce.Job - Job job_local747192086_0001 completed successfully
2020-05-02 14:18:30,798 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10173582
		FILE: Number of bytes written=16199373
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132791
		Map output materialized bytes=133559
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133559
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=165
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68111
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:18:30,799 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:18:30,809 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:18:30,834 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:18:30, elapsed: 00:00:03
2020-05-02 14:24:56,001 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:24:56,355 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:24:56
2020-05-02 14:24:56,355 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:24:57,345 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:24:57,346 INFO  mapreduce.Job - Running job: job_local659961292_0001
2020-05-02 14:24:58,354 INFO  mapreduce.Job - Job job_local659961292_0001 running in uber mode : false
2020-05-02 14:24:58,355 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:24:58,814 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:24:58,824 INFO  parse.ParseSegment - Parsed (1038ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:24:58,940 INFO  parse.ParseSegment - Parsed (110ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:24:59,139 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:24:59,236 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:24:59,362 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:24:59,363 INFO  mapreduce.Job - Job job_local659961292_0001 completed successfully
2020-05-02 14:24:59,378 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051437
		FILE: Number of bytes written=4807115
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74565
		Map output materialized bytes=74585
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74585
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=90
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:24:59,397 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:24:59, elapsed: 00:00:03
2020-05-02 14:25:07,074 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:25:07,621 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:25:07,623 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:25:07
2020-05-02 14:25:07,648 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:25:07,650 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:25:07,650 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:25:07,652 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:25:07,652 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:25:07,652 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:25:08,949 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:25:08,950 INFO  mapreduce.Job - Running job: job_local1564197029_0001
2020-05-02 14:25:09,480 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:09,612 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:09,857 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:09,959 INFO  mapreduce.Job - Job job_local1564197029_0001 running in uber mode : false
2020-05-02 14:25:09,960 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:25:10,072 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,260 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,315 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,402 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,453 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,630 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:25:10,661 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:25:11,446 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 14:25:12,351 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:25:12,352 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:25:12,974 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:25:12,974 INFO  mapreduce.Job - Job job_local1564197029_0001 completed successfully
2020-05-02 14:25:12,998 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10174374
		FILE: Number of bytes written=16226713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132791
		Map output materialized bytes=133559
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133559
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=217
		Total committed heap usage (bytes)=6242172928
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68210
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:25:12,998 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:25:13,006 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:25:13,025 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:25:13, elapsed: 00:00:05
2020-05-02 17:22:44,794 INFO  util.SitemapProcessor - SitemapProcessor: sitemap urls dir: urls
2020-05-02 17:22:44,795 INFO  util.SitemapProcessor - SitemapProcessor: threads: 50
2020-05-02 17:22:44,795 INFO  util.SitemapProcessor - SitemapProcessor: Starting at 2020-05-02 17:22:44
2020-05-02 17:22:44,968 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:22:46,573 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:46,574 INFO  mapreduce.Job - Running job: job_local515781573_0001
2020-05-02 17:22:47,514 INFO  regex.RegexURLNormalizer - can't find rules for scope 'default', using default
2020-05-02 17:22:47,585 INFO  mapreduce.Job - Job job_local515781573_0001 running in uber mode : false
2020-05-02 17:22:47,586 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:22:47,809 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:22:47,818 INFO  http.Http - http.proxy.host = null
2020-05-02 17:22:47,818 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:22:47,818 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:22:47,818 INFO  http.Http - http.timeout = 30000
2020-05-02 17:22:47,818 INFO  http.Http - http.content.limit = -1
2020-05-02 17:22:47,818 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:22:47,818 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:22:47,818 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:22:47,818 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:22:49,006 INFO  util.SitemapProcessor - Parsing sitemap file: https://www.apple.com/sitemap.xml
2020-05-02 17:22:49,594 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:22:49,594 INFO  mapreduce.Job - Job job_local515781573_0001 completed successfully
2020-05-02 17:22:49,611 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2838622
		FILE: Number of bytes written=4525994
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=135
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10157
		Input split bytes=614
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10157
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=119
		Total committed heap usage (bytes)=919601152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	Sitemap
		existing_sitemap_entries=134
		sitemap_seeds=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 17:22:49,632 INFO  util.SitemapProcessor - SitemapProcessor: Total records rejected by filters: 0
2020-05-02 17:22:49,632 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from host name: 0
2020-05-02 17:22:49,632 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from seed urls: 1
2020-05-02 17:22:49,633 INFO  util.SitemapProcessor - SitemapProcessor: Total failed sitemap fetches: 0
2020-05-02 17:22:49,633 INFO  util.SitemapProcessor - SitemapProcessor: Total new sitemap entries added: 0
2020-05-02 17:22:49,634 INFO  util.SitemapProcessor - SitemapProcessor: Finished at 2020-05-02 17:22:49, elapsed: 00:00:04
2020-05-02 17:22:51,130 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: starting at 2020-05-02 17:22:51
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 17:22:51,572 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 17:22:52,485 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:52,487 INFO  mapreduce.Job - Running job: job_local1699725899_0001
2020-05-02 17:22:53,328 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:22:53,329 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:22:53,329 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:22:53,338 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 17:22:53,497 INFO  mapreduce.Job - Job job_local1699725899_0001 running in uber mode : false
2020-05-02 17:22:53,498 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:22:53,567 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:22:53,703 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:22:54,502 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:22:54,503 INFO  mapreduce.Job - Job job_local1699725899_0001 completed successfully
2020-05-02 17:22:54,524 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2819156
		FILE: Number of bytes written=4526369
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=132
		Map output bytes=13247
		Map output materialized bytes=878
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=878
		Reduce input records=132
		Reduce output records=0
		Spilled Records=264
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=805306368
	Generator
		SCHEDULE_REJECTED=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=16
2020-05-02 17:22:54,524 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 17:22:54,527 INFO  crawl.Generator - Generator:      2  SCHEDULE_REJECTED
2020-05-02 17:22:54,529 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 17:22:55,529 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502172255
2020-05-02 17:22:55,813 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:55,814 INFO  mapreduce.Job - Running job: job_local752281513_0002
2020-05-02 17:22:56,818 INFO  mapreduce.Job - Job job_local752281513_0002 running in uber mode : false
2020-05-02 17:22:56,818 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:22:56,819 INFO  mapreduce.Job - Job job_local752281513_0002 completed successfully
2020-05-02 17:22:56,825 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5651408
		FILE: Number of bytes written=9039336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=132
		Map output records=132
		Map output bytes=18310
		Map output materialized bytes=1344
		Input split bytes=366
		Combine input records=0
		Combine output records=0
		Reduce input groups=132
		Reduce shuffle bytes=1344
		Reduce input records=132
		Reduce output records=132
		Spilled Records=264
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1332215808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14775
	File Output Format Counters 
		Bytes Written=13569
2020-05-02 17:22:56,927 INFO  crawl.Generator - Generator: finished at 2020-05-02 17:22:56, elapsed: 00:00:05
2020-05-02 17:22:58,029 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 17:22:57
2020-05-02 17:22:58,030 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502172255
2020-05-02 17:22:58,030 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588425778030  (2020-05-02 20:22:58)
2020-05-02 17:22:58,270 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:22:59,421 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:59,422 INFO  mapreduce.Job - Running job: job_local1299448771_0001
2020-05-02 17:22:59,604 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 17:22:59,604 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 17:22:59,605 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 17:22:59,652 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 132 records hit by time limit : 0
2020-05-02 17:22:59,994 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,015 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,025 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,025 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com.cn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:00,273 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:23:00,277 INFO  http.Http - http.proxy.host = null
2020-05-02 17:23:00,277 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:23:00,277 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:23:00,277 INFO  http.Http - http.timeout = 30000
2020-05-02 17:23:00,278 INFO  http.Http - http.content.limit = -1
2020-05-02 17:23:00,278 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:23:00,278 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:23:00,278 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:23:00,278 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:23:00,278 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,280 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/ie/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:00,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,281 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,282 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,283 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,284 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,286 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,287 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,299 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,300 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,302 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,304 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,304 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,305 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,305 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,306 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,313 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,316 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,319 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,321 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,323 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,323 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,326 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,327 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,328 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,329 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,329 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,330 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,330 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,332 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,334 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,335 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,335 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,445 INFO  mapreduce.Job - Job job_local1299448771_0001 running in uber mode : false
2020-05-02 17:23:00,446 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:23:00,448 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,448 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,449 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,449 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,450 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,450 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,461 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,470 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,472 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,473 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,478 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,481 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,495 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,495 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,505 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,506 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,507 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,508 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,508 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,509 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,510 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,511 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,511 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,512 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,513 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,514 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,514 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,515 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,518 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,518 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,520 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,520 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,521 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,521 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,522 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,523 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,524 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,525 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,527 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,528 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,528 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,529 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,529 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,530 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,531 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,531 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,532 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,532 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,533 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,534 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,535 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,535 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,536 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 17:23:00,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 17:23:00,537 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 17:23:01,539 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=130, fetchQueues.getQueueCount=2
2020-05-02 17:23:01,822 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/li/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:02,543 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=129, fetchQueues.getQueueCount=1
2020-05-02 17:23:02,898 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/th/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:03,287 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/ca/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:03,546 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=127, fetchQueues.getQueueCount=1
2020-05-02 17:23:03,870 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/mk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:04,547 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/au/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:04,550 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=125, fetchQueues.getQueueCount=1
2020-05-02 17:23:05,551 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=125, fetchQueues.getQueueCount=1
2020-05-02 17:23:05,663 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/ee/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:06,555 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=124, fetchQueues.getQueueCount=1
2020-05-02 17:23:06,761 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/de/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:07,556 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=123, fetchQueues.getQueueCount=1
2020-05-02 17:23:07,812 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/eg-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:08,556 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=122, fetchQueues.getQueueCount=1
2020-05-02 17:23:09,037 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/hk/en/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:09,264 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/ph/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:09,540 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/kw-ar/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:09,557 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=119, fetchQueues.getQueueCount=1
2020-05-02 17:23:10,265 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/vn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:10,557 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=118, fetchQueues.getQueueCount=1
2020-05-02 17:23:10,972 INFO  fetcher.FetcherThread - FetcherThread 56 fetching https://www.apple.com/eg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:11,558 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=117, fetchQueues.getQueueCount=1
2020-05-02 17:23:11,814 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/mo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:12,470 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-02 17:23:12,475 INFO  fetcher.FetcherThread - FetcherThread 57 fetching https://www.apple.com/fi/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:12,558 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=115, fetchQueues.getQueueCount=1
2020-05-02 17:23:13,548 INFO  fetcher.FetcherThread - FetcherThread 68 fetching https://www.apple.com/hk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:13,560 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=114, fetchQueues.getQueueCount=1
2020-05-02 17:23:14,484 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/ae-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:14,560 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=113, fetchQueues.getQueueCount=1
2020-05-02 17:23:15,565 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=113, fetchQueues.getQueueCount=1
2020-05-02 17:23:15,594 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/ae/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:16,566 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=112, fetchQueues.getQueueCount=1
2020-05-02 17:23:16,836 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.apple.com/id/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:17,567 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=111, fetchQueues.getQueueCount=1
2020-05-02 17:23:17,830 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/jo-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:18,567 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=110, fetchQueues.getQueueCount=1
2020-05-02 17:23:18,843 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/bg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:19,572 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=109, fetchQueues.getQueueCount=1
2020-05-02 17:23:19,792 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/jo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:20,573 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=108, fetchQueues.getQueueCount=1
2020-05-02 17:23:20,710 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/ca/fr/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:21,529 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/pl/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:21,576 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=106, fetchQueues.getQueueCount=1
2020-05-02 17:23:22,364 INFO  fetcher.FetcherThread - FetcherThread 47 fetching https://www.apple.com/ci/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:22,580 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=105, fetchQueues.getQueueCount=1
2020-05-02 17:23:23,580 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=50, fetchQueues.totalSize=105, fetchQueues.getQueueCount=1
2020-05-02 17:23:23,589 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/dk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:24,196 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/nl/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:24,581 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=103, fetchQueues.getQueueCount=1
2020-05-02 17:23:24,919 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/tr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:25,583 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=102, fetchQueues.getQueueCount=1
2020-05-02 17:23:25,860 INFO  fetcher.FetcherThread - FetcherThread 44 fetching https://www.apple.com/mu/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:26,460 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/lu/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:26,584 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=100, fetchQueues.getQueueCount=1
2020-05-02 17:23:27,495 INFO  fetcher.FetcherThread - FetcherThread 68 fetching https://www.apple.com/cm/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:27,584 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=99, fetchQueues.getQueueCount=1
2020-05-02 17:23:28,530 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/gq/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:28,586 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=98, fetchQueues.getQueueCount=1
2020-05-02 17:23:29,520 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/hk/en/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:29,587 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=97, fetchQueues.getQueueCount=1
2020-05-02 17:23:29,785 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/kw-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:30,589 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=96, fetchQueues.getQueueCount=1
2020-05-02 17:23:30,659 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/am/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:31,592 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=95, fetchQueues.getQueueCount=1
2020-05-02 17:23:31,757 INFO  fetcher.FetcherThread - FetcherThread 56 fetching https://www.apple.com/co/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:32,490 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/kw/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:32,596 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=93, fetchQueues.getQueueCount=1
2020-05-02 17:23:33,289 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.apple.com/my/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:33,601 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=92, fetchQueues.getQueueCount=1
2020-05-02 17:23:34,304 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/hu/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:34,603 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=91, fetchQueues.getQueueCount=1
2020-05-02 17:23:35,364 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/pt/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:35,606 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=90, fetchQueues.getQueueCount=1
2020-05-02 17:23:36,421 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/es/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:36,610 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=89, fetchQueues.getQueueCount=1
2020-05-02 17:23:37,101 INFO  fetcher.FetcherThread - FetcherThread 60 fetching https://www.apple.com/in/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:37,360 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/bh/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:37,611 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=87, fetchQueues.getQueueCount=1
2020-05-02 17:23:38,428 INFO  fetcher.FetcherThread - FetcherThread 46 fetching https://www.apple.com/jp/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:38,614 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=86, fetchQueues.getQueueCount=1
2020-05-02 17:23:39,467 INFO  fetcher.FetcherThread - FetcherThread 55 fetching https://www.apple.com/gw/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:39,615 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=85, fetchQueues.getQueueCount=1
2020-05-02 17:23:40,620 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=85, fetchQueues.getQueueCount=1
2020-05-02 17:23:41,214 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/kr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:41,626 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=84, fetchQueues.getQueueCount=1
2020-05-02 17:23:41,941 INFO  fetcher.FetcherThread - FetcherThread 48 fetching https://www.apple.com/cl/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:42,621 INFO  fetcher.FetcherThread - FetcherThread 48 fetching https://www.apple.com/au/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:42,630 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=82, fetchQueues.getQueueCount=1
2020-05-02 17:23:43,242 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/it/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:43,635 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=81, fetchQueues.getQueueCount=1
2020-05-02 17:23:44,405 INFO  fetcher.FetcherThread - FetcherThread 60 fetching https://www.apple.com/mx/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:44,639 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=80, fetchQueues.getQueueCount=1
2020-05-02 17:23:45,134 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/bw/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:45,642 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=79, fetchQueues.getQueueCount=1
2020-05-02 17:23:46,147 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/fr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:46,643 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=78, fetchQueues.getQueueCount=1
2020-05-02 17:23:47,261 INFO  fetcher.FetcherThread - FetcherThread 48 fetching https://www.apple.com/nz/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:47,645 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=77, fetchQueues.getQueueCount=1
2020-05-02 17:23:48,162 INFO  fetcher.FetcherThread - FetcherThread 65 fetching https://www.apple.com/md/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:48,646 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=76, fetchQueues.getQueueCount=1
2020-05-02 17:23:49,491 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/sa/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:49,647 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=75, fetchQueues.getQueueCount=1
2020-05-02 17:23:49,744 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/qa/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:50,649 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=74, fetchQueues.getQueueCount=1
2020-05-02 17:23:50,731 INFO  fetcher.FetcherThread - FetcherThread 55 fetching https://www.apple.com/chfr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:14,106 INFO  util.SitemapProcessor - SitemapProcessor: sitemap urls dir: urls
2020-05-02 17:25:14,106 INFO  util.SitemapProcessor - SitemapProcessor: threads: 50
2020-05-02 17:25:14,107 INFO  util.SitemapProcessor - SitemapProcessor: Starting at 2020-05-02 17:25:14
2020-05-02 17:25:14,556 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:25:16,202 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:16,203 INFO  mapreduce.Job - Running job: job_local584430198_0001
2020-05-02 17:25:16,901 INFO  regex.RegexURLNormalizer - can't find rules for scope 'default', using default
2020-05-02 17:25:17,100 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:25:17,103 INFO  http.Http - http.proxy.host = null
2020-05-02 17:25:17,103 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:25:17,103 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:25:17,103 INFO  http.Http - http.timeout = 30000
2020-05-02 17:25:17,103 INFO  http.Http - http.content.limit = -1
2020-05-02 17:25:17,103 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:25:17,103 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:25:17,103 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:25:17,103 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:25:17,214 INFO  mapreduce.Job - Job job_local584430198_0001 running in uber mode : false
2020-05-02 17:25:17,215 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:25:18,053 INFO  util.SitemapProcessor - Parsing sitemap file: https://www.apple.com/sitemap.xml
2020-05-02 17:25:19,221 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:25:19,221 INFO  mapreduce.Job - Job job_local584430198_0001 completed successfully
2020-05-02 17:25:19,242 INFO  mapreduce.Job - Counters: 33
	File System Counters
		FILE: Number of bytes read=2839050
		FILE: Number of bytes written=4526704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=135
		Map output records=137
		Map output bytes=10083
		Map output materialized bytes=10371
		Input split bytes=614
		Combine input records=0
		Combine output records=0
		Reduce input groups=135
		Reduce shuffle bytes=10371
		Reduce input records=137
		Reduce output records=135
		Spilled Records=274
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=93
		Total committed heap usage (bytes)=785907712
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	Sitemap
		existing_sitemap_entries=134
		new_sitemap_entries=1
		sitemap_seeds=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=11569
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total records rejected by filters: 0
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from host name: 0
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from seed urls: 1
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total failed sitemap fetches: 0
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total new sitemap entries added: 1
2020-05-02 17:25:19,265 INFO  util.SitemapProcessor - SitemapProcessor: Finished at 2020-05-02 17:25:19, elapsed: 00:00:05
2020-05-02 17:25:20,496 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:25:20,934 INFO  crawl.Generator - Generator: starting at 2020-05-02 17:25:20
2020-05-02 17:25:20,934 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 17:25:20,934 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 17:25:20,935 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 17:25:20,940 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 17:25:21,806 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:21,807 INFO  mapreduce.Job - Running job: job_local432465634_0001
2020-05-02 17:25:22,298 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:25:22,299 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:25:22,299 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:25:22,306 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 17:25:22,550 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:25:22,665 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:25:22,824 INFO  mapreduce.Job - Job job_local432465634_0001 running in uber mode : false
2020-05-02 17:25:22,825 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:25:22,826 INFO  mapreduce.Job - Job job_local432465634_0001 completed successfully
2020-05-02 17:25:22,845 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2819496
		FILE: Number of bytes written=4518468
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=135
		Map output records=133
		Map output bytes=13348
		Map output materialized bytes=903
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=903
		Reduce input records=133
		Reduce output records=0
		Spilled Records=266
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=805306368
	Generator
		SCHEDULE_REJECTED=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11309
	File Output Format Counters 
		Bytes Written=16
2020-05-02 17:25:22,845 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 17:25:22,850 INFO  crawl.Generator - Generator:      2  SCHEDULE_REJECTED
2020-05-02 17:25:22,851 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 17:25:23,855 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502172523
2020-05-02 17:25:24,142 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:24,143 INFO  mapreduce.Job - Running job: job_local600580253_0002
2020-05-02 17:25:25,148 INFO  mapreduce.Job - Job job_local600580253_0002 running in uber mode : false
2020-05-02 17:25:25,148 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:25:25,149 INFO  mapreduce.Job - Job job_local600580253_0002 completed successfully
2020-05-02 17:25:25,154 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5652179
		FILE: Number of bytes written=9031778
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=133
		Map output records=133
		Map output bytes=18450
		Map output materialized bytes=1371
		Input split bytes=366
		Combine input records=0
		Combine output records=0
		Reduce input groups=133
		Reduce shuffle bytes=1371
		Reduce input records=133
		Reduce output records=133
		Spilled Records=266
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1332215808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14884
	File Output Format Counters 
		Bytes Written=13670
2020-05-02 17:25:25,239 INFO  crawl.Generator - Generator: finished at 2020-05-02 17:25:25, elapsed: 00:00:04
2020-05-02 17:25:26,298 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 17:25:26
2020-05-02 17:25:26,299 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502172523
2020-05-02 17:25:26,299 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588425926299  (2020-05-02 20:25:26)
2020-05-02 17:25:26,571 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:25:27,795 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:27,796 INFO  mapreduce.Job - Running job: job_local1940515069_0001
2020-05-02 17:25:27,978 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 17:25:27,978 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 17:25:27,979 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 17:25:28,014 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 133 records hit by time limit : 0
2020-05-02 17:25:28,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,301 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,302 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,302 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com.cn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:28,546 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:25:28,548 INFO  http.Http - http.proxy.host = null
2020-05-02 17:25:28,548 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:25:28,548 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:25:28,548 INFO  http.Http - http.timeout = 30000
2020-05-02 17:25:28,548 INFO  http.Http - http.content.limit = -1
2020-05-02 17:25:28,548 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:25:28,548 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:25:28,548 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:25:28,548 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:25:28,556 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,561 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/ie/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:28,564 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,565 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,580 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,592 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,593 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,711 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,712 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,712 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,713 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,714 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,714 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,715 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,716 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,716 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,717 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,717 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,718 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,719 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,719 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,720 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,720 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,721 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,722 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,722 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,723 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,724 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,725 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,726 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,726 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,727 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,727 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,727 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,732 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,732 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,733 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,734 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,735 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,736 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,736 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,737 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,738 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,738 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,739 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,739 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,740 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,740 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,740 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,741 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,742 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,743 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,744 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,744 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,745 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,746 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,746 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,747 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,748 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,749 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,749 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,750 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,750 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,752 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,753 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,754 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,754 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,755 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,755 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,756 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,756 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,757 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,757 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,758 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,759 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,760 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,760 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,761 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,767 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,770 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,776 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,776 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,777 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,778 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,779 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,780 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,780 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,782 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,784 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,787 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,787 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,788 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,789 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,789 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,790 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,790 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,791 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,792 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,792 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 17:25:28,792 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 17:25:28,792 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 17:25:28,801 INFO  mapreduce.Job - Job job_local1940515069_0001 running in uber mode : false
2020-05-02 17:25:28,802 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:25:29,470 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/li/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:29,728 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/th/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:29,793 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=129, fetchQueues.getQueueCount=1
2020-05-02 17:25:30,033 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/ca/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:30,295 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/mk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:30,543 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/au/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:30,794 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=126, fetchQueues.getQueueCount=1
2020-05-02 17:25:30,976 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ee/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:31,248 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/de/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:31,586 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/eg-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:31,794 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=123, fetchQueues.getQueueCount=1
2020-05-02 17:25:32,006 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/hk/en/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:32,230 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/ph/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:32,795 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=121, fetchQueues.getQueueCount=1
2020-05-02 17:25:33,009 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/kw-ar/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:33,271 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/vn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:33,602 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/eg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:33,797 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=118, fetchQueues.getQueueCount=1
2020-05-02 17:25:34,024 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/mo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:34,279 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/fi/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:34,728 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/hk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:34,802 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=115, fetchQueues.getQueueCount=1
2020-05-02 17:25:34,986 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/ae-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:35,262 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/ae/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:35,544 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/id/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:35,805 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=112, fetchQueues.getQueueCount=1
2020-05-02 17:25:36,519 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/jo-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:36,804 INFO  fetcher.FetcherThread - FetcherThread 79 fetching https://www.apple.com/bg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:36,808 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=110, fetchQueues.getQueueCount=1
2020-05-02 17:25:37,234 INFO  fetcher.FetcherThread - FetcherThread 44 fetching https://www.apple.com/jo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:36,747 INFO  crawl.Injector - Injector: starting at 2020-05-02 17:38:36
2020-05-02 17:38:36,752 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 17:38:36,757 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 17:38:36,762 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 17:38:37,021 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:37,629 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 17:38:38,651 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:38,655 INFO  mapreduce.Job - Running job: job_local1501587315_0001
2020-05-02 17:38:39,370 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 17:38:39,640 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 17:38:39,640 INFO  crawl.Injector - Injector: update: false
2020-05-02 17:38:39,666 INFO  mapreduce.Job - Job job_local1501587315_0001 running in uber mode : false
2020-05-02 17:38:39,668 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:39,669 INFO  mapreduce.Job - Job job_local1501587315_0001 completed successfully
2020-05-02 17:38:39,689 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855710
		FILE: Number of bytes written=2988567
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=276
		Map output materialized bytes=290
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=290
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=4
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=653
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 4
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total new urls injected: 4
2020-05-02 17:38:39,736 INFO  crawl.Injector - Injector: finished at 2020-05-02 17:38:39, elapsed: 00:00:02
2020-05-02 17:38:41,186 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: starting at 2020-05-02 17:38:41
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 17:38:41,692 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 17:38:44,280 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:44,281 INFO  mapreduce.Job - Running job: job_local616860332_0001
2020-05-02 17:38:45,225 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:38:45,227 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:38:45,227 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:38:45,242 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 17:38:45,291 INFO  mapreduce.Job - Job job_local616860332_0001 running in uber mode : false
2020-05-02 17:38:45,293 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:38:45,654 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:38:46,298 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:46,299 INFO  mapreduce.Job - Job job_local616860332_0001 completed successfully
2020-05-02 17:38:46,351 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783711
		FILE: Number of bytes written=4486263
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=392
		Map output materialized bytes=134
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=739770368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=406
	File Output Format Counters 
		Bytes Written=16
2020-05-02 17:38:46,352 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 17:38:46,358 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 17:38:47,360 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502173847
2020-05-02 17:38:47,775 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:47,777 INFO  mapreduce.Job - Running job: job_local2116062707_0002
2020-05-02 17:38:48,777 INFO  mapreduce.Job - Job job_local2116062707_0002 running in uber mode : false
2020-05-02 17:38:48,778 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:48,778 INFO  mapreduce.Job - Job job_local2116062707_0002 completed successfully
2020-05-02 17:38:48,782 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3712126
		FILE: Number of bytes written=5982713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=536
		Map output materialized bytes=133
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=133
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=752877568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=548
	File Output Format Counters 
		Bytes Written=490
2020-05-02 17:38:48,805 INFO  crawl.Generator - Generator: finished at 2020-05-02 17:38:48, elapsed: 00:00:07
2020-05-02 17:38:50,069 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 17:38:50
2020-05-02 17:38:50,070 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502173847
2020-05-02 17:38:50,070 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588426730070  (2020-05-02 20:38:50)
2020-05-02 17:38:50,332 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:51,545 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:51,546 INFO  mapreduce.Job - Running job: job_local1926215383_0001
2020-05-02 17:38:51,758 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 17:38:51,759 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 17:38:51,759 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 17:38:51,769 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 4 records hit by time limit : 0
2020-05-02 17:38:52,095 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,116 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,117 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,117 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:52,329 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:38:52,330 INFO  http.Http - http.proxy.host = null
2020-05-02 17:38:52,331 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:38:52,331 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:38:52,331 INFO  http.Http - http.timeout = 30000
2020-05-02 17:38:52,331 INFO  http.Http - http.content.limit = -1
2020-05-02 17:38:52,331 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:38:52,331 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:38:52,331 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:38:52,331 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:38:52,332 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,334 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,335 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,335 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,336 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,337 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,337 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,338 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,338 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,339 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,340 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,346 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,347 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,349 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,359 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,359 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,363 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,364 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,365 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,365 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,366 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,379 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,380 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,382 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,389 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,389 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,390 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,398 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,399 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,399 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,400 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,405 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,405 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,406 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,407 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,409 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,414 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,415 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,416 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,417 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,417 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,422 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,422 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,423 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,424 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,425 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,430 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,431 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,432 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,433 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,533 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,534 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,535 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,536 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,536 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,537 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,552 INFO  mapreduce.Job - Job job_local1926215383_0001 running in uber mode : false
2020-05-02 17:38:52,554 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:38:52,557 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,558 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,562 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,564 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,565 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,568 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,568 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,569 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,573 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,574 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,580 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,581 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,582 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,585 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,585 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,586 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,587 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,589 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,591 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,596 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,597 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,597 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,598 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,598 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,599 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,600 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,601 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,602 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,609 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,610 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,613 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,614 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,615 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,624 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,631 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,633 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,634 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,638 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,638 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,639 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,639 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 17:38:52,640 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 17:38:52,640 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 17:38:53,364 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:53,643 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-02 17:38:53,643 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588415933362
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   now           = 1588415933644
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 17:38:54,084 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:54,347 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 17:38:54,347 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=48
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=47
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 17:38:54,349 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 17:38:54,349 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=46
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 17:38:54,349 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=45
2020-05-02 17:38:54,354 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 17:38:54,354 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 17:38:54,354 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 17:38:54,355 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=43
2020-05-02 17:38:54,365 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 17:38:54,366 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=42
2020-05-02 17:38:54,369 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 17:38:54,369 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 17:38:54,369 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=41
2020-05-02 17:38:54,370 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=40
2020-05-02 17:38:54,385 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 17:38:54,386 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=39
2020-05-02 17:38:54,387 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 17:38:54,387 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=38
2020-05-02 17:38:54,397 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 17:38:54,398 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=37
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=36
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=35
2020-05-02 17:38:54,411 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 17:38:54,411 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=34
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=33
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=32
2020-05-02 17:38:54,419 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 17:38:54,420 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=31
2020-05-02 17:38:54,419 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 17:38:54,420 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=30
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=29
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=28
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 17:38:54,434 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=27
2020-05-02 17:38:54,438 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 17:38:54,438 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=26
2020-05-02 17:38:54,446 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 17:38:54,446 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=25
2020-05-02 17:38:54,534 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 17:38:54,535 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=23
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=22
2020-05-02 17:38:54,563 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 17:38:54,563 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=21
2020-05-02 17:38:54,574 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 17:38:54,575 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=20
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=19
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 17:38:54,581 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=17
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=18
2020-05-02 17:38:54,586 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 17:38:54,586 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=16
2020-05-02 17:38:54,596 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 17:38:54,596 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=15
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=13
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=14
2020-05-02 17:38:54,603 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 17:38:54,603 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=12
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=11
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=10
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 17:38:54,608 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=9
2020-05-02 17:38:54,612 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 17:38:54,612 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=8
2020-05-02 17:38:54,615 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 17:38:54,616 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=7
2020-05-02 17:38:54,623 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 17:38:54,623 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=6
2020-05-02 17:38:54,629 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 17:38:54,630 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=5
2020-05-02 17:38:54,636 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 17:38:54,636 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=4
2020-05-02 17:38:54,642 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 17:38:54,642 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=3
2020-05-02 17:38:54,650 INFO  fetcher.Fetcher - -activeThreads=3, spinWaiting=3, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 17:38:54,651 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 17:38:54,651 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=2
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=1
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=0
2020-05-02 17:38:55,653 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 17:38:55,653 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 17:38:56,565 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:56,566 INFO  mapreduce.Job - Job job_local1926215383_0001 completed successfully
2020-05-02 17:38:56,583 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2945161
		FILE: Number of bytes written=4865953
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=8
		Map output bytes=461890
		Map output materialized bytes=76759
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=76759
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=100
		Total committed heap usage (bytes)=967311360
	FetcherStatus
		bytes_downloaded=457983
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=490
	File Output Format Counters 
		Bytes Written=80314
2020-05-02 17:38:56,583 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 17:38:56, elapsed: 00:00:06
2020-05-02 17:38:57,754 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:58,177 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:38:58
2020-05-02 17:38:58,177 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:38:59,130 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:59,132 INFO  mapreduce.Job - Running job: job_local493069373_0001
2020-05-02 17:39:00,141 INFO  mapreduce.Job - Job job_local493069373_0001 running in uber mode : false
2020-05-02 17:39:00,142 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:39:00,345 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:39:00,594 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,597 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:39:00,610 INFO  parse.ParseSegment - Parsed (992ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:39:00,687 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,688 INFO  parse.ParseSegment - Parsed (64ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:39:00,745 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,746 INFO  parse.ParseSegment - Parsed (54ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:39:00,804 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,805 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:39:01,021 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:39:01,144 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 17:39:01,155 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:39:01,255 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:39:02,145 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:02,146 INFO  mapreduce.Job - Job job_local493069373_0001 completed successfully
2020-05-02 17:39:02,165 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4113920
		FILE: Number of bytes written=6218941
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=40460
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=40460
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=1597505536
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:39:02,180 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:39:02, elapsed: 00:00:03
2020-05-02 17:39:03,292 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:03,714 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 17:39:03
2020-05-02 17:39:03,714 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 17:39:03,714 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502173847]
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 17:39:03,720 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 17:39:04,669 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:04,670 INFO  mapreduce.Job - Running job: job_local1849642166_0001
2020-05-02 17:39:05,690 INFO  mapreduce.Job - Job job_local1849642166_0001 running in uber mode : false
2020-05-02 17:39:05,693 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:39:05,981 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:39:05,982 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:39:05,982 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:39:06,059 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:39:06,059 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:39:06,059 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:39:06,694 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:06,694 INFO  mapreduce.Job - Job job_local1849642166_0001 completed successfully
2020-05-02 17:39:06,722 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=6617375
		FILE: Number of bytes written=10466046
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=188
		Map output records=188
		Map output bytes=13684
		Map output materialized bytes=930
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=930
		Reduce input records=188
		Reduce output records=4
		Spilled Records=376
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=15223
	File Output Format Counters 
		Bytes Written=1540
2020-05-02 17:39:06,754 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 17:39:06, elapsed: 00:00:03
2020-05-02 17:39:08,180 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:08,566 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 17:39:08
2020-05-02 17:39:08,586 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 17:39:08,587 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 17:39:08,598 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 17:39:08,598 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 17:39:08,598 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502173847
2020-05-02 17:39:09,630 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:09,631 INFO  mapreduce.Job - Running job: job_local1848288729_0001
2020-05-02 17:39:10,147 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 17:39:10,642 INFO  mapreduce.Job - Job job_local1848288729_0001 running in uber mode : false
2020-05-02 17:39:10,643 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:10,644 INFO  mapreduce.Job - Job job_local1848288729_0001 completed successfully
2020-05-02 17:39:10,659 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2794787
		FILE: Number of bytes written=4483024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3926
	File Output Format Counters 
		Bytes Written=279
2020-05-02 17:39:10,676 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 17:39:10, elapsed: 00:00:02
2020-05-02 17:39:11,746 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 17:39:11
2020-05-02 17:39:12,037 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:13,405 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:13,405 INFO  mapreduce.Job - Running job: job_local1609343073_0001
2020-05-02 17:39:14,411 INFO  mapreduce.Job - Job job_local1609343073_0001 running in uber mode : false
2020-05-02 17:39:14,412 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:14,413 INFO  mapreduce.Job - Job job_local1609343073_0001 completed successfully
2020-05-02 17:39:14,429 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2788450
		FILE: Number of bytes written=4488534
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1056
		Map output materialized bytes=1080
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1080
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1152
	File Output Format Counters 
		Bytes Written=98
2020-05-02 17:39:14,435 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 17:39:14,435 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 17:39:14,756 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:14,756 INFO  mapreduce.Job - Running job: job_local653361765_0002
2020-05-02 17:39:15,757 INFO  mapreduce.Job - Job job_local653361765_0002 running in uber mode : false
2020-05-02 17:39:15,757 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:15,758 INFO  mapreduce.Job - Job job_local653361765_0002 completed successfully
2020-05-02 17:39:15,761 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7443762
		FILE: Number of bytes written=11956225
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=916
		Map output materialized bytes=946
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=946
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1250
	File Output Format Counters 
		Bytes Written=1301
2020-05-02 17:39:15,779 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 17:39:15, elapsed: 00:00:04
2020-05-02 17:39:16,942 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:17,429 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:39:17,434 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:39:17
2020-05-02 17:39:17,476 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 17:39:17,477 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 17:39:17,477 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 17:39:17,480 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:39:17,480 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:39:17,481 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:39:18,750 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:18,753 INFO  mapreduce.Job - Running job: job_local620731998_0001
2020-05-02 17:39:19,941 INFO  mapreduce.Job - Job job_local620731998_0001 running in uber mode : false
2020-05-02 17:39:19,943 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:39:20,757 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:39:20,798 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:39:21,177 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 17:39:21,777 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:39:21,787 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,800 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,801 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,803 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,804 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:39:21,804 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:39:22,950 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:22,951 INFO  mapreduce.Job - Job job_local620731998_0001 completed successfully
2020-05-02 17:39:22,980 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=11078440
		FILE: Number of bytes written=17739177
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=196
		Map output records=196
		Map output bytes=111275
		Map output materialized bytes=111751
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=111751
		Reduce input records=196
		Reduce output records=4
		Spilled Records=392
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=310
		Total committed heap usage (bytes)=4910481408
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=54507
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:39:22,981 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:39:22,993 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:39:23,021 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:39:22, elapsed: 00:00:05
2020-05-02 17:39:24,243 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 17:39:24
2020-05-02 17:39:24,471 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:25,644 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:25,644 INFO  mapreduce.Job - Running job: job_local397672846_0001
2020-05-02 17:39:26,214 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:39:26,240 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:39:26,650 INFO  mapreduce.Job - Job job_local397672846_0001 running in uber mode : false
2020-05-02 17:39:26,651 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:39:26,666 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 17:39:27,654 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:27,655 INFO  mapreduce.Job - Job job_local397672846_0001 completed successfully
2020-05-02 17:39:27,675 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1856662
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=92
		Total committed heap usage (bytes)=481296384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1054
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:39:27,697 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 17:39:27, elapsed: 00:00:03
2020-05-02 17:41:48,137 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:41:48,559 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:41:48
2020-05-02 17:41:48,559 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:41:50,452 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:41:50,453 INFO  mapreduce.Job - Running job: job_local225455475_0001
2020-05-02 17:41:51,461 INFO  mapreduce.Job - Job job_local225455475_0001 running in uber mode : false
2020-05-02 17:41:51,462 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:41:51,785 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:41:52,198 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,204 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:41:52,214 INFO  parse.ParseSegment - Parsed (1184ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:41:52,321 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,323 INFO  parse.ParseSegment - Parsed (97ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:41:52,415 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,416 INFO  parse.ParseSegment - Parsed (90ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:41:52,522 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,523 INFO  parse.ParseSegment - Parsed (104ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:41:52,766 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:41:52,879 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:41:53,465 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:41:53,466 INFO  mapreduce.Job - Job job_local225455475_0001 completed successfully
2020-05-02 17:41:53,482 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5097210
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=90
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:41:53,498 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:41:53, elapsed: 00:00:04
2020-05-02 17:41:54,661 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:41:55,045 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:41:55,048 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:41:55
2020-05-02 17:41:55,059 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:41:55,059 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:41:55,061 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:41:55,064 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:41:55,064 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:41:55,064 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:41:56,003 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:41:56,004 INFO  mapreduce.Job - Running job: job_local2037565605_0001
2020-05-02 17:41:56,520 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:56,631 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:56,836 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,017 INFO  mapreduce.Job - Job job_local2037565605_0001 running in uber mode : false
2020-05-02 17:41:57,019 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:41:57,032 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,208 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,444 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,512 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,731 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:41:57,768 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:41:58,348 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 17:41:59,133 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:41:59,145 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,155 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,158 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,163 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,163 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:41:59,163 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:42:00,032 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:42:00,033 INFO  mapreduce.Job - Job job_local2037565605_0001 completed successfully
2020-05-02 17:42:00,073 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578437
		FILE: Number of bytes written=17057137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=191
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92299
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:42:00,073 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:42:00,081 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:42:00,114 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:42:00, elapsed: 00:00:05
2020-05-02 17:44:15,569 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:44:15,887 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:44:15
2020-05-02 17:44:15,895 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:44:17,077 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:44:17,081 INFO  mapreduce.Job - Running job: job_local1461421952_0001
2020-05-02 17:44:18,106 INFO  mapreduce.Job - Job job_local1461421952_0001 running in uber mode : false
2020-05-02 17:44:18,108 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:44:18,770 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:44:19,125 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,132 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:44:19,144 INFO  parse.ParseSegment - Parsed (1117ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:44:19,222 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,223 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:44:19,295 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,296 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:44:19,377 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,378 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:44:19,623 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:44:19,743 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:44:20,114 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:44:20,115 INFO  mapreduce.Job - Job job_local1461421952_0001 completed successfully
2020-05-02 17:44:20,143 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105381
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:44:20,162 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:44:20, elapsed: 00:00:04
2020-05-02 17:44:21,322 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:44:21,702 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:44:21,706 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:44:21
2020-05-02 17:44:21,722 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:44:21,722 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:44:21,722 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:44:21,723 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:44:21,724 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:44:21,729 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:44:22,826 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:44:22,827 INFO  mapreduce.Job - Running job: job_local169790368_0001
2020-05-02 17:44:23,598 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:23,825 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:23,834 INFO  mapreduce.Job - Job job_local169790368_0001 running in uber mode : false
2020-05-02 17:44:23,835 INFO  mapreduce.Job -  map 11% reduce 0%
2020-05-02 17:44:23,935 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,104 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,291 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,441 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,507 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,720 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:44:24,756 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:44:24,964 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:44:25,282 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 17:44:25,827 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:44:25,837 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,846 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,849 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,853 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,853 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:44:25,854 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:44:26,971 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:44:26,972 INFO  mapreduce.Job - Job job_local169790368_0001 completed successfully
2020-05-02 17:44:27,011 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578429
		FILE: Number of bytes written=17029817
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=176
		Total committed heap usage (bytes)=6195511296
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92298
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:44:27,011 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:44:27,019 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:44:27,042 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:44:27, elapsed: 00:00:05
2020-05-02 17:45:30,008 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:45:30,469 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:45:30
2020-05-02 17:45:30,470 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:45:31,790 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:45:31,794 INFO  mapreduce.Job - Running job: job_local882011035_0001
2020-05-02 17:45:32,809 INFO  mapreduce.Job - Job job_local882011035_0001 running in uber mode : false
2020-05-02 17:45:32,809 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:45:32,981 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:45:33,222 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,226 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:45:33,236 INFO  parse.ParseSegment - Parsed (833ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:45:33,316 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,317 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:45:33,368 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,369 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:45:33,417 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,418 INFO  parse.ParseSegment - Parsed (46ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:45:33,616 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:45:33,722 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:45:33,813 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:45:34,815 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:45:34,815 INFO  mapreduce.Job - Job job_local882011035_0001 completed successfully
2020-05-02 17:45:34,831 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5097214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=1165492224
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:45:34,844 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:45:34, elapsed: 00:00:04
2020-05-02 17:45:35,847 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:45:36,219 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:45:36,222 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:45:36
2020-05-02 17:45:36,244 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:45:36,244 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:45:36,244 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:45:36,247 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:45:36,247 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:45:36,247 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:45:37,137 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:45:37,138 INFO  mapreduce.Job - Running job: job_local130649158_0001
2020-05-02 17:45:37,588 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:37,683 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:37,778 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:37,960 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,032 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,134 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,144 INFO  mapreduce.Job - Job job_local130649158_0001 running in uber mode : false
2020-05-02 17:45:38,145 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:45:38,202 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,381 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:45:38,410 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:45:38,789 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 17:45:39,384 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:45:39,470 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,480 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,483 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,488 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,489 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:45:39,490 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:45:40,155 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:45:40,156 INFO  mapreduce.Job - Job job_local130649158_0001 completed successfully
2020-05-02 17:45:40,184 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578469
		FILE: Number of bytes written=17029817
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=168
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92303
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:45:40,185 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:45:40,193 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:45:40,213 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:45:40, elapsed: 00:00:03
2020-05-02 17:56:16,626 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:56:17,028 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:56:17
2020-05-02 17:56:17,028 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:56:18,017 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:56:18,018 INFO  mapreduce.Job - Running job: job_local1686074360_0001
2020-05-02 17:56:19,026 INFO  mapreduce.Job - Job job_local1686074360_0001 running in uber mode : false
2020-05-02 17:56:19,027 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:56:19,068 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:56:19,303 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,307 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:56:19,315 INFO  parse.ParseSegment - Parsed (846ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:56:19,395 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,396 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:56:19,504 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,505 INFO  parse.ParseSegment - Parsed (105ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:56:19,576 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,577 INFO  parse.ParseSegment - Parsed (69ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:56:19,803 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:56:19,938 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:56:20,034 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:56:21,036 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:56:21,036 INFO  mapreduce.Job - Job job_local1686074360_0001 completed successfully
2020-05-02 17:56:21,054 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105386
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=68
		Total committed heap usage (bytes)=1171783680
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:56:21,074 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:56:21, elapsed: 00:00:04
2020-05-02 17:56:22,342 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:56:22,753 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:56:22,756 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:56:22
2020-05-02 17:56:22,782 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:56:22,782 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:56:22,784 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:56:22,785 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:56:22,785 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:56:22,785 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:56:23,872 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:56:23,873 INFO  mapreduce.Job - Running job: job_local433490765_0001
2020-05-02 17:56:24,443 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:24,673 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:24,763 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:24,879 INFO  mapreduce.Job - Job job_local433490765_0001 running in uber mode : false
2020-05-02 17:56:24,880 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:56:24,908 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,060 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,278 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,456 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,803 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:56:25,843 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:56:26,374 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 17:56:26,943 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:56:26,954 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,964 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,966 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,969 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,970 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:56:26,970 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:56:27,887 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:56:27,889 INFO  mapreduce.Job - Job job_local433490765_0001 completed successfully
2020-05-02 17:56:27,939 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578469
		FILE: Number of bytes written=17029797
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=211
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92303
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:56:27,939 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:56:27,947 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:56:28,015 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:56:27, elapsed: 00:00:05
2020-05-02 17:57:37,134 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:57:37,693 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:57:37
2020-05-02 17:57:37,694 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:57:38,642 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:57:38,643 INFO  mapreduce.Job - Running job: job_local1379892038_0001
2020-05-02 17:57:39,651 INFO  mapreduce.Job - Job job_local1379892038_0001 running in uber mode : false
2020-05-02 17:57:39,652 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:57:39,733 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:57:39,972 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:39,976 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:57:39,984 INFO  parse.ParseSegment - Parsed (853ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:57:40,059 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:40,059 INFO  parse.ParseSegment - Parsed (50ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:57:40,135 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:40,136 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:57:40,191 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:40,192 INFO  parse.ParseSegment - Parsed (54ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:57:40,384 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:57:40,521 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:57:40,657 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:57:41,661 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:57:41,662 INFO  mapreduce.Job - Job job_local1379892038_0001 completed successfully
2020-05-02 17:57:41,677 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:57:41,689 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:57:41, elapsed: 00:00:03
2020-05-02 17:57:42,771 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:57:43,168 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:57:43,171 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:57:43
2020-05-02 17:57:43,180 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:57:43,180 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:57:43,181 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:57:43,182 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:57:43,182 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:57:43,182 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:57:44,046 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:57:44,046 INFO  mapreduce.Job - Running job: job_local1270655222_0001
2020-05-02 17:57:44,788 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,055 INFO  mapreduce.Job - Job job_local1270655222_0001 running in uber mode : false
2020-05-02 17:57:45,056 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:57:45,095 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,278 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,631 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,782 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,913 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,993 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:46,309 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:57:46,356 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:57:46,799 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 17:57:47,416 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:57:47,428 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,436 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,438 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,445 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,445 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:57:47,466 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:57:48,071 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:57:48,072 INFO  mapreduce.Job - Job job_local1270655222_0001 completed successfully
2020-05-02 17:57:48,101 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578437
		FILE: Number of bytes written=17057137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=184
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92299
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:57:48,101 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:57:48,115 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:57:48,137 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:57:48, elapsed: 00:00:04
2020-05-02 18:00:51,106 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:00:51,452 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:00:51
2020-05-02 18:00:51,452 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:00:52,585 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:00:52,585 INFO  mapreduce.Job - Running job: job_local1265210216_0001
2020-05-02 18:00:53,593 INFO  mapreduce.Job - Job job_local1265210216_0001 running in uber mode : false
2020-05-02 18:00:53,594 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:00:53,785 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 18:00:54,128 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,132 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:00:54,142 INFO  parse.ParseSegment - Parsed (1028ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:00:54,222 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,223 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:00:54,355 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,356 INFO  parse.ParseSegment - Parsed (129ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:00:54,405 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,406 INFO  parse.ParseSegment - Parsed (45ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:00:54,600 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:00:54,602 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:00:54,727 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:00:55,603 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:00:55,603 INFO  mapreduce.Job - Job job_local1265210216_0001 completed successfully
2020-05-02 18:00:55,623 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=74
		Total committed heap usage (bytes)=1167065088
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:00:55,636 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:00:55, elapsed: 00:00:04
2020-05-02 18:00:56,706 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:00:57,152 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:00:57,155 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:00:57
2020-05-02 18:00:57,170 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:00:57,171 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:00:57,171 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:00:57,172 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:00:57,174 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:00:57,174 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:00:58,349 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:00:58,350 INFO  mapreduce.Job - Running job: job_local881184524_0001
2020-05-02 18:00:58,851 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,045 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,295 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,358 INFO  mapreduce.Job - Job job_local881184524_0001 running in uber mode : false
2020-05-02 18:00:59,360 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:00:59,528 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,665 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,880 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,938 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:00,154 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:01:00,185 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:01:00,673 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:01:01,333 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 18:01:01,372 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,386 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,388 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,392 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,393 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:01:01,393 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:01:02,403 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:01:02,405 INFO  mapreduce.Job - Job job_local881184524_0001 completed successfully
2020-05-02 18:01:02,434 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578437
		FILE: Number of bytes written=17029777
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=198
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92299
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:01:02,434 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:01:02,448 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:01:02,504 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:01:02, elapsed: 00:00:05
2020-05-02 18:01:43,520 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:01:43,881 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:01:43
2020-05-02 18:01:43,881 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:01:44,734 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:01:44,735 INFO  mapreduce.Job - Running job: job_local42893344_0001
2020-05-02 18:01:45,743 INFO  mapreduce.Job - Job job_local42893344_0001 running in uber mode : false
2020-05-02 18:01:45,744 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:01:45,779 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 18:01:46,012 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,016 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:01:46,024 INFO  parse.ParseSegment - Parsed (824ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:01:46,118 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,119 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:01:46,181 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,182 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:01:46,223 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,224 INFO  parse.ParseSegment - Parsed (40ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:01:46,448 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:01:46,578 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:01:46,750 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:01:47,755 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:01:47,756 INFO  mapreduce.Job - Job job_local42893344_0001 completed successfully
2020-05-02 18:01:47,770 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5089042
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:01:47,786 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:01:47, elapsed: 00:00:03
2020-05-02 18:01:49,081 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:01:49,563 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:01:49,566 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:01:49
2020-05-02 18:01:49,587 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:01:49,594 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:01:49,594 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:01:49,595 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:01:49,595 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:01:49,596 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:01:50,741 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:01:50,742 INFO  mapreduce.Job - Running job: job_local698639243_0001
2020-05-02 18:01:51,355 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,517 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,684 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,754 INFO  mapreduce.Job - Job job_local698639243_0001 running in uber mode : false
2020-05-02 18:01:51,755 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:01:51,824 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,911 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:52,021 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:52,107 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:52,293 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:01:52,324 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:01:54,706 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:01:55,123 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:01:55
2020-05-02 18:01:55,124 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:01:56,083 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:01:56,084 INFO  mapreduce.Job - Running job: job_local1567022607_0001
2020-05-02 18:01:57,152 INFO  mapreduce.Job - Job job_local1567022607_0001 running in uber mode : false
2020-05-02 18:01:57,153 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:01:57,690 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:01:57,701 INFO  parse.ParseSegment - Parsed (1088ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:01:57,840 INFO  parse.ParseSegment - Parsed (131ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:01:57,936 INFO  parse.ParseSegment - Parsed (94ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:01:58,018 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:01:58,160 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:01:58,230 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:01:58,363 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:01:59,162 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:01:59,162 INFO  mapreduce.Job - Job job_local1567022607_0001 completed successfully
2020-05-02 18:01:59,179 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3382910
		FILE: Number of bytes written=5278241
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=182296
		Map output materialized bytes=182324
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=182324
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:01:59,202 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:01:59, elapsed: 00:00:04
2020-05-02 18:02:00,325 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:02:00,689 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:02:00,691 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:02:00
2020-05-02 18:02:00,704 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:02:00,705 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:02:00,705 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:02:00,720 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:02:00,720 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:02:00,721 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:02:01,693 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:02:01,710 INFO  mapreduce.Job - Running job: job_local1334941027_0001
2020-05-02 18:02:02,311 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,489 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,567 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,645 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,764 INFO  mapreduce.Job - Job job_local1334941027_0001 running in uber mode : false
2020-05-02 18:02:02,765 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:02:02,767 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,890 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,949 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:03,160 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:02:03,184 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:02:03,616 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:02:04,260 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:02:04,261 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:02:05,775 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:02:05,777 INFO  mapreduce.Job - Job job_local1334941027_0001 completed successfully
2020-05-02 18:02:05,805 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10777958
		FILE: Number of bytes written=17409157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=247157
		Map output materialized bytes=247659
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=247659
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=176
		Total committed heap usage (bytes)=6193414144
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108682
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:02:05,806 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:02:05,814 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:02:05,837 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:02:05, elapsed: 00:00:05
2020-05-02 18:06:40,449 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:06:40,790 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:06:40
2020-05-02 18:06:40,790 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:06:41,649 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:06:41,650 INFO  mapreduce.Job - Running job: job_local414727304_0001
2020-05-02 18:06:42,655 INFO  mapreduce.Job - Job job_local414727304_0001 running in uber mode : false
2020-05-02 18:06:42,656 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:06:43,119 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:06:43,130 INFO  parse.ParseSegment - Parsed (1020ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:06:43,264 INFO  parse.ParseSegment - Parsed (121ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:06:43,360 INFO  parse.ParseSegment - Parsed (93ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:06:43,431 INFO  parse.ParseSegment - Parsed (67ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:06:43,630 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:06:43,661 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:06:43,757 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:06:44,667 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:06:44,667 INFO  mapreduce.Job - Job job_local414727304_0001 completed successfully
2020-05-02 18:06:44,684 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3382910
		FILE: Number of bytes written=5269942
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=182296
		Map output materialized bytes=182324
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=182324
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:06:44,696 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:06:44, elapsed: 00:00:03
2020-05-02 18:06:45,720 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:06:46,080 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:06:46,083 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:06:46
2020-05-02 18:06:46,138 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:06:46,140 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:06:46,156 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:06:46,173 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:06:46,174 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:06:46,174 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:06:47,144 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:06:47,145 INFO  mapreduce.Job - Running job: job_local1459157327_0001
2020-05-02 18:06:47,657 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:47,775 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:47,916 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,010 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,134 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,155 INFO  mapreduce.Job - Job job_local1459157327_0001 running in uber mode : false
2020-05-02 18:06:48,156 INFO  mapreduce.Job -  map 44% reduce 0%
2020-05-02 18:06:48,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,271 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,470 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:06:48,490 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:06:48,966 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:06:49,162 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:06:49,678 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:06:49,681 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:06:50,165 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:06:50,167 INFO  mapreduce.Job - Job job_local1459157327_0001 completed successfully
2020-05-02 18:06:50,186 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10777069
		FILE: Number of bytes written=17409137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=247157
		Map output materialized bytes=247659
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=247659
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=188
		Total committed heap usage (bytes)=6190268416
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108555
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:06:50,186 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:06:50,203 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:06:50,245 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:06:50, elapsed: 00:00:04
2020-05-02 18:08:52,524 INFO  crawl.Injector - Injector: starting at 2020-05-02 18:08:52
2020-05-02 18:08:52,525 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 18:08:52,525 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 18:08:52,525 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 18:08:52,678 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:08:53,077 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 18:08:54,033 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:08:54,034 INFO  mapreduce.Job - Running job: job_local408452337_0001
2020-05-02 18:08:54,488 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 18:08:54,696 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 18:08:54,696 INFO  crawl.Injector - Injector: update: false
2020-05-02 18:08:55,043 INFO  mapreduce.Job - Job job_local408452337_0001 running in uber mode : false
2020-05-02 18:08:55,044 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:08:55,047 INFO  mapreduce.Job - Job job_local408452337_0001 completed successfully
2020-05-02 18:08:55,059 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855710
		FILE: Number of bytes written=2983115
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=276
		Map output materialized bytes=290
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=290
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=4
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=653
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 4
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total new urls injected: 4
2020-05-02 18:08:55,093 INFO  crawl.Injector - Injector: finished at 2020-05-02 18:08:55, elapsed: 00:00:02
2020-05-02 18:08:56,173 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: starting at 2020-05-02 18:08:56
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 18:08:56,571 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 18:08:57,472 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:08:57,474 INFO  mapreduce.Job - Running job: job_local279751828_0001
2020-05-02 18:08:57,949 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 18:08:57,949 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 18:08:57,949 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 18:08:57,955 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 18:08:58,116 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 18:08:58,482 INFO  mapreduce.Job - Job job_local279751828_0001 running in uber mode : false
2020-05-02 18:08:58,483 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:08:58,483 INFO  mapreduce.Job - Job job_local279751828_0001 completed successfully
2020-05-02 18:08:58,497 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783711
		FILE: Number of bytes written=4486263
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=392
		Map output materialized bytes=134
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=941621248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=406
	File Output Format Counters 
		Bytes Written=16
2020-05-02 18:08:58,497 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 18:08:58,505 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 18:08:59,510 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502180859
2020-05-02 18:08:59,774 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:08:59,776 INFO  mapreduce.Job - Running job: job_local1020610565_0002
2020-05-02 18:09:00,777 INFO  mapreduce.Job - Job job_local1020610565_0002 running in uber mode : false
2020-05-02 18:09:00,777 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:00,778 INFO  mapreduce.Job - Job job_local1020610565_0002 completed successfully
2020-05-02 18:09:00,783 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3712126
		FILE: Number of bytes written=5982713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=536
		Map output materialized bytes=133
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=133
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=883949568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=548
	File Output Format Counters 
		Bytes Written=490
2020-05-02 18:09:00,802 INFO  crawl.Generator - Generator: finished at 2020-05-02 18:09:00, elapsed: 00:00:04
2020-05-02 18:09:01,824 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 18:09:01
2020-05-02 18:09:01,825 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502180859
2020-05-02 18:09:01,825 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588428541825  (2020-05-02 21:09:01)
2020-05-02 18:09:02,050 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:03,144 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:03,145 INFO  mapreduce.Job - Running job: job_local602175612_0001
2020-05-02 18:09:03,353 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 18:09:03,353 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 18:09:03,354 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 18:09:03,364 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 4 records hit by time limit : 0
2020-05-02 18:09:03,664 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,689 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,690 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,690 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:03,910 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 18:09:03,913 INFO  http.Http - http.proxy.host = null
2020-05-02 18:09:03,913 INFO  http.Http - http.proxy.port = 8080
2020-05-02 18:09:03,913 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 18:09:03,913 INFO  http.Http - http.timeout = 30000
2020-05-02 18:09:03,913 INFO  http.Http - http.content.limit = -1
2020-05-02 18:09:03,913 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 18:09:03,913 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 18:09:03,913 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 18:09:03,913 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 18:09:03,914 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,927 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,928 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,942 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,945 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,947 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,959 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,960 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,961 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,962 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,963 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,963 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,964 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,965 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,987 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,990 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,991 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,993 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,994 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,996 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,997 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,998 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,012 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,014 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,015 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,015 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,016 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,030 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,030 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,137 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,137 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,138 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,139 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,148 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,149 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,151 INFO  mapreduce.Job - Job job_local602175612_0001 running in uber mode : false
2020-05-02 18:09:04,152 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:09:04,156 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,157 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,158 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,158 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,159 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,159 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,165 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,165 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,174 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,175 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,176 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,177 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,178 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,181 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,182 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,183 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,184 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,186 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,186 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,187 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,188 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,188 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,189 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,190 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,191 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,192 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,192 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,194 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,196 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,197 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,198 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,203 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,209 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,210 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,211 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,211 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,212 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,215 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,216 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,217 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,218 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,219 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,220 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,220 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,221 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,221 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,222 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,224 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,224 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,225 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,226 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,226 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,228 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,229 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 18:09:04,231 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 18:09:04,232 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 18:09:05,240 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588417743363
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   now           = 1588417745240
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-se/specs/
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/iphone-xr/specs/
2020-05-02 18:09:05,412 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:05,712 INFO  fetcher.FetcherThread - FetcherThread 75 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:06,244 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588417745710
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   now           = 1588417746244
2020-05-02 18:09:06,245 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-02 18:09:06,945 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:06,956 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 18:09:06,956 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 18:09:06,957 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 18:09:06,957 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=48
2020-05-02 18:09:06,979 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 18:09:06,980 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=47
2020-05-02 18:09:06,980 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 18:09:06,981 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=46
2020-05-02 18:09:06,979 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 18:09:06,982 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=45
2020-05-02 18:09:06,980 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 18:09:06,982 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=44
2020-05-02 18:09:07,011 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 18:09:07,011 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=43
2020-05-02 18:09:07,012 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 18:09:07,012 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=42
2020-05-02 18:09:07,011 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 18:09:07,012 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=41
2020-05-02 18:09:07,021 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 18:09:07,021 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=40
2020-05-02 18:09:07,035 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 18:09:07,035 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=39
2020-05-02 18:09:07,035 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 18:09:07,036 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=38
2020-05-02 18:09:07,046 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 18:09:07,046 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=37
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=35
2020-05-02 18:09:07,165 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 18:09:07,166 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=34
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=33
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=32
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 18:09:07,179 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=31
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 18:09:07,179 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=30
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=29
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=28
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=27
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=25
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 18:09:07,204 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=24
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 18:09:07,204 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=23
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=26
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 18:09:07,205 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=22
2020-05-02 18:09:07,212 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 18:09:07,212 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=21
2020-05-02 18:09:07,213 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=20
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=19
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=18
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 18:09:07,215 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 18:09:07,215 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 18:09:07,217 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=15
2020-05-02 18:09:07,216 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=17
2020-05-02 18:09:07,215 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 18:09:07,218 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=14
2020-05-02 18:09:07,216 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=16
2020-05-02 18:09:07,228 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=13
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=12
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=11
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 18:09:07,230 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=9
2020-05-02 18:09:07,230 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=9
2020-05-02 18:09:07,228 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 18:09:07,232 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=8
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 18:09:07,232 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=7
2020-05-02 18:09:07,240 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=6
2020-05-02 18:09:07,240 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=5
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=4
2020-05-02 18:09:07,240 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=3
2020-05-02 18:09:07,246 INFO  fetcher.Fetcher - -activeThreads=3, spinWaiting=2, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 18:09:07,248 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 18:09:07,248 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=2
2020-05-02 18:09:07,361 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 18:09:07,362 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=1
2020-05-02 18:09:07,982 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 18:09:07,982 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=0
2020-05-02 18:09:08,247 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 18:09:08,249 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 18:09:09,176 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:09,177 INFO  mapreduce.Job - Job job_local602175612_0001 completed successfully
2020-05-02 18:09:09,196 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2945141
		FILE: Number of bytes written=4857741
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=8
		Map output bytes=461890
		Map output materialized bytes=76749
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=76749
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=120
		Total committed heap usage (bytes)=968884224
	FetcherStatus
		bytes_downloaded=457983
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=490
	File Output Format Counters 
		Bytes Written=80320
2020-05-02 18:09:09,196 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 18:09:09, elapsed: 00:00:07
2020-05-02 18:09:10,248 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:10,610 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:09:10
2020-05-02 18:09:10,610 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:09:11,452 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:11,453 INFO  mapreduce.Job - Running job: job_local1616095019_0001
2020-05-02 18:09:12,463 INFO  mapreduce.Job - Job job_local1616095019_0001 running in uber mode : false
2020-05-02 18:09:12,464 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:09:12,921 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:09:12,937 INFO  parse.ParseSegment - Parsed (1034ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:09:13,086 INFO  parse.ParseSegment - Parsed (144ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:09:13,202 INFO  parse.ParseSegment - Parsed (111ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:09:13,290 INFO  parse.ParseSegment - Parsed (87ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:09:13,471 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:13,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:13,608 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:13,710 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:09:14,472 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:14,473 INFO  mapreduce.Job - Job job_local1616095019_0001 completed successfully
2020-05-02 18:09:14,490 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4124022
		FILE: Number of bytes written=6271345
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=182296
		Map output materialized bytes=45503
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=45503
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=1595932672
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:09:14,508 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:09:14, elapsed: 00:00:03
2020-05-02 18:09:15,810 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:16,325 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 18:09:16
2020-05-02 18:09:16,328 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 18:09:16,328 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502180859]
2020-05-02 18:09:16,329 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 18:09:16,330 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 18:09:16,331 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 18:09:16,331 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 18:09:16,333 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 18:09:17,310 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:17,311 INFO  mapreduce.Job - Running job: job_local1696147252_0001
2020-05-02 18:09:18,318 INFO  mapreduce.Job - Job job_local1696147252_0001 running in uber mode : false
2020-05-02 18:09:18,319 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:18,412 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 18:09:18,412 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 18:09:18,412 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 18:09:18,463 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 18:09:18,463 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 18:09:18,463 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 18:09:19,322 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:19,323 INFO  mapreduce.Job - Job job_local1696147252_0001 completed successfully
2020-05-02 18:09:19,341 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=6616735
		FILE: Number of bytes written=10465970
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=188
		Map output records=188
		Map output bytes=13684
		Map output materialized bytes=922
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=922
		Reduce input records=188
		Reduce output records=4
		Spilled Records=376
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=15136
	File Output Format Counters 
		Bytes Written=1540
2020-05-02 18:09:19,364 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 18:09:19, elapsed: 00:00:03
2020-05-02 18:09:20,707 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:21,214 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 18:09:21
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502180859
2020-05-02 18:09:22,057 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:22,058 INFO  mapreduce.Job - Running job: job_local1631640523_0001
2020-05-02 18:09:22,576 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 18:09:23,066 INFO  mapreduce.Job - Job job_local1631640523_0001 running in uber mode : false
2020-05-02 18:09:23,067 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:23,069 INFO  mapreduce.Job - Job job_local1631640523_0001 completed successfully
2020-05-02 18:09:23,083 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2843933
		FILE: Number of bytes written=4483012
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=1084227584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=20308
	File Output Format Counters 
		Bytes Written=279
2020-05-02 18:09:23,103 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 18:09:23, elapsed: 00:00:01
2020-05-02 18:09:24,100 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 18:09:24
2020-05-02 18:09:24,353 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:25,523 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:25,524 INFO  mapreduce.Job - Running job: job_local1846916925_0001
2020-05-02 18:09:26,536 INFO  mapreduce.Job - Job job_local1846916925_0001 running in uber mode : false
2020-05-02 18:09:26,537 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:26,539 INFO  mapreduce.Job - Job job_local1846916925_0001 completed successfully
2020-05-02 18:09:26,551 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2788450
		FILE: Number of bytes written=4488534
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1056
		Map output materialized bytes=1080
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1080
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1152
	File Output Format Counters 
		Bytes Written=98
2020-05-02 18:09:26,557 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 18:09:26,557 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 18:09:26,891 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:26,891 INFO  mapreduce.Job - Running job: job_local797995204_0002
2020-05-02 18:09:27,893 INFO  mapreduce.Job - Job job_local797995204_0002 running in uber mode : false
2020-05-02 18:09:27,894 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:27,894 INFO  mapreduce.Job - Job job_local797995204_0002 completed successfully
2020-05-02 18:09:27,899 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7443762
		FILE: Number of bytes written=11956225
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=916
		Map output materialized bytes=946
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=946
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1250
	File Output Format Counters 
		Bytes Written=1301
2020-05-02 18:09:27,927 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 18:09:27, elapsed: 00:00:03
2020-05-02 18:09:29,271 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:29,744 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:09:29,748 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:09:29
2020-05-02 18:09:29,817 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 18:09:29,818 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 18:09:29,820 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 18:09:29,840 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:09:29,841 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:09:29,841 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:09:30,828 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:30,829 INFO  mapreduce.Job - Running job: job_local77765944_0001
2020-05-02 18:09:31,836 INFO  mapreduce.Job - Job job_local77765944_0001 running in uber mode : false
2020-05-02 18:09:31,837 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:32,383 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:09:32,404 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:09:32,707 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:09:33,442 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:09:33,442 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:09:33,842 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:33,842 INFO  mapreduce.Job - Job job_local77765944_0001 completed successfully
2020-05-02 18:09:33,873 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=11309924
		FILE: Number of bytes written=18139319
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=196
		Map output records=196
		Map output bytes=150394
		Map output materialized bytes=150870
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=150870
		Reduce input records=196
		Reduce output records=4
		Spilled Records=392
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=240
		Total committed heap usage (bytes)=4899995648
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=70802
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:09:33,873 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:09:33,891 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:09:33,946 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:09:33, elapsed: 00:00:04
2020-05-02 18:09:35,206 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 18:09:35
2020-05-02 18:09:35,485 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:36,978 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:36,986 INFO  mapreduce.Job - Running job: job_local872719421_0001
2020-05-02 18:09:37,738 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:09:37,764 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:09:38,016 INFO  mapreduce.Job - Job job_local872719421_0001 running in uber mode : false
2020-05-02 18:09:38,018 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:38,181 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 18:09:39,020 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:39,021 INFO  mapreduce.Job - Job job_local872719421_0001 completed successfully
2020-05-02 18:09:39,038 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1856662
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=478150656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1054
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:09:39,059 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 18:09:39, elapsed: 00:00:03
2020-05-02 18:17:42,386 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:17:42,772 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:17:42
2020-05-02 18:17:42,772 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:17:44,588 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:17:44,589 INFO  mapreduce.Job - Running job: job_local31739510_0001
2020-05-02 18:17:45,597 INFO  mapreduce.Job - Job job_local31739510_0001 running in uber mode : false
2020-05-02 18:17:45,598 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:17:46,284 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:17:46,295 INFO  parse.ParseSegment - Parsed (1159ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:17:46,433 INFO  parse.ParseSegment - Parsed (129ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:17:46,543 INFO  parse.ParseSegment - Parsed (107ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:17:46,620 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:17:46,822 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:17:46,931 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:17:47,606 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:17:47,607 INFO  mapreduce.Job - Job job_local31739510_0001 completed successfully
2020-05-02 18:17:47,622 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3394686
		FILE: Number of bytes written=5288044
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=188178
		Map output materialized bytes=188206
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=188206
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=74
		Total committed heap usage (bytes)=1165492224
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:17:47,638 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:17:47, elapsed: 00:00:04
2020-05-02 18:17:48,714 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:17:49,072 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:17:49,079 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:17:49
2020-05-02 18:17:49,109 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:17:49,110 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:17:49,110 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:17:49,115 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:17:49,115 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:17:49,115 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:17:50,207 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:17:50,207 INFO  mapreduce.Job - Running job: job_local767937080_0001
2020-05-02 18:17:50,889 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,184 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,217 INFO  mapreduce.Job - Job job_local767937080_0001 running in uber mode : false
2020-05-02 18:17:51,219 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:17:51,300 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,408 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,544 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,729 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,783 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,959 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:17:51,990 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:17:52,558 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:17:53,456 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:17:53,456 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:17:54,231 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:17:54,233 INFO  mapreduce.Job - Job job_local767937080_0001 completed successfully
2020-05-02 18:17:54,258 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10993897
		FILE: Number of bytes written=17747596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=292158
		Map output materialized bytes=292660
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=292660
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=162
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=127685
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:17:54,258 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:17:54,267 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:17:54,286 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:17:54, elapsed: 00:00:05
2020-05-02 18:30:10,114 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:30:11,314 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:30:11
2020-05-02 18:30:11,314 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:30:12,599 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:30:12,601 INFO  mapreduce.Job - Running job: job_local62392434_0001
2020-05-02 18:30:13,607 INFO  mapreduce.Job - Job job_local62392434_0001 running in uber mode : false
2020-05-02 18:30:13,608 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:30:14,131 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:30:14,138 INFO  parse.ParseSegment - Parsed (1002ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:30:14,235 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:30:14,309 INFO  parse.ParseSegment - Parsed (69ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:30:14,589 INFO  parse.ParseSegment - Parsed (276ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:30:14,816 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:30:14,952 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:30:15,613 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:30:15,613 INFO  mapreduce.Job - Job job_local62392434_0001 completed successfully
2020-05-02 18:30:15,634 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318220
		FILE: Number of bytes written=5119280
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149945
		Map output materialized bytes=149973
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149973
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=98
		Total committed heap usage (bytes)=1094713344
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:30:15,647 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:30:15, elapsed: 00:00:04
2020-05-02 18:30:16,868 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:30:17,256 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:30:17,258 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:30:17
2020-05-02 18:30:17,270 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:30:17,270 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:30:17,270 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:30:17,271 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:30:17,271 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:30:17,272 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:30:18,129 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:30:18,130 INFO  mapreduce.Job - Running job: job_local1486865289_0001
2020-05-02 18:30:18,625 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:18,770 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:18,953 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,050 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,140 INFO  mapreduce.Job - Job job_local1486865289_0001 running in uber mode : false
2020-05-02 18:30:19,141 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:30:19,210 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,332 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,410 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,583 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:30:19,616 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:30:20,101 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:30:20,762 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:30:20,769 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:30:21,160 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:30:21,161 INFO  mapreduce.Job - Job job_local1486865289_0001 completed successfully
2020-05-02 18:30:21,182 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810517
		FILE: Number of bytes written=17456513
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253925
		Map output materialized bytes=254427
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254427
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=203
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111853
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:30:21,182 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:30:21,188 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:30:21,216 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:30:21, elapsed: 00:00:03
2020-05-02 18:47:56,106 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:47:56,528 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:47:56
2020-05-02 18:47:56,528 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:47:57,575 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:47:57,576 INFO  mapreduce.Job - Running job: job_local1586198216_0001
2020-05-02 18:47:58,584 INFO  mapreduce.Job - Job job_local1586198216_0001 running in uber mode : false
2020-05-02 18:47:58,585 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:47:59,136 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:47:59,145 INFO  parse.ParseSegment - Parsed (1092ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:47:59,247 INFO  parse.ParseSegment - Parsed (86ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:47:59,323 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:47:59,726 INFO  parse.ParseSegment - Parsed (400ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:47:59,932 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:48:00,110 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:48:00,590 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:48:00,590 INFO  mapreduce.Job - Job job_local1586198216_0001 completed successfully
2020-05-02 18:48:00,610 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318222
		FILE: Number of bytes written=5135627
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149946
		Map output materialized bytes=149974
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149974
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=78
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:48:00,628 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:48:00, elapsed: 00:00:04
2020-05-02 18:48:01,843 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:48:02,325 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:48:02,329 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:48:02
2020-05-02 18:48:02,401 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:48:02,401 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:48:02,402 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:48:02,410 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:48:02,410 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:48:02,410 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:48:03,352 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:48:03,353 INFO  mapreduce.Job - Running job: job_local424997706_0001
2020-05-02 18:48:03,859 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:03,976 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,188 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,326 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,360 INFO  mapreduce.Job - Job job_local424997706_0001 running in uber mode : false
2020-05-02 18:48:04,361 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:48:04,530 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,733 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,799 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,964 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:48:04,991 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:48:05,414 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:48:05,933 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:48:05,934 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:48:06,370 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:48:06,373 INFO  mapreduce.Job - Job job_local424997706_0001 completed successfully
2020-05-02 18:48:06,396 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810511
		FILE: Number of bytes written=17429160
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253926
		Map output materialized bytes=254428
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254428
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=6191841280
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111852
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:48:06,396 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:48:06,406 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:48:06,429 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:48:06, elapsed: 00:00:04
2020-05-02 18:48:51,508 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:48:51,865 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:48:51
2020-05-02 18:48:51,866 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:48:52,701 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:48:52,702 INFO  mapreduce.Job - Running job: job_local453089167_0001
2020-05-02 18:48:53,712 INFO  mapreduce.Job - Job job_local453089167_0001 running in uber mode : false
2020-05-02 18:48:53,713 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:48:54,243 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:48:54,252 INFO  parse.ParseSegment - Parsed (1113ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:48:54,326 INFO  parse.ParseSegment - Parsed (67ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:48:54,405 INFO  parse.ParseSegment - Parsed (76ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:48:54,648 INFO  parse.ParseSegment - Parsed (241ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:48:54,718 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:48:54,890 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:48:55,017 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:48:55,721 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:48:55,722 INFO  mapreduce.Job - Job job_local453089167_0001 completed successfully
2020-05-02 18:48:55,737 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318230
		FILE: Number of bytes written=5127469
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149950
		Map output materialized bytes=149978
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149978
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=1176502272
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:48:55,753 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:48:55, elapsed: 00:00:03
2020-05-02 18:48:56,809 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:48:57,190 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:48:57,193 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:48:57
2020-05-02 18:48:57,205 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:48:57,206 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:48:57,206 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:48:57,208 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:48:57,208 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:48:57,208 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:48:58,111 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:48:58,112 INFO  mapreduce.Job - Running job: job_local969553989_0001
2020-05-02 18:48:58,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:58,689 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:58,796 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:58,910 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,045 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,122 INFO  mapreduce.Job - Job job_local969553989_0001 running in uber mode : false
2020-05-02 18:48:59,123 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:48:59,144 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,215 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,430 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:48:59,452 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:48:59,838 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:49:00,551 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:49:00,555 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:49:01,129 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:49:01,130 INFO  mapreduce.Job - Job job_local969553989_0001 completed successfully
2020-05-02 18:49:01,158 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810504
		FILE: Number of bytes written=17429208
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253930
		Map output materialized bytes=254432
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254432
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=146
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111850
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:49:01,158 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:49:01,168 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:49:01,196 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:49:01, elapsed: 00:00:03
2020-05-02 18:51:02,916 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:03,276 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:51:03
2020-05-02 18:51:03,277 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:51:04,275 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:04,276 INFO  mapreduce.Job - Running job: job_local1504282378_0001
2020-05-02 18:51:05,287 INFO  mapreduce.Job - Job job_local1504282378_0001 running in uber mode : false
2020-05-02 18:51:05,288 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:51:05,590 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:51:05,602 INFO  parse.ParseSegment - Parsed (875ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:51:05,797 INFO  parse.ParseSegment - Parsed (185ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:51:05,907 INFO  parse.ParseSegment - Parsed (106ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:51:06,125 INFO  parse.ParseSegment - Parsed (215ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:51:06,293 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:06,352 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:51:06,479 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:51:07,294 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:07,295 INFO  mapreduce.Job - Job job_local1504282378_0001 completed successfully
2020-05-02 18:51:07,312 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318230
		FILE: Number of bytes written=5135646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149950
		Map output materialized bytes=149978
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149978
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:07,332 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:51:07, elapsed: 00:00:04
2020-05-02 18:51:08,473 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:08,850 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:51:08,853 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:51:08
2020-05-02 18:51:08,870 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:51:08,870 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:51:08,870 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:51:08,872 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:51:08,872 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:51:08,872 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:51:09,799 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:09,800 INFO  mapreduce.Job - Running job: job_local982864338_0001
2020-05-02 18:51:10,291 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,393 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,577 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,672 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,783 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,807 INFO  mapreduce.Job - Job job_local982864338_0001 running in uber mode : false
2020-05-02 18:51:10,808 INFO  mapreduce.Job -  map 44% reduce 0%
2020-05-02 18:51:10,872 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,922 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:11,103 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:51:11,126 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:51:11,522 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:51:11,813 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:12,227 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:51:12,229 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:51:12,818 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:12,818 INFO  mapreduce.Job - Job job_local982864338_0001 completed successfully
2020-05-02 18:51:12,842 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810539
		FILE: Number of bytes written=17429228
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253930
		Map output materialized bytes=254432
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254432
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=162
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111855
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:12,843 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:51:12,850 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:51:12,870 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:51:12, elapsed: 00:00:04
2020-05-02 18:51:31,840 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:32,227 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:51:32
2020-05-02 18:51:32,227 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:51:33,221 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:33,223 INFO  mapreduce.Job - Running job: job_local1297613748_0001
2020-05-02 18:51:34,229 INFO  mapreduce.Job - Job job_local1297613748_0001 running in uber mode : false
2020-05-02 18:51:34,230 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:51:34,684 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:51:34,695 INFO  parse.ParseSegment - Parsed (937ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:51:34,790 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:51:34,852 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:51:35,152 INFO  parse.ParseSegment - Parsed (287ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:51:35,236 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:35,413 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:51:35,540 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:51:36,238 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:36,239 INFO  mapreduce.Job - Job job_local1297613748_0001 completed successfully
2020-05-02 18:51:36,253 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318230
		FILE: Number of bytes written=5135617
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149950
		Map output materialized bytes=149978
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149978
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:36,267 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:51:36, elapsed: 00:00:04
2020-05-02 18:51:37,355 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:37,750 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:51:37,753 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:51:37
2020-05-02 18:51:37,782 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:51:37,783 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:51:37,783 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:51:37,784 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:51:37,784 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:51:37,784 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:51:38,758 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:38,759 INFO  mapreduce.Job - Running job: job_local983337037_0001
2020-05-02 18:51:39,251 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,357 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,503 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,634 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,771 INFO  mapreduce.Job - Job job_local983337037_0001 running in uber mode : false
2020-05-02 18:51:39,773 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:39,807 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,922 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:40,067 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:40,408 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:51:40,438 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:51:40,885 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 18:51:42,099 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:51:42,099 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:51:42,781 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:42,783 INFO  mapreduce.Job - Job job_local983337037_0001 completed successfully
2020-05-02 18:51:42,819 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810336
		FILE: Number of bytes written=17429188
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253930
		Map output materialized bytes=254432
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254432
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=176
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111826
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:42,819 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:51:42,831 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:51:42,851 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:51:42, elapsed: 00:00:05
2020-05-02 19:07:03,271 INFO  crawl.Injector - Injector: starting at 2020-05-02 19:07:03
2020-05-02 19:07:03,272 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 19:07:03,272 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 19:07:03,282 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 19:07:03,460 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:04,022 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 19:07:05,107 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:05,109 INFO  mapreduce.Job - Running job: job_local1023143491_0001
2020-05-02 19:07:05,730 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 19:07:05,970 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 19:07:05,970 INFO  crawl.Injector - Injector: update: false
2020-05-02 19:07:06,118 INFO  mapreduce.Job - Job job_local1023143491_0001 running in uber mode : false
2020-05-02 19:07:06,119 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:06,119 INFO  mapreduce.Job - Job job_local1023143491_0001 completed successfully
2020-05-02 19:07:06,133 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1856344
		FILE: Number of bytes written=2988565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=4
		Map output bytes=276
		Map output materialized bytes=290
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=290
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_filtered=8
		urls_injected=4
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=653
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total urls rejected by filters: 8
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 4
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total new urls injected: 4
2020-05-02 19:07:06,166 INFO  crawl.Injector - Injector: finished at 2020-05-02 19:07:06, elapsed: 00:00:02
2020-05-02 19:07:07,248 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:07,701 INFO  crawl.Generator - Generator: starting at 2020-05-02 19:07:07
2020-05-02 19:07:07,702 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 19:07:07,702 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 19:07:07,702 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 19:07:07,705 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 19:07:08,572 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:08,573 INFO  mapreduce.Job - Running job: job_local655348898_0001
2020-05-02 19:07:09,051 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:07:09,052 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:07:09,052 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:07:09,062 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 19:07:09,299 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 19:07:09,578 INFO  mapreduce.Job - Job job_local655348898_0001 running in uber mode : false
2020-05-02 19:07:09,580 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:09,581 INFO  mapreduce.Job - Job job_local655348898_0001 completed successfully
2020-05-02 19:07:09,594 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783711
		FILE: Number of bytes written=4486263
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=392
		Map output materialized bytes=134
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=406
	File Output Format Counters 
		Bytes Written=16
2020-05-02 19:07:09,594 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 19:07:09,599 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 19:07:10,604 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502190710
2020-05-02 19:07:10,880 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:10,880 INFO  mapreduce.Job - Running job: job_local1094954066_0002
2020-05-02 19:07:11,881 INFO  mapreduce.Job - Job job_local1094954066_0002 running in uber mode : false
2020-05-02 19:07:11,881 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:11,882 INFO  mapreduce.Job - Job job_local1094954066_0002 completed successfully
2020-05-02 19:07:11,885 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3712126
		FILE: Number of bytes written=5982713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=536
		Map output materialized bytes=133
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=133
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=548
	File Output Format Counters 
		Bytes Written=490
2020-05-02 19:07:11,904 INFO  crawl.Generator - Generator: finished at 2020-05-02 19:07:11, elapsed: 00:00:04
2020-05-02 19:07:13,030 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 19:07:13
2020-05-02 19:07:13,031 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502190710
2020-05-02 19:07:13,031 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588432033031  (2020-05-02 22:07:13)
2020-05-02 19:07:13,318 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:14,468 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:14,469 INFO  mapreduce.Job - Running job: job_local1651248860_0001
2020-05-02 19:07:14,641 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 19:07:14,641 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 19:07:14,642 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 19:07:14,654 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 4 records hit by time limit : 0
2020-05-02 19:07:14,910 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:14,933 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:14,933 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:14,934 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:14,934 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:14,935 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,176 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 19:07:15,180 INFO  http.Http - http.proxy.host = null
2020-05-02 19:07:15,180 INFO  http.Http - http.proxy.port = 8080
2020-05-02 19:07:15,180 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 19:07:15,180 INFO  http.Http - http.timeout = 30000
2020-05-02 19:07:15,180 INFO  http.Http - http.content.limit = -1
2020-05-02 19:07:15,180 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 19:07:15,180 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 19:07:15,180 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 19:07:15,180 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 19:07:15,181 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,181 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,182 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,183 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,183 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,184 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,184 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,185 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,186 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,186 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,187 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,188 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,191 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,191 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,192 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,192 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,194 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,194 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,195 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,196 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,196 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,197 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,198 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,198 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,199 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,200 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,201 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,202 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,202 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,203 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,204 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,206 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,207 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,208 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,209 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,211 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,215 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,216 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,220 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,221 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,229 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,231 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,231 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,232 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,235 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,238 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,238 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,239 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,239 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,240 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,240 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,241 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,242 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,244 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,245 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,246 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,246 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,247 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,247 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,248 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,249 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,250 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,250 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,251 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,253 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,254 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,254 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,255 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,255 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,255 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,256 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,256 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,257 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,257 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,257 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,258 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,259 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,260 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,260 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,261 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,261 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,262 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,262 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,264 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,264 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 19:07:15,265 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 19:07:15,265 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 19:07:15,480 INFO  mapreduce.Job - Job job_local1651248860_0001 running in uber mode : false
2020-05-02 19:07:15,481 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:07:16,271 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421234649
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   now           = 1588421236271
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-se/specs/
2020-05-02 19:07:16,272 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:07:16,272 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:16,836 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:17,274 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421236836
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   now           = 1588421237275
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:17,451 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:18,277 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421237404
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   now           = 1588421238278
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:18,565 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 19:07:18,704 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=48
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 19:07:18,706 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=47
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 19:07:18,714 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=41
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=42
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 19:07:18,714 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=40
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 19:07:18,714 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=39
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=45
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 19:07:18,716 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 19:07:18,716 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=38
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=35
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=32
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=30
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=29
2020-05-02 19:07:18,725 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=33
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=34
2020-05-02 19:07:18,725 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=28
2020-05-02 19:07:18,729 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 19:07:18,731 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=26
2020-05-02 19:07:18,725 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=27
2020-05-02 19:07:18,740 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=25
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=23
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=22
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=21
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=20
2020-05-02 19:07:18,759 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 19:07:18,759 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=19
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=18
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 19:07:18,767 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=17
2020-05-02 19:07:18,768 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=16
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 19:07:18,768 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=15
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=11
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 19:07:18,772 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=9
2020-05-02 19:07:18,772 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=10
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=14
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=12
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 19:07:18,774 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=8
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=13
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 19:07:18,775 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=7
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 19:07:18,781 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=6
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 19:07:18,786 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=5
2020-05-02 19:07:18,783 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 19:07:18,782 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 19:07:18,787 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=4
2020-05-02 19:07:18,787 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=3
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 19:07:18,788 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=2
2020-05-02 19:07:18,911 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 19:07:18,912 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=1
2020-05-02 19:07:19,281 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 19:07:19,483 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 19:07:19,483 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=0
2020-05-02 19:07:20,286 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 19:07:20,287 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 19:07:20,499 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:21,499 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:21,500 INFO  mapreduce.Job - Job job_local1651248860_0001 completed successfully
2020-05-02 19:07:21,520 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2945147
		FILE: Number of bytes written=4865926
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=8
		Map output bytes=461891
		Map output materialized bytes=76752
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=76752
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=86
		Total committed heap usage (bytes)=976748544
	FetcherStatus
		bytes_downloaded=457983
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=490
	File Output Format Counters 
		Bytes Written=80315
2020-05-02 19:07:21,520 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 19:07:21, elapsed: 00:00:08
2020-05-02 19:07:22,654 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:23,039 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:07:23
2020-05-02 19:07:23,041 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190710
2020-05-02 19:07:24,004 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:24,005 INFO  mapreduce.Job - Running job: job_local974578749_0001
2020-05-02 19:07:25,011 INFO  mapreduce.Job - Job job_local974578749_0001 running in uber mode : false
2020-05-02 19:07:25,012 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:07:25,387 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:07:25,393 INFO  parse.ParseSegment - Parsed (907ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:07:25,464 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:07:25,551 INFO  parse.ParseSegment - Parsed (84ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:07:25,843 INFO  parse.ParseSegment - Parsed (290ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:26,018 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:26,041 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:26,160 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:26,245 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:07:27,019 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:27,019 INFO  mapreduce.Job - Job job_local974578749_0001 completed successfully
2020-05-02 19:07:27,044 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4116848
		FILE: Number of bytes written=6229428
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149951
		Map output materialized bytes=41928
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=41928
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1589116928
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78433
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:07:27,068 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:07:27, elapsed: 00:00:04
2020-05-02 19:07:28,383 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:28,950 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 19:07:28
2020-05-02 19:07:28,951 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 19:07:28,951 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502190710]
2020-05-02 19:07:28,951 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 19:07:28,952 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 19:07:28,953 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 19:07:28,953 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 19:07:28,960 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 19:07:29,909 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:29,910 INFO  mapreduce.Job - Running job: job_local1238561642_0001
2020-05-02 19:07:30,919 INFO  mapreduce.Job - Job job_local1238561642_0001 running in uber mode : false
2020-05-02 19:07:30,921 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:31,043 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:07:31,044 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:07:31,044 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:07:31,117 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:07:31,117 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:07:31,117 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:07:31,923 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:31,923 INFO  mapreduce.Job - Job job_local1238561642_0001 completed successfully
2020-05-02 19:07:31,952 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=6617094
		FILE: Number of bytes written=10465693
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=188
		Map output records=188
		Map output bytes=13684
		Map output materialized bytes=889
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=889
		Reduce input records=188
		Reduce output records=4
		Spilled Records=376
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=15208
	File Output Format Counters 
		Bytes Written=1540
2020-05-02 19:07:31,980 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 19:07:31, elapsed: 00:00:03
2020-05-02 19:07:33,490 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:33,932 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 19:07:33
2020-05-02 19:07:33,932 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 19:07:33,932 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 19:07:33,933 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 19:07:33,933 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 19:07:33,933 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502190710
2020-05-02 19:07:35,385 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:35,386 INFO  mapreduce.Job - Running job: job_local1603073375_0001
2020-05-02 19:07:36,397 INFO  mapreduce.Job - Job job_local1603073375_0001 running in uber mode : false
2020-05-02 19:07:36,398 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:36,399 INFO  mapreduce.Job - Job job_local1603073375_0001 completed successfully
2020-05-02 19:07:36,414 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2804282
		FILE: Number of bytes written=4480816
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=7091
	File Output Format Counters 
		Bytes Written=279
2020-05-02 19:07:36,414 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 19:07:36,830 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:36,830 INFO  mapreduce.Job - Running job: job_local1736692884_0002
2020-05-02 19:07:37,831 INFO  mapreduce.Job - Job job_local1736692884_0002 running in uber mode : false
2020-05-02 19:07:37,831 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:37,832 INFO  mapreduce.Job - Job job_local1736692884_0002 completed successfully
2020-05-02 19:07:37,837 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5588577
		FILE: Number of bytes written=8963155
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=276
	File Output Format Counters 
		Bytes Written=279
2020-05-02 19:07:37,858 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 19:07:37, elapsed: 00:00:03
2020-05-02 19:07:39,060 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 19:07:39
2020-05-02 19:07:39,430 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:40,813 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:40,814 INFO  mapreduce.Job - Running job: job_local769570520_0001
2020-05-02 19:07:41,821 INFO  mapreduce.Job - Job job_local769570520_0001 running in uber mode : false
2020-05-02 19:07:41,823 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:41,825 INFO  mapreduce.Job - Job job_local769570520_0001 completed successfully
2020-05-02 19:07:41,838 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2788450
		FILE: Number of bytes written=4480350
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1056
		Map output materialized bytes=1080
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1080
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1152
	File Output Format Counters 
		Bytes Written=98
2020-05-02 19:07:41,843 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 19:07:41,843 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 19:07:42,169 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:42,169 INFO  mapreduce.Job - Running job: job_local1297836942_0002
2020-05-02 19:07:43,173 INFO  mapreduce.Job - Job job_local1297836942_0002 running in uber mode : false
2020-05-02 19:07:43,174 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:43,174 INFO  mapreduce.Job - Job job_local1297836942_0002 completed successfully
2020-05-02 19:07:43,180 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7443771
		FILE: Number of bytes written=11956213
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=916
		Map output materialized bytes=946
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=946
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1250
	File Output Format Counters 
		Bytes Written=1301
2020-05-02 19:07:43,202 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 19:07:43, elapsed: 00:00:04
2020-05-02 19:07:44,533 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:45,031 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190710.
2020-05-02 19:07:45,034 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:07:45
2020-05-02 19:07:45,045 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 19:07:45,046 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 19:07:45,046 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 19:07:45,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:07:45,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:07:45,047 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190710
2020-05-02 19:07:46,244 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:46,245 INFO  mapreduce.Job - Running job: job_local400380403_0001
2020-05-02 19:07:47,251 INFO  mapreduce.Job - Job job_local400380403_0001 running in uber mode : false
2020-05-02 19:07:47,252 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:48,116 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:07:48,163 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:07:48,574 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:07:49,406 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 19:07:49,407 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:07:50,259 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:50,260 INFO  mapreduce.Job - Job job_local400380403_0001 completed successfully
2020-05-02 19:07:50,287 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=11120314
		FILE: Number of bytes written=17806895
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=196
		Map output records=196
		Map output bytes=118049
		Map output materialized bytes=118525
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=118525
		Reduce input records=196
		Reduce output records=4
		Spilled Records=392
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=281
		Total committed heap usage (bytes)=4902617088
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=57657
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:07:50,287 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:07:50,296 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 19:07:50,312 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:07:50, elapsed: 00:00:05
2020-05-02 19:07:52,010 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 19:07:52
2020-05-02 19:07:52,305 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:53,825 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:53,826 INFO  mapreduce.Job - Running job: job_local2104914791_0001
2020-05-02 19:07:54,448 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:07:54,469 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:07:54,836 INFO  mapreduce.Job - Job job_local2104914791_0001 running in uber mode : false
2020-05-02 19:07:54,837 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:54,875 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 19:07:55,838 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:55,839 INFO  mapreduce.Job - Job job_local2104914791_0001 completed successfully
2020-05-02 19:07:55,853 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1856662
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=477626368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1054
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:07:55,873 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 19:07:55, elapsed: 00:00:03
2020-05-02 19:08:07,766 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:08,170 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:08:08
2020-05-02 19:08:08,170 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190710
2020-05-02 19:08:09,180 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:09,181 INFO  mapreduce.Job - Running job: job_local1047573533_0001
2020-05-02 19:08:10,189 INFO  mapreduce.Job - Job job_local1047573533_0001 running in uber mode : false
2020-05-02 19:08:10,190 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:08:10,511 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:08:10,518 INFO  parse.ParseSegment - Parsed (853ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:08:10,598 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:08:10,660 INFO  parse.ParseSegment - Parsed (58ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:08:10,904 INFO  parse.ParseSegment - Parsed (242ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:08:11,105 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:08:11,194 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:08:11,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:08:12,198 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:08:12,199 INFO  mapreduce.Job - Job job_local1047573533_0001 completed successfully
2020-05-02 19:08:12,226 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318214
		FILE: Number of bytes written=5135506
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149951
		Map output materialized bytes=149979
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149979
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1171783680
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78433
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:08:12,244 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:08:12, elapsed: 00:00:04
2020-05-02 19:08:13,331 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:13,717 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190710.
2020-05-02 19:08:13,719 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:08:13
2020-05-02 19:08:13,729 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:08:13,730 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:08:13,730 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:08:13,732 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:08:13,732 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:08:13,732 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190710
2020-05-02 19:08:14,667 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:14,668 INFO  mapreduce.Job - Running job: job_local113251858_0001
2020-05-02 19:08:15,178 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,298 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,410 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,547 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,624 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,674 INFO  mapreduce.Job - Job job_local113251858_0001 running in uber mode : false
2020-05-02 19:08:15,675 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:08:15,761 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,854 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:16,056 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:08:16,088 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:08:16,522 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:08:17,131 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 19:08:17,132 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:08:17,682 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:08:17,683 INFO  mapreduce.Job - Job job_local113251858_0001 completed successfully
2020-05-02 19:08:17,711 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10645594
		FILE: Number of bytes written=17131387
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=221586
		Map output materialized bytes=222088
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=222088
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=180
		Total committed heap usage (bytes)=6193414144
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=98495
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:08:17,711 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:08:17,719 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 19:08:17,747 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:08:17, elapsed: 00:00:04
2020-05-02 19:08:46,382 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:46,737 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:08:46
2020-05-02 19:08:46,750 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190710
2020-05-02 19:08:47,829 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:47,830 INFO  mapreduce.Job - Running job: job_local1186634806_0001
2020-05-02 19:08:48,837 INFO  mapreduce.Job - Job job_local1186634806_0001 running in uber mode : false
2020-05-02 19:08:48,838 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:08:49,452 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:08:49,461 INFO  parse.ParseSegment - Parsed (1104ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:08:49,556 INFO  parse.ParseSegment - Parsed (87ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:08:49,628 INFO  parse.ParseSegment - Parsed (69ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:08:49,916 INFO  parse.ParseSegment - Parsed (286ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:08:50,136 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:08:50,280 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:08:50,844 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:08:50,845 INFO  mapreduce.Job - Job job_local1186634806_0001 completed successfully
2020-05-02 19:08:50,862 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318214
		FILE: Number of bytes written=5135626
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149951
		Map output materialized bytes=149979
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149979
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78433
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:08:50,878 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:08:50, elapsed: 00:00:04
2020-05-02 19:08:51,969 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:52,464 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190710.
2020-05-02 19:08:52,466 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:08:52
2020-05-02 19:08:52,475 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:08:52,475 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:08:52,475 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:08:52,477 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:08:52,477 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:08:52,477 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190710
2020-05-02 19:08:53,404 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:53,405 INFO  mapreduce.Job - Running job: job_local1081988311_0001
2020-05-02 19:09:32,018 INFO  crawl.Injector - Injector: starting at 2020-05-02 19:09:32
2020-05-02 19:09:32,019 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 19:09:32,019 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 19:09:32,019 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 19:09:32,161 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:32,568 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 19:09:33,366 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:33,366 INFO  mapreduce.Job - Running job: job_local1572039161_0001
2020-05-02 19:09:33,803 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 19:09:34,024 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 19:09:34,024 INFO  crawl.Injector - Injector: update: false
2020-05-02 19:09:34,376 INFO  mapreduce.Job - Job job_local1572039161_0001 running in uber mode : false
2020-05-02 19:09:34,378 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:34,379 INFO  mapreduce.Job - Job job_local1572039161_0001 completed successfully
2020-05-02 19:09:34,392 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1857472
		FILE: Number of bytes written=2990872
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=824
		Map output materialized bytes=854
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=854
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=12
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1264
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 12
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total new urls injected: 12
2020-05-02 19:09:34,422 INFO  crawl.Injector - Injector: finished at 2020-05-02 19:09:34, elapsed: 00:00:02
2020-05-02 19:09:35,472 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:35,893 INFO  crawl.Generator - Generator: starting at 2020-05-02 19:09:35
2020-05-02 19:09:35,893 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 19:09:35,894 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 19:09:35,894 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 19:09:35,897 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 19:09:36,763 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:36,764 INFO  mapreduce.Job - Running job: job_local1949161384_0001
2020-05-02 19:09:37,205 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:09:37,205 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:09:37,205 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:09:37,212 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 19:09:37,423 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 19:09:37,782 INFO  mapreduce.Job - Job job_local1949161384_0001 running in uber mode : false
2020-05-02 19:09:37,784 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:37,786 INFO  mapreduce.Job - Job job_local1949161384_0001 completed successfully
2020-05-02 19:09:37,801 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785867
		FILE: Number of bytes written=4496588
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1172
		Map output materialized bytes=211
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=211
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1022
	File Output Format Counters 
		Bytes Written=16
2020-05-02 19:09:37,801 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 19:09:37,807 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 19:09:38,813 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502190938
2020-05-02 19:09:39,055 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:39,056 INFO  mapreduce.Job - Running job: job_local989571258_0002
2020-05-02 19:09:40,060 INFO  mapreduce.Job - Job job_local989571258_0002 running in uber mode : false
2020-05-02 19:09:40,061 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:40,061 INFO  mapreduce.Job - Job job_local989571258_0002 completed successfully
2020-05-02 19:09:40,066 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3715578
		FILE: Number of bytes written=5985853
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1600
		Map output materialized bytes=241
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=241
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1396
	File Output Format Counters 
		Bytes Written=1278
2020-05-02 19:09:40,086 INFO  crawl.Generator - Generator: finished at 2020-05-02 19:09:40, elapsed: 00:00:04
2020-05-02 19:09:41,086 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 19:09:41
2020-05-02 19:09:41,087 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502190938
2020-05-02 19:09:41,087 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588432181087  (2020-05-02 22:09:41)
2020-05-02 19:09:41,309 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:42,499 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:42,500 INFO  mapreduce.Job - Running job: job_local494711029_0001
2020-05-02 19:09:42,693 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 19:09:42,693 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 19:09:42,693 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 19:09:42,704 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 12 records hit by time limit : 0
2020-05-02 19:09:42,978 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,002 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,002 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,003 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:43,213 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 19:09:43,215 INFO  http.Http - http.proxy.host = null
2020-05-02 19:09:43,215 INFO  http.Http - http.proxy.port = 8080
2020-05-02 19:09:43,215 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 19:09:43,216 INFO  http.Http - http.timeout = 30000
2020-05-02 19:09:43,216 INFO  http.Http - http.content.limit = -1
2020-05-02 19:09:43,216 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 19:09:43,216 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 19:09:43,216 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 19:09:43,216 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 19:09:43,236 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,237 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,237 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,240 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,241 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,244 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,245 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,245 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,246 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,252 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,253 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,265 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,266 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,267 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,270 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,272 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,272 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,273 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,275 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,277 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,277 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,279 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,279 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,280 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,290 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,291 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,298 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,299 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,304 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,305 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,391 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,392 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,393 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,394 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,396 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,396 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,397 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,398 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,398 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,399 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,401 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,403 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,415 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,416 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,416 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,417 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,424 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,425 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,427 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,428 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,435 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,436 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,437 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,437 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,444 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,445 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,458 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,459 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,461 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,461 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,461 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,462 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,463 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,463 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,464 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,464 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,467 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,468 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,468 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,469 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,470 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,471 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,473 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,473 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,478 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,479 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,480 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,482 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,483 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,484 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,485 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,490 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,491 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,492 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,493 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,494 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 19:09:43,494 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 19:09:43,494 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 19:09:43,509 INFO  mapreduce.Job - Job job_local494711029_0001 running in uber mode : false
2020-05-02 19:09:43,511 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:09:44,499 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2020-05-02 19:09:45,003 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:45,303 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/imac-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:45,504 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-02 19:09:46,509 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-02 19:09:46,940 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:47,513 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2020-05-02 19:09:47,551 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/imac/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:48,517 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2020-05-02 19:09:48,725 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:49,509 INFO  fetcher.FetcherThread - FetcherThread 82 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:49,520 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-02 19:09:49,822 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:50,245 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:50,522 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:09:50,522 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421390081
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   now           = 1588421390523
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-02 19:09:50,940 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:51,208 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:51,528 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421391208
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   now           = 1588421391528
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/ipad-air/specs/
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=45
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=48
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=49
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 19:09:51,999 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=44
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 19:09:52,001 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 19:09:52,002 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=42
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=47
2020-05-02 19:09:52,009 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 19:09:52,009 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=41
2020-05-02 19:09:52,019 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 19:09:52,019 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=40
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=39
2020-05-02 19:09:52,024 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=36
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=35
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=34
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=33
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=32
2020-05-02 19:09:52,032 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 19:09:52,032 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:09:52,033 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 19:09:52,033 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=30
2020-05-02 19:09:52,086 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 19:09:52,087 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=29
2020-05-02 19:09:52,272 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 19:09:52,273 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=28
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=27
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=26
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 19:09:52,291 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=25
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=24
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=23
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=22
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=21
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=20
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=19
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=18
2020-05-02 19:09:52,317 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 19:09:52,317 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 19:09:52,318 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=17
2020-05-02 19:09:52,318 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=16
2020-05-02 19:09:52,342 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 19:09:52,342 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=15
2020-05-02 19:09:52,421 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 19:09:52,421 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 19:09:52,422 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=14
2020-05-02 19:09:52,422 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=13
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=9
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=8
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=7
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=6
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=10
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=11
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=12
2020-05-02 19:09:52,443 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=5
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=4
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=3
2020-05-02 19:09:52,481 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 19:09:52,481 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=2
2020-05-02 19:09:52,494 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 19:09:52,494 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=1
2020-05-02 19:09:52,530 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 19:09:52,669 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 19:09:52,669 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=0
2020-05-02 19:09:53,531 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 19:09:53,531 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 19:09:54,552 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:54,552 INFO  mapreduce.Job - Job job_local494711029_0001 completed successfully
2020-05-02 19:09:54,584 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3319217
		FILE: Number of bytes written=5652874
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=24
		Map output bytes=1358473
		Map output materialized bytes=213453
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=213453
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=92
		Total committed heap usage (bytes)=968884224
	FetcherStatus
		bytes_downloaded=1346765
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1278
	File Output Format Counters 
		Bytes Written=221716
2020-05-02 19:09:54,585 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 19:09:54, elapsed: 00:00:13
2020-05-02 19:09:55,831 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:56,270 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:09:56
2020-05-02 19:09:56,270 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:09:57,250 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:57,251 INFO  mapreduce.Job - Running job: job_local1906531787_0001
2020-05-02 19:09:58,257 INFO  mapreduce.Job - Job job_local1906531787_0001 running in uber mode : false
2020-05-02 19:09:58,258 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:09:58,684 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:09:58,692 INFO  parse.ParseSegment - Parsed (948ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:09:58,763 INFO  parse.ParseSegment - Parsed (66ms):https://www.apple.com/imac/specs/
2020-05-02 19:09:58,823 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:09:58,885 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:09:58,941 INFO  parse.ParseSegment - Parsed (52ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:09:58,995 INFO  parse.ParseSegment - Parsed (52ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:09:59,045 INFO  parse.ParseSegment - Parsed (48ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:09:59,295 INFO  parse.ParseSegment - Parsed (248ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:09:59,359 INFO  parse.ParseSegment - Parsed (63ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:09:59,494 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:09:59,494 INFO  parse.ParseSegment - Parsed (30ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:09:59,525 INFO  parse.ParseSegment - Parsed (29ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:09:59,562 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:09:59,695 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:59,852 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:09:59,985 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:10:00,085 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:10:00,265 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 19:10:01,267 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:01,269 INFO  mapreduce.Job - Job job_local1906531787_0001 completed successfully
2020-05-02 19:10:01,291 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4773879
		FILE: Number of bytes written=6697388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=96972
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=96972
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=88
		Total committed heap usage (bytes)=1594359808
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:10:01,315 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:10:01, elapsed: 00:00:05
2020-05-02 19:10:02,833 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 19:10:03
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502190938]
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 19:10:03,266 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 19:10:04,083 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:04,085 INFO  mapreduce.Job - Running job: job_local1014735562_0001
2020-05-02 19:10:05,095 INFO  mapreduce.Job - Job job_local1014735562_0001 running in uber mode : false
2020-05-02 19:10:05,097 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:10:05,393 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:10:05,393 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:10:05,393 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:10:05,509 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:10:05,509 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:10:05,509 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:10:06,101 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:06,103 INFO  mapreduce.Job - Job job_local1014735562_0001 completed successfully
2020-05-02 19:10:06,137 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=7181133
		FILE: Number of bytes written=10616916
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1236
		Map output records=1236
		Map output bytes=90629
		Map output materialized bytes=7363
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=7363
		Reduce input records=1236
		Reduce output records=798
		Spilled Records=2472
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=12
		db_unfetched=786
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=96772
	File Output Format Counters 
		Bytes Written=67516
2020-05-02 19:10:06,161 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 19:10:06, elapsed: 00:00:02
2020-05-02 19:10:07,582 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:08,029 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 19:10:08
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502190938
2020-05-02 19:10:09,393 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:09,394 INFO  mapreduce.Job - Running job: job_local1735656804_0001
2020-05-02 19:10:10,401 INFO  mapreduce.Job - Job job_local1735656804_0001 running in uber mode : false
2020-05-02 19:10:10,402 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:10,404 INFO  mapreduce.Job - Job job_local1735656804_0001 completed successfully
2020-05-02 19:10:10,416 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2832981
		FILE: Number of bytes written=4484311
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=332
		Combine input records=7
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17291
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:10:10,416 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 19:10:10,724 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:10,725 INFO  mapreduce.Job - Running job: job_local1142832152_0002
2020-05-02 19:10:11,055 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 19:10:11,727 INFO  mapreduce.Job - Job job_local1142832152_0002 running in uber mode : false
2020-05-02 19:10:11,727 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:11,728 INFO  mapreduce.Job - Job job_local1142832152_0002 completed successfully
2020-05-02 19:10:11,733 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5626726
		FILE: Number of bytes written=8973139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1017
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:10:11,756 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 19:10:11, elapsed: 00:00:03
2020-05-02 19:10:12,724 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 19:10:12
2020-05-02 19:10:12,961 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:14,158 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:14,159 INFO  mapreduce.Job - Running job: job_local550841849_0001
2020-05-02 19:10:15,169 INFO  mapreduce.Job - Job job_local550841849_0001 running in uber mode : false
2020-05-02 19:10:15,170 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:15,172 INFO  mapreduce.Job - Job job_local550841849_0001 completed successfully
2020-05-02 19:10:15,188 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2956832
		FILE: Number of bytes written=4486482
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=12
		Map output bytes=3164
		Map output materialized bytes=3212
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=3212
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66898
	File Output Format Counters 
		Bytes Written=98
2020-05-02 19:10:15,193 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 19:10:15,194 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 19:10:15,533 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:15,533 INFO  mapreduce.Job - Running job: job_local443855507_0002
2020-05-02 19:10:16,535 INFO  mapreduce.Job - Job job_local443855507_0002 running in uber mode : false
2020-05-02 19:10:16,535 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:16,536 INFO  mapreduce.Job - Job job_local443855507_0002 completed successfully
2020-05-02 19:10:16,541 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8073400
		FILE: Number of bytes written=12297309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=798
		Map output bytes=59182
		Map output materialized bytes=60808
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=60808
		Reduce input records=798
		Reduce output records=798
		Spilled Records=1596
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=67156
2020-05-02 19:10:16,561 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 19:10:16, elapsed: 00:00:03
2020-05-02 19:10:17,633 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:18,007 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:10:18,027 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:10:18
2020-05-02 19:10:18,044 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 19:10:18,044 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 19:10:18,045 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 19:10:18,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:10:18,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:10:18,047 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:10:18,945 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:18,946 INFO  mapreduce.Job - Running job: job_local86927638_0001
2020-05-02 19:10:19,952 INFO  mapreduce.Job - Job job_local86927638_0001 running in uber mode : false
2020-05-02 19:10:19,953 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:10:20,640 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:10:20,677 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:10:21,009 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:10:21,626 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:10:21,626 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:10:21,961 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:21,962 INFO  mapreduce.Job - Job job_local86927638_0001 completed successfully
2020-05-02 19:10:21,980 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13607588
		FILE: Number of bytes written=20664976
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2053
		Map output records=2053
		Map output bytes=439257
		Map output materialized bytes=443495
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=443495
		Reduce input records=2053
		Reduce output records=12
		Spilled Records=4106
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=242
		Total committed heap usage (bytes)=4902617088
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=262494
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:10:21,981 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:10:21,990 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:10:22,010 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:10:21, elapsed: 00:00:03
2020-05-02 19:10:22,990 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 19:10:22
2020-05-02 19:10:23,237 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:24,446 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:24,447 INFO  mapreduce.Job - Running job: job_local613133701_0001
2020-05-02 19:10:25,030 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:10:25,054 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:10:25,386 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 19:10:25,454 INFO  mapreduce.Job - Job job_local613133701_0001 running in uber mode : false
2020-05-02 19:10:25,455 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:25,456 INFO  mapreduce.Job - Job job_local613133701_0001 completed successfully
2020-05-02 19:10:25,471 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1988196
		FILE: Number of bytes written=2980390
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=79
		Total committed heap usage (bytes)=477626368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66820
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:10:25,491 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 19:10:25, elapsed: 00:00:02
2020-05-02 19:11:28,073 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:11:28,430 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:11:28
2020-05-02 19:11:28,432 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:11:29,676 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:11:29,677 INFO  mapreduce.Job - Running job: job_local4674744_0001
2020-05-02 19:11:30,744 INFO  mapreduce.Job - Job job_local4674744_0001 running in uber mode : false
2020-05-02 19:11:30,745 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:11:31,202 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:11:31,211 INFO  parse.ParseSegment - Parsed (942ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:11:31,316 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/imac/specs/
2020-05-02 19:11:31,395 INFO  parse.ParseSegment - Parsed (76ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:11:31,462 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:11:31,528 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:11:31,581 INFO  parse.ParseSegment - Parsed (51ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:11:31,634 INFO  parse.ParseSegment - Parsed (51ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:11:31,895 INFO  parse.ParseSegment - Parsed (259ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:11:31,965 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:11:32,110 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:11:32,110 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:11:32,147 INFO  parse.ParseSegment - Parsed (34ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:11:32,190 INFO  parse.ParseSegment - Parsed (42ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:11:32,339 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:11:32,473 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:11:32,747 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:11:32,748 INFO  mapreduce.Job - Job job_local4674744_0001 completed successfully
2020-05-02 19:11:32,764 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205315
		FILE: Number of bytes written=6191777
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=410945
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410945
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=86
		Total committed heap usage (bytes)=1166016512
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:11:32,777 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:11:32, elapsed: 00:00:04
2020-05-02 19:11:33,846 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:11:34,227 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:11:34,230 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:11:34
2020-05-02 19:11:34,244 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:11:34,252 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:11:34,252 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:11:34,253 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:11:34,253 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:11:34,253 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:11:35,178 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:11:35,179 INFO  mapreduce.Job - Running job: job_local500473406_0001
2020-05-02 19:11:35,711 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,182 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,187 INFO  mapreduce.Job - Job job_local500473406_0001 running in uber mode : false
2020-05-02 19:11:36,189 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:11:36,278 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,465 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,552 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,655 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,742 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,802 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,837 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,982 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:11:37,019 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:11:37,466 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:11:38,169 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:11:38,169 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:11:39,197 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:11:39,198 INFO  mapreduce.Job - Job job_local500473406_0001 completed successfully
2020-05-02 19:11:39,234 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13500913
		FILE: Number of bytes written=20833479
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=662059
		Map output materialized bytes=666363
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=666363
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=169
		Total committed heap usage (bytes)=6195511296
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=339740
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:11:39,235 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:11:39,244 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:11:39,279 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:11:39, elapsed: 00:00:05
2020-05-02 19:14:12,393 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:12,853 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:14:12
2020-05-02 19:14:12,853 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:14:14,099 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:14,100 INFO  mapreduce.Job - Running job: job_local613504018_0001
2020-05-02 19:14:15,126 INFO  mapreduce.Job - Job job_local613504018_0001 running in uber mode : false
2020-05-02 19:14:15,127 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:14:15,552 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:15,559 INFO  parse.ParseSegment - Parsed (910ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:14:15,649 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/imac/specs/
2020-05-02 19:14:15,707 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:14:15,769 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:14:15,828 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:14:15,894 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:14:15,955 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:14:16,194 INFO  parse.ParseSegment - Parsed (237ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:14:16,297 INFO  parse.ParseSegment - Parsed (101ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:14:16,443 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:16,444 INFO  parse.ParseSegment - Parsed (39ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:14:16,481 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:14:16,529 INFO  parse.ParseSegment - Parsed (45ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:14:16,665 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:14:16,791 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:14:17,132 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:14:17,132 INFO  mapreduce.Job - Job job_local613504018_0001 completed successfully
2020-05-02 19:14:17,155 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205315
		FILE: Number of bytes written=6208106
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=410945
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410945
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=82
		Total committed heap usage (bytes)=1162870784
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:14:17,176 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:14:17, elapsed: 00:00:04
2020-05-02 19:14:18,409 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:18,869 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:14:18,874 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:14:18
2020-05-02 19:14:18,887 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:14:18,887 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:14:18,887 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:14:18,889 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:14:18,889 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:14:18,889 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:14:19,903 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:19,904 INFO  mapreduce.Job - Running job: job_local1357022972_0001
2020-05-02 19:14:20,459 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:20,911 INFO  mapreduce.Job - Job job_local1357022972_0001 running in uber mode : false
2020-05-02 19:14:20,912 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:14:21,071 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,172 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,475 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,681 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,829 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,909 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,917 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-02 19:14:21,957 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,993 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:22,103 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:14:22,130 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:14:22,613 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:14:22,921 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:14:23,293 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:14:23,295 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:14:23,927 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:14:23,927 INFO  mapreduce.Job - Job job_local1357022972_0001 completed successfully
2020-05-02 19:14:23,950 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13500643
		FILE: Number of bytes written=20860799
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=662059
		Map output materialized bytes=666363
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=666363
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=168
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=339713
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:14:23,950 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:14:23,967 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:14:23,999 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:14:23, elapsed: 00:00:05
2020-05-02 19:14:53,050 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:53,412 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:14:53
2020-05-02 19:14:53,412 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:14:54,179 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:54,180 INFO  mapreduce.Job - Running job: job_local1334528602_0001
2020-05-02 19:14:55,188 INFO  mapreduce.Job - Job job_local1334528602_0001 running in uber mode : false
2020-05-02 19:14:55,189 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:14:55,448 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:55,455 INFO  parse.ParseSegment - Parsed (809ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:14:55,529 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/imac/specs/
2020-05-02 19:14:55,594 INFO  parse.ParseSegment - Parsed (62ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:14:55,657 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:14:55,725 INFO  parse.ParseSegment - Parsed (66ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:14:55,788 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:14:55,844 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:14:56,071 INFO  parse.ParseSegment - Parsed (226ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:14:56,152 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:14:56,195 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:14:56,298 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:56,299 INFO  parse.ParseSegment - Parsed (34ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:14:56,324 INFO  parse.ParseSegment - Parsed (24ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:14:56,370 INFO  parse.ParseSegment - Parsed (44ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:14:56,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:14:56,616 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:14:57,200 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:14:57,201 INFO  mapreduce.Job - Job job_local1334528602_0001 completed successfully
2020-05-02 19:14:57,215 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205315
		FILE: Number of bytes written=6217093
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=410945
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410945
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=1170735104
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:14:57,233 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:14:57, elapsed: 00:00:03
2020-05-02 19:14:58,237 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:58,588 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:14:58,591 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:14:58
2020-05-02 19:14:58,602 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:14:58,602 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:14:58,602 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:14:58,603 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:14:58,603 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:14:58,603 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:14:59,510 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:59,511 INFO  mapreduce.Job - Running job: job_local317017543_0001
2020-05-02 19:14:59,950 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,425 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,521 INFO  mapreduce.Job - Job job_local317017543_0001 running in uber mode : false
2020-05-02 19:15:00,522 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:15:00,544 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,660 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,755 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,837 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,923 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,964 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:01,000 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:01,113 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:15:01,135 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:15:01,541 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:15:02,137 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:15:02,138 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:15:02,528 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:15:02,529 INFO  mapreduce.Job - Job job_local317017543_0001 completed successfully
2020-05-02 19:15:02,559 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13508793
		FILE: Number of bytes written=20833459
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=662059
		Map output materialized bytes=666363
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=666363
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=161
		Total committed heap usage (bytes)=6167199744
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=340528
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:15:02,559 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:15:02,567 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:15:02,592 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:15:02, elapsed: 00:00:03
2020-05-02 19:15:11,984 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:15:12,364 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:15:12
2020-05-02 19:15:12,364 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:15:13,429 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:15:13,431 INFO  mapreduce.Job - Running job: job_local1958081519_0001
2020-05-02 19:15:14,439 INFO  mapreduce.Job - Job job_local1958081519_0001 running in uber mode : false
2020-05-02 19:15:14,440 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:15:14,884 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:15:14,895 INFO  parse.ParseSegment - Parsed (1003ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:15:15,035 INFO  parse.ParseSegment - Parsed (134ms):https://www.apple.com/imac/specs/
2020-05-02 19:15:15,122 INFO  parse.ParseSegment - Parsed (83ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:15:15,244 INFO  parse.ParseSegment - Parsed (120ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:15:15,337 INFO  parse.ParseSegment - Parsed (91ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:15:15,429 INFO  parse.ParseSegment - Parsed (90ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:15:15,504 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:15:15,569 INFO  parse.ParseSegment - Parsed (63ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:15:15,652 INFO  parse.ParseSegment - Parsed (81ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:15:15,739 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:15:15,740 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:15:15,771 INFO  parse.ParseSegment - Parsed (30ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:15:15,981 INFO  parse.ParseSegment - Parsed (208ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:15:16,105 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:15:16,219 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:15:16,451 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:15:16,451 INFO  mapreduce.Job - Job job_local1958081519_0001 completed successfully
2020-05-02 19:15:16,471 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4312539
		FILE: Number of bytes written=6449335
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=464497
		Map output materialized bytes=464557
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=464557
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=235
		Total committed heap usage (bytes)=1329594368
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:15:16,497 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:15:16, elapsed: 00:00:04
2020-05-02 19:15:17,534 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:15:17,896 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:15:17,899 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:15:17
2020-05-02 19:15:17,915 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:15:17,915 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:15:17,916 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:15:17,917 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:15:17,917 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:15:17,918 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:15:19,162 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:15:19,165 INFO  mapreduce.Job - Running job: job_local1802074168_0001
2020-05-02 19:15:19,688 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,067 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,169 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,177 INFO  mapreduce.Job - Job job_local1802074168_0001 running in uber mode : false
2020-05-02 19:15:20,178 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:15:20,309 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,395 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,508 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,582 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,625 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,681 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,809 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:15:20,841 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:15:21,303 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:15:21,953 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:15:21,958 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:15:22,192 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:15:22,194 INFO  mapreduce.Job - Job job_local1802074168_0001 completed successfully
2020-05-02 19:15:22,225 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13754291
		FILE: Number of bytes written=21236083
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=715671
		Map output materialized bytes=719975
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=719975
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=168
		Total committed heap usage (bytes)=6165102592
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=363585
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:15:22,225 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:15:22,235 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:15:22,268 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:15:22, elapsed: 00:00:04
2020-05-02 19:22:14,193 INFO  crawl.Injector - Injector: starting at 2020-05-02 19:22:14
2020-05-02 19:22:14,193 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 19:22:14,194 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 19:22:14,194 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 19:22:14,361 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:14,753 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 19:22:15,845 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:15,846 INFO  mapreduce.Job - Running job: job_local1847089440_0001
2020-05-02 19:22:16,331 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 19:22:16,536 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 19:22:16,536 INFO  crawl.Injector - Injector: update: false
2020-05-02 19:22:16,852 INFO  mapreduce.Job - Job job_local1847089440_0001 running in uber mode : false
2020-05-02 19:22:16,853 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:16,855 INFO  mapreduce.Job - Job job_local1847089440_0001 completed successfully
2020-05-02 19:22:16,867 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1857472
		FILE: Number of bytes written=2990868
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=824
		Map output materialized bytes=854
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=854
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=12
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1264
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 12
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total new urls injected: 12
2020-05-02 19:22:16,901 INFO  crawl.Injector - Injector: finished at 2020-05-02 19:22:16, elapsed: 00:00:02
2020-05-02 19:22:18,022 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: starting at 2020-05-02 19:22:18
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 19:22:18,460 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 19:22:19,334 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:19,334 INFO  mapreduce.Job - Running job: job_local564964933_0001
2020-05-02 19:22:19,779 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:22:19,779 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:22:19,779 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:22:19,788 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 19:22:19,964 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 19:22:20,343 INFO  mapreduce.Job - Job job_local564964933_0001 running in uber mode : false
2020-05-02 19:22:20,345 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:20,346 INFO  mapreduce.Job - Job job_local564964933_0001 completed successfully
2020-05-02 19:22:20,360 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785867
		FILE: Number of bytes written=4488344
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1172
		Map output materialized bytes=211
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=211
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1022
	File Output Format Counters 
		Bytes Written=16
2020-05-02 19:22:20,360 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 19:22:20,365 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 19:22:21,366 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502192221
2020-05-02 19:22:21,622 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:21,622 INFO  mapreduce.Job - Running job: job_local1171300427_0002
2020-05-02 19:22:22,626 INFO  mapreduce.Job - Job job_local1171300427_0002 running in uber mode : false
2020-05-02 19:22:22,626 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:22,627 INFO  mapreduce.Job - Job job_local1171300427_0002 completed successfully
2020-05-02 19:22:22,631 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3715576
		FILE: Number of bytes written=5985822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1600
		Map output materialized bytes=240
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=240
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1396
	File Output Format Counters 
		Bytes Written=1278
2020-05-02 19:22:22,649 INFO  crawl.Generator - Generator: finished at 2020-05-02 19:22:22, elapsed: 00:00:04
2020-05-02 19:22:23,740 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 19:22:23
2020-05-02 19:22:23,741 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502192221
2020-05-02 19:22:23,741 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588432943741  (2020-05-02 22:22:23)
2020-05-02 19:22:24,056 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:25,442 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:25,443 INFO  mapreduce.Job - Running job: job_local455603076_0001
2020-05-02 19:22:25,641 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 19:22:25,641 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 19:22:25,641 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 19:22:25,656 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 12 records hit by time limit : 0
2020-05-02 19:22:25,938 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:25,960 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:25,960 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:25,961 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:26,195 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 19:22:26,198 INFO  http.Http - http.proxy.host = null
2020-05-02 19:22:26,198 INFO  http.Http - http.proxy.port = 8080
2020-05-02 19:22:26,198 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 19:22:26,198 INFO  http.Http - http.timeout = 30000
2020-05-02 19:22:26,198 INFO  http.Http - http.content.limit = -1
2020-05-02 19:22:26,198 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 19:22:26,198 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 19:22:26,198 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 19:22:26,198 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 19:22:26,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,208 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,209 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,210 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,217 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,218 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,219 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,219 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,221 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,224 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,227 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,228 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,233 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,234 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,234 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,235 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,236 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,266 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,273 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,273 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,274 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,277 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,279 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,281 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,282 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,283 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,284 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,285 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,286 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,287 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,289 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,290 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,292 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,293 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,294 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,296 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,304 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,396 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,397 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,398 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,399 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,399 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,401 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,401 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,403 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,404 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,405 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,406 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,412 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,412 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,413 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,414 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,422 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,424 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,434 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,434 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,436 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,436 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,451 INFO  mapreduce.Job - Job job_local455603076_0001 running in uber mode : false
2020-05-02 19:22:26,453 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:22:26,462 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,462 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,466 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,468 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,470 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,471 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,472 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,473 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,474 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,475 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,477 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,478 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,479 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,481 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,482 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,483 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,484 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,485 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,486 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,487 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,488 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,488 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,491 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,492 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,492 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,493 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,495 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,496 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 19:22:26,496 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 19:22:26,496 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 19:22:27,503 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2020-05-02 19:22:27,752 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:28,015 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/imac-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:28,503 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-02 19:22:28,719 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:29,504 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2020-05-02 19:22:29,686 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/imac/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:30,506 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2020-05-02 19:22:30,627 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:31,479 INFO  fetcher.FetcherThread - FetcherThread 71 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:31,511 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-02 19:22:31,726 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:32,484 INFO  fetcher.FetcherThread - FetcherThread 70 fetching https://www.apple.com/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:32,511 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:22:32,511 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422152473
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   now           = 1588422152512
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:33,516 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422152473
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   now           = 1588422153517
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:33,701 INFO  fetcher.FetcherThread - FetcherThread 70 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:34,519 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-02 19:22:34,519 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:34,519 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:34,519 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422153701
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   now           = 1588422154520
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:34,926 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:35,522 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422154829
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   now           = 1588422155523
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:35,853 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:35,928 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 19:22:35,928 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=49
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=48
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:22:35,930 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:22:35,933 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 19:22:35,933 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=45
2020-05-02 19:22:35,947 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 19:22:35,947 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 19:22:35,947 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:22:35,948 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:22:35,948 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 19:22:35,948 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=42
2020-05-02 19:22:35,954 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 19:22:35,954 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=41
2020-05-02 19:22:35,957 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 19:22:35,957 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=40
2020-05-02 19:22:35,988 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 19:22:35,989 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=39
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=36
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=35
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=34
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=38
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 19:22:36,005 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=33
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 19:22:36,007 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:22:36,007 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=30
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 19:22:36,024 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=28
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 19:22:36,026 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=27
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 19:22:36,027 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=25
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 19:22:36,028 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=24
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 19:22:36,028 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=23
2020-05-02 19:22:36,016 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=29
2020-05-02 19:22:36,027 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=26
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 19:22:36,030 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=22
2020-05-02 19:22:36,135 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 19:22:36,135 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=21
2020-05-02 19:22:36,231 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 19:22:36,231 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 19:22:36,232 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=20
2020-05-02 19:22:36,232 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=19
2020-05-02 19:22:36,252 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=18
2020-05-02 19:22:36,252 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=16
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=17
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=15
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 19:22:36,267 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=14
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 19:22:36,267 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=13
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=12
2020-05-02 19:22:36,298 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=10
2020-05-02 19:22:36,298 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=11
2020-05-02 19:22:36,318 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 19:22:36,318 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=9
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=8
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=7
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=6
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=5
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=4
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=3
2020-05-02 19:22:36,328 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 19:22:36,328 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=2
2020-05-02 19:22:36,333 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 19:22:36,333 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=1
2020-05-02 19:22:36,525 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 19:22:36,875 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 19:22:36,875 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=0
2020-05-02 19:22:37,529 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 19:22:37,530 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 19:22:38,487 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:38,488 INFO  mapreduce.Job - Job job_local455603076_0001 completed successfully
2020-05-02 19:22:38,509 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3319141
		FILE: Number of bytes written=5652685
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=24
		Map output bytes=1358472
		Map output materialized bytes=213415
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=213415
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=105
		Total committed heap usage (bytes)=968884224
	FetcherStatus
		bytes_downloaded=1346765
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1278
	File Output Format Counters 
		Bytes Written=221699
2020-05-02 19:22:38,510 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 19:22:38, elapsed: 00:00:14
2020-05-02 19:22:39,997 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:40,440 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:22:40
2020-05-02 19:22:40,440 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-02 19:22:41,393 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:41,394 INFO  mapreduce.Job - Running job: job_local851368484_0001
2020-05-02 19:22:42,405 INFO  mapreduce.Job - Job job_local851368484_0001 running in uber mode : false
2020-05-02 19:22:42,406 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:22:42,845 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:22:42,859 INFO  parse.ParseSegment - Parsed (1006ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:22:42,986 INFO  parse.ParseSegment - Parsed (119ms):https://www.apple.com/imac/specs/
2020-05-02 19:22:43,078 INFO  parse.ParseSegment - Parsed (87ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:22:43,161 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:22:43,235 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:22:43,332 INFO  parse.ParseSegment - Parsed (77ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:22:43,414 INFO  parse.ParseSegment - Parsed (78ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:22:43,489 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:43,572 INFO  parse.ParseSegment - Parsed (81ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:22:43,768 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:22:43,769 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:43,823 INFO  parse.ParseSegment - Parsed (51ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:22:43,903 INFO  parse.ParseSegment - Parsed (78ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:22:44,053 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:44,197 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:22:44,324 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:44,409 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 19:22:44,415 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:22:45,412 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:45,414 INFO  mapreduce.Job - Job job_local851368484_0001 completed successfully
2020-05-02 19:22:45,435 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4790970
		FILE: Number of bytes written=6750209
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=464496
		Map output materialized bytes=104407
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=104407
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=94
		Total committed heap usage (bytes)=1539833856
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:22:45,450 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:22:45, elapsed: 00:00:04
2020-05-02 19:22:46,810 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:47,355 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 19:22:47
2020-05-02 19:22:47,355 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 19:22:47,357 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502192221]
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 19:22:47,362 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 19:22:48,364 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:48,365 INFO  mapreduce.Job - Running job: job_local859927944_0001
2020-05-02 19:22:49,376 INFO  mapreduce.Job - Job job_local859927944_0001 running in uber mode : false
2020-05-02 19:22:49,378 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:22:49,628 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:22:49,628 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:22:49,629 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:22:49,733 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:22:49,733 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:22:49,733 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:22:50,382 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:50,383 INFO  mapreduce.Job - Job job_local859927944_0001 completed successfully
2020-05-02 19:22:50,402 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=7185550
		FILE: Number of bytes written=10595485
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1236
		Map output records=1236
		Map output bytes=90629
		Map output materialized bytes=7088
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=7088
		Reduce input records=1236
		Reduce output records=798
		Spilled Records=2472
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=12
		db_unfetched=786
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=97550
	File Output Format Counters 
		Bytes Written=67516
2020-05-02 19:22:50,419 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 19:22:50, elapsed: 00:00:03
2020-05-02 19:22:51,852 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:52,297 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 19:22:52
2020-05-02 19:22:52,297 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 19:22:52,298 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 19:22:52,298 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 19:22:52,298 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 19:22:52,299 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502192221
2020-05-02 19:22:53,277 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:53,278 INFO  mapreduce.Job - Running job: job_local496578145_0001
2020-05-02 19:22:54,288 INFO  mapreduce.Job - Job job_local496578145_0001 running in uber mode : false
2020-05-02 19:22:54,289 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:54,290 INFO  mapreduce.Job - Job job_local496578145_0001 completed successfully
2020-05-02 19:22:54,303 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2899796
		FILE: Number of bytes written=4476139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=332
		Combine input records=7
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=40360
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:22:54,304 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 19:22:54,616 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:54,616 INFO  mapreduce.Job - Running job: job_local1738814066_0002
2020-05-02 19:22:54,951 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 19:22:55,031 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 19:22:55,618 INFO  mapreduce.Job - Job job_local1738814066_0002 running in uber mode : false
2020-05-02 19:22:55,619 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:55,619 INFO  mapreduce.Job - Job job_local1738814066_0002 completed successfully
2020-05-02 19:22:55,624 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5698749
		FILE: Number of bytes written=8966965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=1300
		Map output materialized bytes=1340
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1340
		Reduce input records=14
		Reduce output records=7
		Spilled Records=28
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1758
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:22:55,642 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 19:22:55, elapsed: 00:00:03
2020-05-02 19:22:56,674 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 19:22:56
2020-05-02 19:22:56,937 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:58,218 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:58,219 INFO  mapreduce.Job - Running job: job_local536792027_0001
2020-05-02 19:22:59,226 INFO  mapreduce.Job - Job job_local536792027_0001 running in uber mode : false
2020-05-02 19:22:59,228 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:59,229 INFO  mapreduce.Job - Job job_local536792027_0001 completed successfully
2020-05-02 19:22:59,256 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2956832
		FILE: Number of bytes written=4486488
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=12
		Map output bytes=3164
		Map output materialized bytes=3212
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=3212
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66898
	File Output Format Counters 
		Bytes Written=98
2020-05-02 19:22:59,263 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 19:22:59,263 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 19:22:59,602 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:59,602 INFO  mapreduce.Job - Running job: job_local1227513023_0002
2020-05-02 19:23:00,603 INFO  mapreduce.Job - Job job_local1227513023_0002 running in uber mode : false
2020-05-02 19:23:00,603 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:23:00,603 INFO  mapreduce.Job - Job job_local1227513023_0002 completed successfully
2020-05-02 19:23:00,608 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8073409
		FILE: Number of bytes written=12308217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=798
		Map output bytes=59182
		Map output materialized bytes=60808
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=60808
		Reduce input records=798
		Reduce output records=798
		Spilled Records=1596
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=67156
2020-05-02 19:23:00,629 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 19:23:00, elapsed: 00:00:03
2020-05-02 19:23:01,769 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:23:02,199 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-02 19:23:02,203 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:23:02
2020-05-02 19:23:02,218 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 19:23:02,218 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 19:23:02,218 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 19:23:02,220 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:23:02,220 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:23:02,220 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-02 19:23:03,161 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:23:03,162 INFO  mapreduce.Job - Running job: job_local302354623_0001
2020-05-02 19:23:04,201 INFO  mapreduce.Job - Job job_local302354623_0001 running in uber mode : false
2020-05-02 19:23:04,204 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:23:05,047 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:23:05,108 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:23:05,490 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:23:06,331 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:23:06,332 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:23:07,212 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:23:07,213 INFO  mapreduce.Job - Job job_local302354623_0001 completed successfully
2020-05-02 19:23:07,255 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13885539
		FILE: Number of bytes written=21206670
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2053
		Map output records=2053
		Map output bytes=492868
		Map output materialized bytes=497106
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=497106
		Reduce input records=2053
		Reduce output records=12
		Spilled Records=4106
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=240
		Total committed heap usage (bytes)=4899471360
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=286341
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:23:07,255 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:23:07,269 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:23:07,302 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:23:07, elapsed: 00:00:05
2020-05-02 19:23:08,411 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 19:23:08
2020-05-02 19:23:08,662 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:23:09,878 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:23:09,879 INFO  mapreduce.Job - Running job: job_local1906528864_0001
2020-05-02 19:23:10,679 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:23:10,718 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:23:10,885 INFO  mapreduce.Job - Job job_local1906528864_0001 running in uber mode : false
2020-05-02 19:23:10,887 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:23:11,528 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 19:23:11,888 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:23:11,889 INFO  mapreduce.Job - Job job_local1906528864_0001 completed successfully
2020-05-02 19:23:11,910 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1988196
		FILE: Number of bytes written=2985838
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=479199232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66820
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:23:11,929 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 19:23:11, elapsed: 00:00:03
2020-05-02 19:35:56,885 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:35:57,647 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:35:57
2020-05-02 19:35:57,648 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-02 19:36:00,087 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:36:00,088 INFO  mapreduce.Job - Running job: job_local643155353_0001
2020-05-02 19:36:01,152 INFO  mapreduce.Job - Job job_local643155353_0001 running in uber mode : false
2020-05-02 19:36:01,153 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:36:01,576 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 19:36:01,820 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/imac-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:01,824 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:36:01,832 INFO  parse.ParseSegment - Parsed (1066ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:36:01,912 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/imac/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:01,913 INFO  parse.ParseSegment - Parsed (73ms):https://www.apple.com/imac/specs/
2020-05-02 19:36:01,989 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-mini/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:01,990 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:36:02,065 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,066 INFO  parse.ParseSegment - Parsed (73ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:36:02,140 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,141 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:36:02,210 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,211 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:36:02,274 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,274 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:36:02,315 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,316 INFO  parse.ParseSegment - Parsed (40ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:36:02,366 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-16/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,367 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:36:02,520 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-air/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,520 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:36:02,521 INFO  parse.ParseSegment - Parsed (29ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:36:02,547 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-air/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,548 INFO  parse.ParseSegment - Parsed (23ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:36:02,595 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-13/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,596 INFO  parse.ParseSegment - Parsed (46ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:36:02,720 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:36:02,845 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:36:03,160 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:36:03,161 INFO  mapreduce.Job - Job job_local643155353_0001 completed successfully
2020-05-02 19:36:03,176 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4191715
		FILE: Number of bytes written=6178701
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=404111
		Map output materialized bytes=404171
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=404171
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=102
		Total committed heap usage (bytes)=1089994752
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:36:03,192 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:36:03, elapsed: 00:00:05
2020-05-02 19:36:04,217 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:36:04,610 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-02 19:36:04,623 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:36:04
2020-05-02 19:36:04,638 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:36:04,640 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:36:04,640 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:36:04,643 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:36:04,643 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:36:04,643 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-02 19:36:05,580 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:36:05,581 INFO  mapreduce.Job - Running job: job_local1084918957_0001
2020-05-02 19:36:06,047 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:06,443 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:06,587 INFO  mapreduce.Job - Job job_local1084918957_0001 running in uber mode : false
2020-05-02 19:36:06,588 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:36:06,632 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,037 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,153 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,277 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,383 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,437 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,484 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,629 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:36:07,660 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:36:08,148 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  orhttp                            
            "http". The values represent CloudSolrServer or HttpSolrServer respectively.                                                              

url         Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  providedhttp://localhost:8983/solr/nutch
            using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any                                
            collections or cores; just the root Solr path.                                                                                            

collection  The collection used in requests. Only used when the value of type property is cloud.                                                      

commitSize  Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very1000                            
            large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server                                
            side commit.                                                                                                                              

weight.fieldField's name where the weight of the documents will be written. If it is empty no field will be used.                                     

auth        Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  passwordfalse                           
            properties to configure your credentials.                                                                                                 

username    The username of Solr server.                                                                              dev-user                        

password    The password of Solr server.                                                                              SolrRocks                       



2020-05-02 19:36:08,796 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 19:36:08,826 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,841 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,841 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,843 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,851 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,854 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,855 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,862 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,949 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,962 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,963 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,964 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,967 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:36:08,967 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:36:09,600 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:36:09,601 INFO  mapreduce.Job - Job job_local1084918957_0001 completed successfully
2020-05-02 19:36:09,623 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13697135
		FILE: Number of bytes written=21141296
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=703633
		Map output materialized bytes=707937
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=707937
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=186
		Total committed heap usage (bytes)=6194987008
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=358083
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:36:09,623 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:36:09,631 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:36:09,650 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:36:09, elapsed: 00:00:05
