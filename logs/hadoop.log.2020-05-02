2020-05-02 11:36:22,516 INFO  crawl.Injector - Injector: starting at 2020-05-02 11:36:22
2020-05-02 11:36:22,518 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 11:36:22,521 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 11:36:22,521 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 11:36:22,720 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:36:23,400 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 11:36:24,884 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:24,888 INFO  mapreduce.Job - Running job: job_local2028664375_0001
2020-05-02 11:36:25,815 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 11:36:25,899 INFO  mapreduce.Job - Job job_local2028664375_0001 running in uber mode : false
2020-05-02 11:36:25,901 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:36:25,998 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 11:36:25,998 INFO  crawl.Injector - Injector: update: false
2020-05-02 11:36:26,903 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:36:26,904 INFO  mapreduce.Job - Job job_local2028664375_0001 completed successfully
2020-05-02 11:36:26,931 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2971837
		FILE: Number of bytes written=4665997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=187
		Map output records=187
		Map output bytes=36004
		Map output materialized bytes=36502
		Input split bytes=592
		Combine input records=0
		Combine output records=0
		Reduce input groups=187
		Reduce shuffle bytes=36502
		Reduce input records=187
		Reduce output records=187
		Spilled Records=374
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=913833984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=38530
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 11:36:26,952 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 11:36:27,052 INFO  crawl.Injector - Injector: finished at 2020-05-02 11:36:26, elapsed: 00:00:04
2020-05-02 11:36:28,294 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:36:29,395 INFO  crawl.Generator - Generator: starting at 2020-05-02 11:36:29
2020-05-02 11:36:29,395 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 11:36:29,396 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 11:36:29,396 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 11:36:29,399 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 11:36:30,417 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:30,418 INFO  mapreduce.Job - Running job: job_local1320640094_0001
2020-05-02 11:36:30,976 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:36:30,976 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:36:30,976 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:36:30,991 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 11:36:31,202 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 11:36:31,276 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 11:36:31,426 INFO  mapreduce.Job - Job job_local1320640094_0001 running in uber mode : false
2020-05-02 11:36:31,427 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:36:31,428 INFO  mapreduce.Job - Job job_local1320640094_0001 completed successfully
2020-05-02 11:36:31,449 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2905431
		FILE: Number of bytes written=4513173
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=187
		Map output records=76
		Map output bytes=10182
		Map output materialized bytes=2193
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=2193
		Reduce input records=76
		Reduce output records=0
		Spilled Records=152
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=739770368
	Generator
		SCHEDULE_REJECTED=111
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=38234
	File Output Format Counters 
		Bytes Written=16
2020-05-02 11:36:31,449 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 11:36:31,454 INFO  crawl.Generator - Generator:    111  SCHEDULE_REJECTED
2020-05-02 11:36:31,456 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 11:36:32,458 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502113632
2020-05-02 11:36:32,725 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:32,726 INFO  mapreduce.Job - Running job: job_local1387946928_0002
2020-05-02 11:36:33,730 INFO  mapreduce.Job - Job job_local1387946928_0002 running in uber mode : false
2020-05-02 11:36:33,731 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:36:33,731 INFO  mapreduce.Job - Job job_local1387946928_0002 completed successfully
2020-05-02 11:36:33,735 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5737760
		FILE: Number of bytes written=9046090
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=76
		Map output records=76
		Map output bytes=15652
		Map output materialized bytes=2454
		Input split bytes=366
		Combine input records=0
		Combine output records=0
		Reduce input groups=76
		Reduce shuffle bytes=2454
		Reduce input records=76
		Reduce output records=76
		Spilled Records=152
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1340080128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11214
	File Output Format Counters 
		Bytes Written=10440
2020-05-02 11:36:33,831 INFO  crawl.Generator - Generator: finished at 2020-05-02 11:36:33, elapsed: 00:00:04
2020-05-02 11:36:34,832 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 11:36:34
2020-05-02 11:36:34,832 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502113632
2020-05-02 11:36:34,833 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588404994833  (2020-05-02 14:36:34)
2020-05-02 11:36:35,118 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:36:36,287 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:36:36,288 INFO  mapreduce.Job - Running job: job_local1816575884_0001
2020-05-02 11:36:36,478 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 11:36:36,478 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 11:36:36,479 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 11:36:36,502 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 76 records hit by time limit : 0
2020-05-02 11:36:36,781 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:36,808 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:36,809 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.raywenderlich.com/8241072-ios-tutorial-collection-view-and-diffable-data-source (queue crawl delay=1ms)
2020-05-02 11:36:36,810 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,052 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 11:36:37,053 INFO  http.Http - http.proxy.host = null
2020-05-02 11:36:37,053 INFO  http.Http - http.proxy.port = 8080
2020-05-02 11:36:37,053 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 11:36:37,053 INFO  http.Http - http.timeout = 30000
2020-05-02 11:36:37,053 INFO  http.Http - http.content.limit = -1
2020-05-02 11:36:37,053 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 11:36:37,053 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 11:36:37,053 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 11:36:37,054 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 11:36:37,055 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,055 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 11:36:37,056 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,056 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,057 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,057 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,058 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,058 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,059 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,060 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,060 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,061 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,062 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,063 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,069 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,069 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,070 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,071 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,072 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,074 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,076 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,077 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,080 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,081 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,081 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,082 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,082 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,084 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,084 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,085 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,086 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,086 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,088 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,091 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,092 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,092 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,093 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,094 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,095 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,104 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,106 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,106 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,111 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,117 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,118 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,119 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,122 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,123 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,124 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,124 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,125 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,130 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,135 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,135 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,136 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,139 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,140 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,140 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,141 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,142 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,142 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,143 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,144 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,144 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,149 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,150 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,150 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,151 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,152 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,153 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,158 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,260 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,261 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,262 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,262 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,263 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,263 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,264 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,271 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,272 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,272 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,273 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,273 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,274 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,274 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,275 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,275 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,277 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,280 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,280 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,281 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,282 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,283 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,283 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,284 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:36:37,284 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:36:37,285 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 11:36:37,285 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 11:36:37,285 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 11:36:37,299 INFO  mapreduce.Job - Job job_local1816575884_0001 running in uber mode : false
2020-05-02 11:36:37,301 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 11:36:38,288 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=74, fetchQueues.getQueueCount=2
2020-05-02 11:36:38,847 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 11:36:39,292 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=73, fetchQueues.getQueueCount=2
2020-05-02 11:36:40,292 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=73, fetchQueues.getQueueCount=1
2020-05-02 11:36:41,293 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=73, fetchQueues.getQueueCount=1
2020-05-02 11:36:42,296 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=73, fetchQueues.getQueueCount=1
2020-05-02 11:36:42,365 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.raywenderlich.com/176876/rwdevcon-2018-schedule-now-available (queue crawl delay=1ms)
2020-05-02 11:36:43,297 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=72, fetchQueues.getQueueCount=1
2020-05-02 11:36:43,969 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:43,970 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.raywenderlich.com/147687/introduction-unity-getting-started-part-12 (queue crawl delay=1ms)
2020-05-02 11:36:44,302 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=71, fetchQueues.getQueueCount=1
2020-05-02 11:36:45,306 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=71, fetchQueues.getQueueCount=1
2020-05-02 11:36:45,825 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/151018/unreal-engine-4-tutorial-beginners (queue crawl delay=1ms)
2020-05-02 11:36:46,306 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=70, fetchQueues.getQueueCount=1
2020-05-02 11:36:47,311 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=70, fetchQueues.getQueueCount=1
2020-05-02 11:36:47,503 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:47,503 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/66062/procedural-level-generation-games-using-cellular-automaton-part-1 (queue crawl delay=1ms)
2020-05-02 11:36:48,314 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=69, fetchQueues.getQueueCount=1
2020-05-02 11:36:48,979 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/185264/rwdevcon-2018-student-scholarships-apply-now (queue crawl delay=1ms)
2020-05-02 11:36:49,317 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=68, fetchQueues.getQueueCount=1
2020-05-02 11:36:49,337 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-02 11:36:50,321 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=68, fetchQueues.getQueueCount=1
2020-05-02 11:36:50,619 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/173813/unreal-engine-4-audio-tutorial (queue crawl delay=1ms)
2020-05-02 11:36:51,325 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=67, fetchQueues.getQueueCount=1
2020-05-02 11:36:52,330 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=67, fetchQueues.getQueueCount=1
2020-05-02 11:36:52,360 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/138939/getting-started-mobile-analytics (queue crawl delay=1ms)
2020-05-02 11:36:53,334 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=66, fetchQueues.getQueueCount=1
2020-05-02 11:36:54,115 INFO  fetcher.FetcherThread - FetcherThread 87 fetching https://www.raywenderlich.com/146804/dependency-injection-dagger-2 (queue crawl delay=1ms)
2020-05-02 11:36:54,334 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=65, fetchQueues.getQueueCount=1
2020-05-02 11:36:55,337 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=65, fetchQueues.getQueueCount=1
2020-05-02 11:36:55,841 INFO  fetcher.FetcherThread - FetcherThread 77 fetching https://www.raywenderlich.com/161314/spritekit-animations-texture-atlases-swift (queue crawl delay=1ms)
2020-05-02 11:36:56,338 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=64, fetchQueues.getQueueCount=1
2020-05-02 11:36:57,340 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=64, fetchQueues.getQueueCount=1
2020-05-02 11:36:57,489 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:57,649 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.raywenderlich.com/167015/learning-techniques-programmers (queue crawl delay=1ms)
2020-05-02 11:36:58,341 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=63, fetchQueues.getQueueCount=1
2020-05-02 11:36:59,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:36:59,223 INFO  fetcher.FetcherThread - FetcherThread 69 fetching https://www.raywenderlich.com/82022/make-game-like-cut-rope-using-spritekit-swift (queue crawl delay=1ms)
2020-05-02 11:36:59,341 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=62, fetchQueues.getQueueCount=1
2020-05-02 11:37:00,342 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=62, fetchQueues.getQueueCount=1
2020-05-02 11:37:00,856 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:37:00,862 INFO  fetcher.FetcherThread - FetcherThread 75 fetching https://www.raywenderlich.com/168916/android-an-introduction-to-material-design (queue crawl delay=1ms)
2020-05-02 11:37:01,346 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=61, fetchQueues.getQueueCount=1
2020-05-02 11:37:02,347 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=61, fetchQueues.getQueueCount=1
2020-05-02 11:37:02,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:37:02,597 INFO  fetcher.FetcherThread - FetcherThread 75 fetching https://www.raywenderlich.com/135380/using-framer-prototype-ios-animations (queue crawl delay=1ms)
2020-05-02 11:37:03,348 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=60, fetchQueues.getQueueCount=1
2020-05-02 11:37:04,257 INFO  fetcher.FetcherThread - FetcherThread 74 fetching https://www.raywenderlich.com/167227/unreal-engine-4-ui-tutorial (queue crawl delay=1ms)
2020-05-02 11:37:04,351 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=59, fetchQueues.getQueueCount=1
2020-05-02 11:37:05,352 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=59, fetchQueues.getQueueCount=1
2020-05-02 11:37:05,773 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-02 11:37:05,773 INFO  fetcher.FetcherThread - FetcherThread 74 fetching https://www.raywenderlich.com/175401/custom-downloadable-fonts-android (queue crawl delay=1ms)
2020-05-02 11:37:06,355 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=58, fetchQueues.getQueueCount=1
2020-05-02 11:37:27,632 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:37:28,014 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 11:37:28
2020-05-02 11:37:28,015 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502113632
2020-05-02 11:37:28,377 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113632/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:261)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:308)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:280)

2020-05-02 11:37:49,031 INFO  crawl.Injector - Injector: starting at 2020-05-02 11:37:49
2020-05-02 11:37:49,035 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 11:37:49,035 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 11:37:49,035 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 11:37:49,241 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:37:49,674 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 11:37:50,760 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:37:50,761 INFO  mapreduce.Job - Running job: job_local1996525723_0001
2020-05-02 11:37:51,302 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 11:37:51,502 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 11:37:51,502 INFO  crawl.Injector - Injector: update: false
2020-05-02 11:37:51,772 INFO  mapreduce.Job - Job job_local1996525723_0001 running in uber mode : false
2020-05-02 11:37:51,774 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:37:51,775 INFO  mapreduce.Job - Job job_local1996525723_0001 completed successfully
2020-05-02 11:37:51,787 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855256
		FILE: Number of bytes written=2987973
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=136
		Map output materialized bytes=146
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=146
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=493
2020-05-02 11:37:51,798 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 11:37:51,799 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 11:37:51,799 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 11:37:51,799 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 11:37:51,817 INFO  crawl.Injector - Injector: finished at 2020-05-02 11:37:51, elapsed: 00:00:02
2020-05-02 11:37:52,862 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: starting at 2020-05-02 11:37:53
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 11:37:53,291 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 11:37:53,294 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 11:37:54,410 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:37:54,413 INFO  mapreduce.Job - Running job: job_local1311664073_0001
2020-05-02 11:37:54,965 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:37:54,966 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:37:54,966 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:37:54,974 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 11:37:55,181 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 11:37:55,421 INFO  mapreduce.Job - Job job_local1311664073_0001 running in uber mode : false
2020-05-02 11:37:55,422 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:37:55,423 INFO  mapreduce.Job - Job job_local1311664073_0001 completed successfully
2020-05-02 11:37:55,437 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783168
		FILE: Number of bytes written=4493978
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=194
		Map output materialized bytes=116
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=116
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=250
	File Output Format Counters 
		Bytes Written=16
2020-05-02 11:37:55,438 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 11:37:55,443 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 11:37:56,444 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502113756
2020-05-02 11:37:56,703 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:37:56,703 INFO  mapreduce.Job - Running job: job_local1334452178_0002
2020-05-02 11:37:57,708 INFO  mapreduce.Job - Job job_local1334452178_0002 running in uber mode : false
2020-05-02 11:37:57,709 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:37:57,710 INFO  mapreduce.Job - Job job_local1334452178_0002 completed successfully
2020-05-02 11:37:57,714 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3711250
		FILE: Number of bytes written=5987424
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=264
		Map output materialized bytes=106
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=106
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=330
	File Output Format Counters 
		Bytes Written=292
2020-05-02 11:37:57,734 INFO  crawl.Generator - Generator: finished at 2020-05-02 11:37:57, elapsed: 00:00:04
2020-05-02 11:37:58,746 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 11:37:58
2020-05-02 11:37:58,746 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502113756
2020-05-02 11:37:58,747 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588405078747  (2020-05-02 14:37:58)
2020-05-02 11:37:59,024 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:00,109 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:00,110 INFO  mapreduce.Job - Running job: job_local633290412_0001
2020-05-02 11:38:00,308 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 11:38:00,308 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 11:38:00,309 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 11:38:00,318 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records hit by time limit : 0
2020-05-02 11:38:00,604 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,630 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,631 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,631 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 11:38:00,842 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 11:38:00,844 INFO  http.Http - http.proxy.host = null
2020-05-02 11:38:00,844 INFO  http.Http - http.proxy.port = 8080
2020-05-02 11:38:00,844 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 11:38:00,844 INFO  http.Http - http.timeout = 30000
2020-05-02 11:38:00,844 INFO  http.Http - http.content.limit = -1
2020-05-02 11:38:00,844 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 11:38:00,844 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 11:38:00,844 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 11:38:00,844 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 11:38:00,849 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,850 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,850 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,851 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,851 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,852 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,853 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,853 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,854 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,855 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,856 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,873 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,876 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,926 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,927 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,928 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,928 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,929 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,930 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:00,931 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:00,932 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,064 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,065 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,066 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,067 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,068 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,069 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,069 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,070 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,071 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,071 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,072 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,073 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,073 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,074 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,075 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,075 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,076 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,077 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,077 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,079 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,080 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,091 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,092 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,093 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,094 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,096 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,097 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,098 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,099 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,099 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,100 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,100 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,101 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,101 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,102 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,103 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,103 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,104 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,104 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,105 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,107 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,108 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,111 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,111 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,112 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,114 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,115 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,115 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,116 INFO  mapreduce.Job - Job job_local633290412_0001 running in uber mode : false
2020-05-02 11:38:01,117 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,118 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 11:38:01,118 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,120 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,120 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,121 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,122 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,122 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,123 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,124 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,125 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,126 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,127 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,127 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,128 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,129 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,130 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,131 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,131 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,143 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,144 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,147 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,148 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,151 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,153 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,154 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,156 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,157 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:01,158 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 11:38:01,159 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 11:38:01,160 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 11:38:01,160 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 11:38:01,801 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=47
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 11:38:01,858 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=46
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 11:38:01,857 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=48
2020-05-02 11:38:01,858 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=45
2020-05-02 11:38:01,868 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 11:38:01,868 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 11:38:01,932 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 11:38:01,933 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=43
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=42
2020-05-02 11:38:01,934 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=41
2020-05-02 11:38:01,935 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 11:38:01,935 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=40
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=39
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=38
2020-05-02 11:38:02,073 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=37
2020-05-02 11:38:02,074 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=35
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=36
2020-05-02 11:38:02,074 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 11:38:02,075 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=34
2020-05-02 11:38:02,074 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 11:38:02,076 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=33
2020-05-02 11:38:02,084 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=32
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=31
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 11:38:02,085 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=30
2020-05-02 11:38:02,091 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 11:38:02,091 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=29
2020-05-02 11:38:02,098 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 11:38:02,098 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=28
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=27
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 11:38:02,101 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=26
2020-05-02 11:38:02,105 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 11:38:02,105 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=25
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=23
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=22
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=21
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 11:38:02,111 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 11:38:02,110 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=20
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=19
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 11:38:02,116 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=18
2020-05-02 11:38:02,112 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 11:38:02,118 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=17
2020-05-02 11:38:02,124 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 11:38:02,124 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=16
2020-05-02 11:38:02,124 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 11:38:02,125 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=15
2020-05-02 11:38:02,130 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 11:38:02,130 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=14
2020-05-02 11:38:02,135 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 11:38:02,135 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=13
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=12
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=11
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=10
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=9
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 11:38:02,142 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=8
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=5
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=4
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=3
2020-05-02 11:38:02,136 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 11:38:02,168 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=2
2020-05-02 11:38:02,165 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=6
2020-05-02 11:38:02,168 INFO  fetcher.Fetcher - -activeThreads=3, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 11:38:02,150 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 11:38:02,172 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=1
2020-05-02 11:38:02,150 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 11:38:02,172 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=0
2020-05-02 11:38:02,146 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=7
2020-05-02 11:38:03,176 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 11:38:03,176 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 11:38:04,131 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:04,131 INFO  mapreduce.Job - Job job_local633290412_0001 completed successfully
2020-05-02 11:38:04,152 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2869167
		FILE: Number of bytes written=4667897
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=235541
		Map output materialized bytes=39059
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=39059
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=135
		Total committed heap usage (bytes)=976748544
	FetcherStatus
		bytes_downloaded=233595
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=292
	File Output Format Counters 
		Bytes Written=41236
2020-05-02 11:38:04,152 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 11:38:04, elapsed: 00:00:05
2020-05-02 11:38:05,342 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:05,690 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 11:38:05
2020-05-02 11:38:05,691 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502113756
2020-05-02 11:38:06,660 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:06,661 INFO  mapreduce.Job - Running job: job_local830552255_0001
2020-05-02 11:38:07,669 INFO  mapreduce.Job - Job job_local830552255_0001 running in uber mode : false
2020-05-02 11:38:07,670 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 11:38:07,828 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 11:38:08,094 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 11:38:08,098 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 11:38:08,110 INFO  parse.ParseSegment - Parsed (928ms):https://www.apple.com/iphone-11/specs/
2020-05-02 11:38:08,195 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 11:38:08,196 INFO  parse.ParseSegment - Parsed (80ms):https://www.apple.com/iphone-se/specs/
2020-05-02 11:38:08,409 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:08,533 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 11:38:08,606 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 11:38:08,673 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 11:38:09,678 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:09,679 INFO  mapreduce.Job - Job job_local830552255_0001 completed successfully
2020-05-02 11:38:09,694 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3921778
		FILE: Number of bytes written=6108630
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=21709
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=21709
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=70
		Total committed heap usage (bytes)=1597505536
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39776
	File Output Format Counters 
		Bytes Written=0
2020-05-02 11:38:09,706 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 11:38:09, elapsed: 00:00:04
2020-05-02 11:38:10,952 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 11:38:11
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502113756]
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 11:38:11,403 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 11:38:11,405 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 11:38:12,324 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:12,325 INFO  mapreduce.Job - Running job: job_local1458095609_0001
2020-05-02 11:38:13,345 INFO  mapreduce.Job - Job job_local1458095609_0001 running in uber mode : false
2020-05-02 11:38:13,347 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:38:13,534 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:38:13,535 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:38:13,535 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:38:13,624 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 11:38:13,624 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 11:38:13,624 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 11:38:14,352 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:14,354 INFO  mapreduce.Job - Job job_local1458095609_0001 completed successfully
2020-05-02 11:38:14,372 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6630864
		FILE: Number of bytes written=10487211
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=206
		Map output records=206
		Map output bytes=15039
		Map output materialized bytes=1476
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=1476
		Reduce input records=206
		Reduce output records=134
		Spilled Records=412
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16736
	File Output Format Counters 
		Bytes Written=11780
2020-05-02 11:38:14,393 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 11:38:14, elapsed: 00:00:02
2020-05-02 11:38:15,602 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:15,961 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 11:38:15
2020-05-02 11:38:15,961 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 11:38:15,961 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 11:38:15,962 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 11:38:15,962 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 11:38:15,962 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502113756
2020-05-02 11:38:16,967 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:16,969 INFO  mapreduce.Job - Running job: job_local305705106_0001
2020-05-02 11:38:17,493 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 11:38:17,979 INFO  mapreduce.Job - Job job_local305705106_0001 running in uber mode : false
2020-05-02 11:38:17,980 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:17,981 INFO  mapreduce.Job - Job job_local305705106_0001 completed successfully
2020-05-02 11:38:17,997 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2790505
		FILE: Number of bytes written=4475393
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=332
		Combine input records=1
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2440
	File Output Format Counters 
		Bytes Written=486
2020-05-02 11:38:18,017 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 11:38:17, elapsed: 00:00:02
2020-05-02 11:38:19,075 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 11:38:19
2020-05-02 11:38:19,355 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:20,483 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:20,484 INFO  mapreduce.Job - Running job: job_local1397497342_0001
2020-05-02 11:38:21,492 INFO  mapreduce.Job - Job job_local1397497342_0001 running in uber mode : false
2020-05-02 11:38:21,493 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:21,494 INFO  mapreduce.Job - Job job_local1397497342_0001 completed successfully
2020-05-02 11:38:21,507 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2812628
		FILE: Number of bytes written=4485870
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=2
		Map output bytes=526
		Map output materialized bytes=544
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=544
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11307
	File Output Format Counters 
		Bytes Written=98
2020-05-02 11:38:21,512 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 11:38:21,512 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 11:38:21,801 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:21,801 INFO  mapreduce.Job - Running job: job_local1571383815_0002
2020-05-02 11:38:22,807 INFO  mapreduce.Job - Job job_local1571383815_0002 running in uber mode : false
2020-05-02 11:38:22,807 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:22,808 INFO  mapreduce.Job - Job job_local1571383815_0002 completed successfully
2020-05-02 11:38:22,812 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7533952
		FILE: Number of bytes written=12014357
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10163
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10163
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11405
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 11:38:22,836 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 11:38:22, elapsed: 00:00:03
2020-05-02 11:38:23,962 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:24,474 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502113756.
2020-05-02 11:38:24,477 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 11:38:24
2020-05-02 11:38:24,493 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 11:38:24,494 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 11:38:24,494 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 11:38:24,499 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 11:38:24,499 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 11:38:24,499 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502113756
2020-05-02 11:38:25,542 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:25,542 INFO  mapreduce.Job - Running job: job_local117106698_0001
2020-05-02 11:38:26,551 INFO  mapreduce.Job - Job job_local117106698_0001 running in uber mode : false
2020-05-02 11:38:26,552 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:38:26,997 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 11:38:27,027 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 11:38:27,321 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 11:38:27,882 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 11:38:27,903 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 11:38:27,921 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 11:38:27,928 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 11:38:27,929 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 11:38:28,559 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:28,559 INFO  mapreduce.Job - Job job_local117106698_0001 completed successfully
2020-05-02 11:38:28,577 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10918865
		FILE: Number of bytes written=17314217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=343
		Map output records=343
		Map output bytes=77719
		Map output materialized bytes=78477
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=78477
		Reduce input records=343
		Reduce output records=2
		Spilled Records=686
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=260
		Total committed heap usage (bytes)=4905762816
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47829
	File Output Format Counters 
		Bytes Written=0
2020-05-02 11:38:28,577 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 11:38:28,585 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 11:38:28,613 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 11:38:28, elapsed: 00:00:04
2020-05-02 11:38:29,693 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 11:38:29
2020-05-02 11:38:29,977 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 11:38:31,151 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 11:38:31,152 INFO  mapreduce.Job - Running job: job_local1855450426_0001
2020-05-02 11:38:31,769 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 11:38:31,797 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 11:38:32,161 INFO  mapreduce.Job - Job job_local1855450426_0001 running in uber mode : false
2020-05-02 11:38:32,162 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 11:38:32,201 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 11:38:33,166 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 11:38:33,167 INFO  mapreduce.Job - Job job_local1855450426_0001 completed successfully
2020-05-02 11:38:33,183 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1877012
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=478150656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=0
2020-05-02 11:38:33,203 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 11:38:33, elapsed: 00:00:03
2020-05-02 12:14:35,802 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:14:36,309 WARN  parse.ParseSegment - Segment: crawl/segments/20200502113756 already parsed!! Skipped parsing this segment!!
2020-05-02 12:14:54,233 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:14:54,588 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:14:54
2020-05-02 12:14:54,589 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502113756
2020-05-02 12:14:55,656 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:14:55,657 INFO  mapreduce.Job - Running job: job_local1619690207_0001
2020-05-02 12:14:56,674 INFO  mapreduce.Job - Job job_local1619690207_0001 running in uber mode : false
2020-05-02 12:14:56,675 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:14:56,945 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 12:14:57,217 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:14:57,221 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:14:57,231 INFO  parse.ParseSegment - Parsed (1053ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:14:57,308 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:14:57,309 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:14:57,524 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:14:57,656 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:14:57,677 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:14:58,683 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:14:58,684 INFO  mapreduce.Job - Job job_local1619690207_0001 completed successfully
2020-05-02 12:14:58,704 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3047840
		FILE: Number of bytes written=4807122
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=72779
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=72779
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=79
		Total committed heap usage (bytes)=1176502272
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39776
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:14:58,717 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:14:58, elapsed: 00:00:04
2020-05-02 12:15:07,425 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:15:07,883 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:15:07
2020-05-02 12:15:07,883 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502113756]
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:15:07,884 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:15:07,886 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:15:09,373 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:09,380 INFO  mapreduce.Job - Running job: job_local2128912528_0001
2020-05-02 12:15:10,399 INFO  mapreduce.Job - Job job_local2128912528_0001 running in uber mode : false
2020-05-02 12:15:10,400 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:15:10,540 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:15:10,541 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:15:10,541 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:15:11,402 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:11,402 INFO  mapreduce.Job - Job job_local2128912528_0001 completed successfully
2020-05-02 12:15:11,418 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=4821174
		FILE: Number of bytes written=7621596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=338
		Map output records=338
		Map output bytes=24778
		Map output materialized bytes=25482
		Input split bytes=643
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=25482
		Reduce input records=338
		Reduce output records=134
		Spilled Records=676
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=2290614272
	CrawlDB status
		db_notmodified=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27568
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:15:11,441 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:15:11, elapsed: 00:00:03
2020-05-02 12:15:13,889 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:15:14,494 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:15:14
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:15:14,495 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:15:14,496 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:15:15,548 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:15,578 INFO  mapreduce.Job - Running job: job_local1793762423_0001
2020-05-02 12:15:16,595 INFO  mapreduce.Job - Job job_local1793762423_0001 running in uber mode : false
2020-05-02 12:15:16,600 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:16,604 INFO  mapreduce.Job - Job job_local1793762423_0001 completed successfully
2020-05-02 12:15:16,645 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2795004
		FILE: Number of bytes written=4481642
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=332
		Combine input records=2
		Combine output records=2
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4600
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:15:16,645 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:15:17,234 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:17,234 INFO  mapreduce.Job - Running job: job_local438898206_0002
2020-05-02 12:15:17,920 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:15:17,958 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:15:18,236 INFO  mapreduce.Job - Job job_local438898206_0002 running in uber mode : false
2020-05-02 12:15:18,237 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:18,237 INFO  mapreduce.Job - Job job_local438898206_0002 completed successfully
2020-05-02 12:15:18,242 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5583031
		FILE: Number of bytes written=8957480
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=242
		Total committed heap usage (bytes)=1360527360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:15:18,267 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:15:18, elapsed: 00:00:03
2020-05-02 12:15:20,586 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:15:20,960 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502113756.
2020-05-02 12:15:20,963 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:15:20
2020-05-02 12:15:21,019 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:15:21,021 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:15:21,022 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:15:21,024 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:15:21,024 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:15:21,024 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502113756
2020-05-02 12:15:22,087 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:15:22,088 INFO  mapreduce.Job - Running job: job_local1047893186_0001
2020-05-02 12:15:22,635 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:22,728 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:22,832 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:22,990 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,100 INFO  mapreduce.Job - Job job_local1047893186_0001 running in uber mode : false
2020-05-02 12:15:23,101 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:15:23,118 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,215 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,275 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,320 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:15:23,459 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:15:23,489 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:15:23,985 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 12:15:24,622 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 12:15:24,640 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:15:24,647 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:15:24,650 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:15:24,651 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:15:25,112 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:15:25,112 INFO  mapreduce.Job - Job job_local1047893186_0001 completed successfully
2020-05-02 12:15:25,147 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10162457
		FILE: Number of bytes written=16209591
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130235
		Map output materialized bytes=131003
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131003
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=6191841280
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:15:25,148 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:15:25,156 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:15:25,171 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:15:25, elapsed: 00:00:04
2020-05-02 12:17:43,602 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:17:44,089 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:17:44
2020-05-02 12:17:44,089 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:17:44,089 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502113756]
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:17:44,090 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:17:44,092 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:17:45,335 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:45,336 INFO  mapreduce.Job - Running job: job_local2078728313_0001
2020-05-02 12:17:46,322 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:17:46,323 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:17:46,323 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:17:46,346 INFO  mapreduce.Job - Job job_local2078728313_0001 running in uber mode : false
2020-05-02 12:17:46,347 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:17:47,351 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:47,352 INFO  mapreduce.Job - Job job_local2078728313_0001 completed successfully
2020-05-02 12:17:47,368 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=4821174
		FILE: Number of bytes written=7621596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=338
		Map output records=338
		Map output bytes=24778
		Map output materialized bytes=25482
		Input split bytes=643
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=25482
		Reduce input records=338
		Reduce output records=134
		Spilled Records=676
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=2290614272
	CrawlDB status
		db_notmodified=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27568
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:17:47,386 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:17:47, elapsed: 00:00:03
2020-05-02 12:17:48,707 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:17:49
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:17:49,173 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:17:50,060 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:50,061 INFO  mapreduce.Job - Running job: job_local404785557_0001
2020-05-02 12:17:51,067 INFO  mapreduce.Job - Job job_local404785557_0001 running in uber mode : false
2020-05-02 12:17:51,068 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:51,070 INFO  mapreduce.Job - Job job_local404785557_0001 completed successfully
2020-05-02 12:17:51,088 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2795004
		FILE: Number of bytes written=4473476
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=332
		Combine input records=2
		Combine output records=2
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4600
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:17:51,089 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:17:51,395 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:51,395 INFO  mapreduce.Job - Running job: job_local1284229186_0002
2020-05-02 12:17:51,727 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:17:51,818 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:17:52,398 INFO  mapreduce.Job - Job job_local1284229186_0002 running in uber mode : false
2020-05-02 12:17:52,399 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:52,399 INFO  mapreduce.Job - Job job_local1284229186_0002 completed successfully
2020-05-02 12:17:52,404 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5583036
		FILE: Number of bytes written=8957501
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:17:52,429 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:17:52, elapsed: 00:00:03
2020-05-02 12:17:53,592 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:17:54,094 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502113756.
2020-05-02 12:17:54,098 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:17:54
2020-05-02 12:17:54,113 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:17:54,113 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:17:54,113 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:17:54,117 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:17:54,117 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:17:54,117 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502113756
2020-05-02 12:17:55,056 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:17:55,057 INFO  mapreduce.Job - Running job: job_local120317803_0001
2020-05-02 12:17:55,528 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:55,622 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:55,700 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:55,985 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,062 INFO  mapreduce.Job - Job job_local120317803_0001 running in uber mode : false
2020-05-02 12:17:56,063 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:17:56,114 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,162 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,362 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,410 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:17:56,551 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:17:56,582 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:17:57,053 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 12:17:57,651 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 22; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 12:17:57,663 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:17:57,671 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:17:57,679 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:17:57,680 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:17:58,068 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:17:58,069 INFO  mapreduce.Job - Job job_local120317803_0001 completed successfully
2020-05-02 12:17:58,095 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10162457
		FILE: Number of bytes written=16182251
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130235
		Map output materialized bytes=131003
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131003
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=6241124352
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:17:58,095 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:17:58,102 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:17:58,121 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:17:58, elapsed: 00:00:04
2020-05-02 12:24:18,530 INFO  crawl.Injector - Injector: starting at 2020-05-02 12:24:18
2020-05-02 12:24:18,531 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 12:24:18,531 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 12:24:18,531 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 12:24:18,673 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:19,092 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 12:24:20,057 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:20,061 INFO  mapreduce.Job - Running job: job_local1460635078_0001
2020-05-02 12:24:20,518 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 12:24:20,715 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 12:24:20,715 INFO  crawl.Injector - Injector: update: false
2020-05-02 12:24:21,115 INFO  mapreduce.Job - Job job_local1460635078_0001 running in uber mode : false
2020-05-02 12:24:21,116 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:21,118 INFO  mapreduce.Job - Job job_local1460635078_0001 completed successfully
2020-05-02 12:24:21,130 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1854978
		FILE: Number of bytes written=2987608
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=53
		Map output materialized bytes=61
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=61
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=387
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 12:24:21,141 INFO  crawl.Injector - Injector: Total new urls injected: 1
2020-05-02 12:24:21,159 INFO  crawl.Injector - Injector: finished at 2020-05-02 12:24:21, elapsed: 00:00:02
2020-05-02 12:24:22,433 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:23,441 INFO  crawl.Generator - Generator: starting at 2020-05-02 12:24:23
2020-05-02 12:24:23,441 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 12:24:23,442 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 12:24:23,442 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 12:24:23,445 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 12:24:24,361 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:24,362 INFO  mapreduce.Job - Running job: job_local227309630_0001
2020-05-02 12:24:25,307 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:24:25,308 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:24:25,312 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:24:25,332 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 12:24:25,372 INFO  mapreduce.Job - Job job_local227309630_0001 running in uber mode : false
2020-05-02 12:24:25,373 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:24:25,689 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 12:24:26,380 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:26,381 INFO  mapreduce.Job - Job job_local227309630_0001 completed successfully
2020-05-02 12:24:26,396 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2782807
		FILE: Number of bytes written=4485108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=82
		Map output materialized bytes=94
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=94
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=159
	File Output Format Counters 
		Bytes Written=16
2020-05-02 12:24:26,396 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 12:24:26,401 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 12:24:27,402 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502122427
2020-05-02 12:24:27,728 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:27,728 INFO  mapreduce.Job - Running job: job_local1840225848_0002
2020-05-02 12:24:28,731 INFO  mapreduce.Job - Job job_local1840225848_0002 running in uber mode : false
2020-05-02 12:24:28,731 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:28,732 INFO  mapreduce.Job - Job job_local1840225848_0002 completed successfully
2020-05-02 12:24:28,735 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3710816
		FILE: Number of bytes written=5981397
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=102
		Map output materialized bytes=79
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=79
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=210
	File Output Format Counters 
		Bytes Written=180
2020-05-02 12:24:28,751 INFO  crawl.Generator - Generator: finished at 2020-05-02 12:24:28, elapsed: 00:00:05
2020-05-02 12:24:29,971 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 12:24:29
2020-05-02 12:24:29,972 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502122427
2020-05-02 12:24:29,972 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588407869972  (2020-05-02 15:24:29)
2020-05-02 12:24:30,290 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:31,578 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:31,583 INFO  mapreduce.Job - Running job: job_local1334054942_0001
2020-05-02 12:24:31,804 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 12:24:31,805 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 12:24:31,808 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 12:24:31,818 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 1 records hit by time limit : 0
2020-05-02 12:24:32,160 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,181 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,181 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,182 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.google.com/ (queue crawl delay=1ms)
2020-05-02 12:24:32,425 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 12:24:32,429 INFO  http.Http - http.proxy.host = null
2020-05-02 12:24:32,429 INFO  http.Http - http.proxy.port = 8080
2020-05-02 12:24:32,429 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 12:24:32,429 INFO  http.Http - http.timeout = 30000
2020-05-02 12:24:32,429 INFO  http.Http - http.content.limit = -1
2020-05-02 12:24:32,429 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 12:24:32,429 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 12:24:32,429 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 12:24:32,429 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 12:24:32,430 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,431 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 12:24:32,431 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,431 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,432 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,432 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 12:24:32,432 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,432 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,433 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,434 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 12:24:32,434 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,434 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,436 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,437 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 12:24:32,437 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,437 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,438 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,441 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 12:24:32,441 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,441 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,444 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,444 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 12:24:32,445 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,445 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,446 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,446 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 12:24:32,447 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,447 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,448 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,451 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 12:24:32,451 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,452 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,454 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,454 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,454 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 12:24:32,455 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,455 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,456 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,456 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 12:24:32,457 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,460 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,460 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,460 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 12:24:32,460 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,461 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,462 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 12:24:32,462 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,462 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,464 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,465 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,465 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 12:24:32,466 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,466 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,467 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 12:24:32,467 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,468 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,470 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,470 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 12:24:32,470 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,471 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,472 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 12:24:32,472 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,472 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,473 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,473 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 12:24:32,473 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,474 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,474 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,475 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 12:24:32,475 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,475 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,477 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 12:24:32,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,477 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,481 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 12:24:32,481 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,482 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,483 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 12:24:32,483 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,483 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,484 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,484 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 12:24:32,485 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,485 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,486 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,488 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 12:24:32,488 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,489 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,489 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,490 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 12:24:32,491 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,491 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,492 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 12:24:32,492 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,492 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,493 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 12:24:32,494 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,494 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,495 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,495 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 12:24:32,495 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,496 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,501 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 12:24:32,501 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,501 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,502 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,503 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 12:24:32,503 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,503 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,504 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,505 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 12:24:32,505 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,505 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,506 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,509 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 12:24:32,509 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,513 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,514 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,514 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 12:24:32,514 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,515 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,515 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,516 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 12:24:32,516 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,517 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,518 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,518 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 12:24:32,518 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,519 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,520 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 12:24:32,520 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,520 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,521 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,522 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 12:24:32,522 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,522 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,523 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,523 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 12:24:32,523 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,529 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,531 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 12:24:32,532 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,535 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,536 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 12:24:32,536 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,536 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,537 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,537 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 12:24:32,537 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,537 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,538 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,538 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 12:24:32,538 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,539 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,539 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,540 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 12:24:32,540 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,540 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,541 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,541 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 12:24:32,542 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,543 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,543 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,544 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,544 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 12:24:32,547 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,547 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,548 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 12:24:32,548 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,548 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,549 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,550 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,550 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 12:24:32,550 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,550 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,551 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 12:24:32,551 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,551 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:32,551 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:24:32,552 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 12:24:32,552 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 12:24:32,552 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:24:32,552 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 12:24:32,554 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 12:24:32,591 INFO  mapreduce.Job - Job job_local1334054942_0001 running in uber mode : false
2020-05-02 12:24:32,593 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:24:33,341 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 12:24:33,341 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=0
2020-05-02 12:24:33,556 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 12:24:33,557 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 12:24:34,602 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:34,602 INFO  mapreduce.Job - Job job_local1334054942_0001 completed successfully
2020-05-02 12:24:34,619 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2808742
		FILE: Number of bytes written=4526130
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=2
		Map output bytes=14807
		Map output materialized bytes=6556
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=6556
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=92
		Total committed heap usage (bytes)=973602816
	FetcherStatus
		bytes_downloaded=13612
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=180
	File Output Format Counters 
		Bytes Written=7953
2020-05-02 12:24:34,619 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 12:24:34, elapsed: 00:00:04
2020-05-02 12:24:35,803 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:36,155 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:24:36
2020-05-02 12:24:36,156 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502122427
2020-05-02 12:24:36,981 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:36,982 INFO  mapreduce.Job - Running job: job_local513757716_0001
2020-05-02 12:24:37,512 WARN  parse.ParserFactory - ParserFactory: Plugin: ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParser mapped to contentType text/html via parse-plugins.xml, but not enabled via plugin.includes in nutch-default.xml
2020-05-02 12:24:37,991 INFO  mapreduce.Job - Job job_local513757716_0001 running in uber mode : false
2020-05-02 12:24:37,998 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:24:38,344 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:24:38,346 INFO  parse.ParseSegment - Parsed (853ms):https://www.google.com/
2020-05-02 12:24:38,548 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:38,648 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:24:38,677 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:24:39,005 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:39,005 INFO  mapreduce.Job - Job job_local513757716_0001 completed successfully
2020-05-02 12:24:39,019 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3744572
		FILE: Number of bytes written=5978283
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=3099
		Map output materialized bytes=1634
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1634
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=68
		Total committed heap usage (bytes)=1587019776
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6757
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:24:39,037 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:24:39, elapsed: 00:00:02
2020-05-02 12:24:40,319 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:40,815 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:24:40
2020-05-02 12:24:40,815 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:24:40,816 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502122427]
2020-05-02 12:24:40,816 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:24:40,834 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:24:40,835 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:24:40,835 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:24:40,837 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:24:41,771 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:41,772 INFO  mapreduce.Job - Running job: job_local515730108_0001
2020-05-02 12:24:42,725 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:24:42,725 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:24:42,726 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:24:42,779 INFO  mapreduce.Job - Job job_local515730108_0001 running in uber mode : false
2020-05-02 12:24:42,780 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 12:24:42,790 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:24:42,790 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:24:42,790 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:24:43,786 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:43,787 INFO  mapreduce.Job - Job job_local515730108_0001 completed successfully
2020-05-02 12:24:43,804 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6519318
		FILE: Number of bytes written=10444489
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=613
		Map output materialized bytes=550
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=550
		Reduce input records=7
		Reduce output records=5
		Spilled Records=14
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=1
		db_unfetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1277
	File Output Format Counters 
		Bytes Written=1195
2020-05-02 12:24:43,822 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:24:43, elapsed: 00:00:03
2020-05-02 12:24:44,962 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:24:45
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:24:45,320 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:24:45,321 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502122427
2020-05-02 12:24:46,157 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:46,158 INFO  mapreduce.Job - Running job: job_local860915945_0001
2020-05-02 12:24:47,168 INFO  mapreduce.Job - Job job_local860915945_0001 running in uber mode : false
2020-05-02 12:24:47,170 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:47,171 INFO  mapreduce.Job - Job job_local860915945_0001 completed successfully
2020-05-02 12:24:47,184 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2786546
		FILE: Number of bytes written=4472650
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1179
	File Output Format Counters 
		Bytes Written=279
2020-05-02 12:24:47,184 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:24:47,457 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:47,457 INFO  mapreduce.Job - Running job: job_local1513967988_0002
2020-05-02 12:24:47,788 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:24:48,463 INFO  mapreduce.Job - Job job_local1513967988_0002 running in uber mode : false
2020-05-02 12:24:48,463 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:48,464 INFO  mapreduce.Job - Job job_local1513967988_0002 completed successfully
2020-05-02 12:24:48,468 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5571331
		FILE: Number of bytes written=8955560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=378
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:24:48,486 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:24:48, elapsed: 00:00:03
2020-05-02 12:24:49,508 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 12:24:49
2020-05-02 12:24:49,840 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:51,154 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:51,155 INFO  mapreduce.Job - Running job: job_local991775611_0001
2020-05-02 12:24:52,165 INFO  mapreduce.Job - Job job_local991775611_0001 running in uber mode : false
2020-05-02 12:24:52,167 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:52,168 INFO  mapreduce.Job - Job job_local991775611_0001 completed successfully
2020-05-02 12:24:52,182 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785363
		FILE: Number of bytes written=4477037
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=1
		Map output bytes=236
		Map output materialized bytes=251
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=251
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=727
	File Output Format Counters 
		Bytes Written=98
2020-05-02 12:24:52,187 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 12:24:52,187 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 12:24:52,515 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:52,515 INFO  mapreduce.Job - Running job: job_local842725531_0002
2020-05-02 12:24:53,516 INFO  mapreduce.Job - Job job_local842725531_0002 running in uber mode : false
2020-05-02 12:24:53,516 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:53,516 INFO  mapreduce.Job - Job job_local842725531_0002 completed successfully
2020-05-02 12:24:53,521 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7432738
		FILE: Number of bytes written=11935978
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=491
		Map output materialized bytes=520
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=520
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=825
	File Output Format Counters 
		Bytes Written=861
2020-05-02 12:24:53,546 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 12:24:53, elapsed: 00:00:04
2020-05-02 12:24:54,733 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:24:55,212 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502122427.
2020-05-02 12:24:55,217 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:24:55
2020-05-02 12:24:55,234 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 12:24:55,234 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 12:24:55,235 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 12:24:55,239 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:24:55,239 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:24:55,239 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502122427
2020-05-02 12:24:56,218 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:24:56,219 INFO  mapreduce.Job - Running job: job_local515226845_0001
2020-05-02 12:24:57,225 INFO  mapreduce.Job - Job job_local515226845_0001 running in uber mode : false
2020-05-02 12:24:57,226 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:24:57,725 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:24:57,755 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:24:58,176 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 12:24:58,752 INFO  solr.SolrIndexWriter - Indexing 1/1 documents
2020-05-02 12:24:58,752 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:24:59,231 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:24:59,232 INFO  mapreduce.Job - Job job_local515226845_0001 completed successfully
2020-05-02 12:24:59,250 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10325838
		FILE: Number of bytes written=16475726
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=2870
		Map output materialized bytes=2964
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=2964
		Reduce input records=14
		Reduce output records=1
		Spilled Records=28
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=298
		Total committed heap usage (bytes)=4911529984
	IndexerStatus
		indexed (add/update)=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3739
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:24:59,250 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:24:59,258 INFO  indexer.IndexingJob - Indexer:      1  indexed (add/update)
2020-05-02 12:24:59,280 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:24:59, elapsed: 00:00:04
2020-05-02 12:25:00,375 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 12:25:00
2020-05-02 12:25:00,630 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:25:02,082 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:25:02,083 INFO  mapreduce.Job - Running job: job_local422061482_0001
2020-05-02 12:25:02,684 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:25:02,706 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:25:03,091 INFO  mapreduce.Job - Job job_local422061482_0001 running in uber mode : false
2020-05-02 12:25:03,092 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:25:03,111 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 12:25:04,098 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:25:04,099 INFO  mapreduce.Job - Job job_local422061482_0001 completed successfully
2020-05-02 12:25:04,124 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1855820
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=91
		Total committed heap usage (bytes)=481820672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=633
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:25:04,144 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 12:25:04, elapsed: 00:00:03
2020-05-02 12:26:28,931 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:26:29,342 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:26:29
2020-05-02 12:26:29,342 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:26:29,343 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502122427]
2020-05-02 12:26:29,343 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:26:29,344 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:26:29,344 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:26:29,344 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:26:29,346 INFO  crawl.CrawlDb -  - adding fetched but unparsed segment crawl/segments/20200502122427
2020-05-02 12:26:29,346 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:26:30,372 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:30,374 INFO  mapreduce.Job - Running job: job_local631989259_0001
2020-05-02 12:26:31,091 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:26:31,092 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:26:31,092 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:26:31,382 INFO  mapreduce.Job - Job job_local631989259_0001 running in uber mode : false
2020-05-02 12:26:31,384 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:31,385 INFO  mapreduce.Job - Job job_local631989259_0001 completed successfully
2020-05-02 12:26:31,400 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3718281
		FILE: Number of bytes written=5966539
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=692
		Map output materialized bytes=724
		Input split bytes=481
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=724
		Reduce input records=6
		Reduce output records=5
		Spilled Records=12
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=1600651264
	CrawlDB status
		db_fetched=1
		db_unfetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1091
	File Output Format Counters 
		Bytes Written=845
2020-05-02 12:26:31,420 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:26:31, elapsed: 00:00:02
2020-05-02 12:26:32,489 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:26:33,006 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:26:33
2020-05-02 12:26:33,006 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:26:33,006 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:26:33,007 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:26:33,007 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:26:33,007 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:26:33,010 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502122427
2020-05-02 12:26:33,934 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:33,935 INFO  mapreduce.Job - Running job: job_local1447631549_0001
2020-05-02 12:26:34,944 INFO  mapreduce.Job - Job job_local1447631549_0001 running in uber mode : false
2020-05-02 12:26:34,946 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:34,947 INFO  mapreduce.Job - Job job_local1447631549_0001 completed successfully
2020-05-02 12:26:34,963 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4669915
		FILE: Number of bytes written=7471947
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=200
		Input split bytes=664
		Combine input records=2
		Combine output records=2
		Reduce input groups=1
		Reduce shuffle bytes=200
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2290614272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5779
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:26:34,963 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:26:35,247 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:35,248 INFO  mapreduce.Job - Running job: job_local1954468760_0002
2020-05-02 12:26:35,728 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:26:35,879 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:26:36,253 INFO  mapreduce.Job - Job job_local1954468760_0002 running in uber mode : false
2020-05-02 12:26:36,253 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:36,253 INFO  mapreduce.Job - Job job_local1954468760_0002 completed successfully
2020-05-02 12:26:36,273 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5593038
		FILE: Number of bytes written=8967536
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2235564032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:26:36,292 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:26:36, elapsed: 00:00:03
2020-05-02 12:26:38,246 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:26:38,724 WARN  segment.SegmentChecker - Skipping segment: crawl/segments/20200502122427. Missing sub directories: crawl_parse
2020-05-02 12:26:38,729 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:26:38
2020-05-02 12:26:38,754 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:26:38,754 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:26:38,754 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:26:38,758 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:26:38,758 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:26:39,898 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:26:39,904 INFO  mapreduce.Job - Running job: job_local731371177_0001
2020-05-02 12:26:40,551 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:26:40,786 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:26:40,901 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:26:40,916 INFO  mapreduce.Job - Job job_local731371177_0001 running in uber mode : false
2020-05-02 12:26:40,918 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:26:40,936 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:26:41,381 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 12:26:42,924 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:26:42,925 INFO  mapreduce.Job - Job job_local731371177_0001 completed successfully
2020-05-02 12:26:42,944 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2786445
		FILE: Number of bytes written=4480113
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=567
		Map output materialized bytes=592
		Input split bytes=293
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=592
		Reduce input records=6
		Reduce output records=0
		Spilled Records=12
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=89
		Total committed heap usage (bytes)=855113728
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=857
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:26:42,944 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:26:42,974 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:26:42, elapsed: 00:00:04
2020-05-02 12:30:28,234 INFO  crawl.Injector - Injector: starting at 2020-05-02 12:30:28
2020-05-02 12:30:28,235 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 12:30:28,236 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 12:30:28,236 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 12:30:28,399 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:28,862 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 12:30:29,884 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:29,885 INFO  mapreduce.Job - Running job: job_local260904640_0001
2020-05-02 12:30:30,344 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 12:30:30,557 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 12:30:30,557 INFO  crawl.Injector - Injector: update: false
2020-05-02 12:30:30,891 INFO  mapreduce.Job - Job job_local260904640_0001 running in uber mode : false
2020-05-02 12:30:30,892 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:30,894 INFO  mapreduce.Job - Job job_local260904640_0001 completed successfully
2020-05-02 12:30:30,907 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855256
		FILE: Number of bytes written=2982521
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=136
		Map output materialized bytes=146
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=146
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=493
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 12:30:30,919 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 12:30:30,934 INFO  crawl.Injector - Injector: finished at 2020-05-02 12:30:30, elapsed: 00:00:02
2020-05-02 12:30:31,955 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: starting at 2020-05-02 12:30:32
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 12:30:32,333 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 12:30:32,335 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 12:30:33,127 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:33,127 INFO  mapreduce.Job - Running job: job_local1473169222_0001
2020-05-02 12:30:33,591 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:30:33,591 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:30:33,591 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:30:33,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 12:30:33,786 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 12:30:34,138 INFO  mapreduce.Job - Job job_local1473169222_0001 running in uber mode : false
2020-05-02 12:30:34,139 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:34,140 INFO  mapreduce.Job - Job job_local1473169222_0001 completed successfully
2020-05-02 12:30:34,156 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783168
		FILE: Number of bytes written=4493978
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=194
		Map output materialized bytes=116
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=116
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=250
	File Output Format Counters 
		Bytes Written=16
2020-05-02 12:30:34,156 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 12:30:34,163 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 12:30:35,169 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502123035
2020-05-02 12:30:35,396 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:35,396 INFO  mapreduce.Job - Running job: job_local1558588550_0002
2020-05-02 12:30:36,399 INFO  mapreduce.Job - Job job_local1558588550_0002 running in uber mode : false
2020-05-02 12:30:36,399 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:36,400 INFO  mapreduce.Job - Job job_local1558588550_0002 completed successfully
2020-05-02 12:30:36,404 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3711250
		FILE: Number of bytes written=5987420
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=264
		Map output materialized bytes=106
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=106
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=330
	File Output Format Counters 
		Bytes Written=292
2020-05-02 12:30:36,422 INFO  crawl.Generator - Generator: finished at 2020-05-02 12:30:36, elapsed: 00:00:04
2020-05-02 12:30:37,421 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 12:30:37
2020-05-02 12:30:37,422 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502123035
2020-05-02 12:30:37,423 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588408237422  (2020-05-02 15:30:37)
2020-05-02 12:30:37,639 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:38,690 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:38,691 INFO  mapreduce.Job - Running job: job_local1675202230_0001
2020-05-02 12:30:38,900 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 12:30:38,901 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 12:30:38,901 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 12:30:38,917 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records hit by time limit : 0
2020-05-02 12:30:39,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,226 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,227 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,227 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 12:30:39,450 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 12:30:39,452 INFO  http.Http - http.proxy.host = null
2020-05-02 12:30:39,452 INFO  http.Http - http.proxy.port = 8080
2020-05-02 12:30:39,452 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 12:30:39,452 INFO  http.Http - http.timeout = 30000
2020-05-02 12:30:39,452 INFO  http.Http - http.content.limit = -1
2020-05-02 12:30:39,452 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 12:30:39,452 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 12:30:39,452 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 12:30:39,452 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 12:30:39,453 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,453 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,454 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,455 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,456 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,456 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,457 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,458 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,459 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,462 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,462 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,463 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,464 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,465 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,466 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,467 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,468 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,468 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,469 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,469 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,470 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,474 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,474 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,475 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,475 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,478 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,478 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,481 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,483 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,483 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,486 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,486 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,487 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,487 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,489 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,489 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,491 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,491 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,492 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,492 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,498 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,499 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,499 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,500 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,501 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,502 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,502 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,503 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,504 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,507 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,508 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,508 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,509 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,509 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,510 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,511 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,511 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,514 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,515 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,515 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,516 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,517 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,517 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,520 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,521 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,521 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,522 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,523 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,524 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,524 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,525 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,525 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,526 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,526 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,527 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,530 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,531 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,531 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,532 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,533 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,534 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:39,535 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:30:39,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 12:30:39,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 12:30:39,537 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 12:30:39,701 INFO  mapreduce.Job - Job job_local1675202230_0001 running in uber mode : false
2020-05-02 12:30:39,701 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:30:40,383 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=49
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=48
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=47
2020-05-02 12:30:40,462 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 12:30:40,463 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=46
2020-05-02 12:30:40,466 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 12:30:40,466 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 12:30:40,466 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=45
2020-05-02 12:30:40,467 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=44
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=43
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 12:30:40,474 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=41
2020-05-02 12:30:40,473 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 12:30:40,474 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=40
2020-05-02 12:30:40,474 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=42
2020-05-02 12:30:40,478 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 12:30:40,478 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=39
2020-05-02 12:30:40,481 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=35
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 12:30:40,483 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=33
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=38
2020-05-02 12:30:40,483 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=34
2020-05-02 12:30:40,482 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=37
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=32
2020-05-02 12:30:40,491 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=31
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 12:30:40,492 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=30
2020-05-02 12:30:40,490 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 12:30:40,492 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=29
2020-05-02 12:30:40,498 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 12:30:40,498 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 12:30:40,498 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=28
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=25
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=26
2020-05-02 12:30:40,499 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=27
2020-05-02 12:30:40,504 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 12:30:40,504 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=23
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 12:30:40,507 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=20
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=21
2020-05-02 12:30:40,506 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=22
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=19
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 12:30:40,517 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=18
2020-05-02 12:30:40,518 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=17
2020-05-02 12:30:40,516 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 12:30:40,518 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=16
2020-05-02 12:30:40,519 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 12:30:40,520 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=15
2020-05-02 12:30:40,519 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 12:30:40,519 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 12:30:40,520 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=14
2020-05-02 12:30:40,520 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=13
2020-05-02 12:30:40,527 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 12:30:40,527 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=12
2020-05-02 12:30:40,528 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 12:30:40,528 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=11
2020-05-02 12:30:40,527 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 12:30:40,528 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=10
2020-05-02 12:30:40,529 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 12:30:40,529 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=7
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=8
2020-05-02 12:30:40,529 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=9
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 12:30:40,531 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=6
2020-05-02 12:30:40,530 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 12:30:40,531 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=5
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=4
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=3
2020-05-02 12:30:40,540 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=2
2020-05-02 12:30:40,542 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 12:30:40,542 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:30:40,543 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 12:30:41,107 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 12:30:41,108 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=0
2020-05-02 12:30:41,548 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 12:30:41,548 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 12:30:41,708 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:30:42,711 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:42,711 INFO  mapreduce.Job - Job job_local1675202230_0001 completed successfully
2020-05-02 12:30:42,730 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2869181
		FILE: Number of bytes written=4676107
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=235541
		Map output materialized bytes=39066
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=39066
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=975175680
	FetcherStatus
		bytes_downloaded=233595
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=292
	File Output Format Counters 
		Bytes Written=41240
2020-05-02 12:30:42,730 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 12:30:42, elapsed: 00:00:05
2020-05-02 12:30:43,783 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:44,122 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:30:44
2020-05-02 12:30:44,122 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123035
2020-05-02 12:30:44,840 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:44,840 INFO  mapreduce.Job - Running job: job_local274137970_0001
2020-05-02 12:30:45,846 INFO  mapreduce.Job - Job job_local274137970_0001 running in uber mode : false
2020-05-02 12:30:45,847 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:30:45,882 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 12:30:46,120 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:30:46,124 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:30:46,134 INFO  parse.ParseSegment - Parsed (851ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:30:46,210 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 12:30:46,211 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:30:46,410 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:46,540 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:30:46,612 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:30:46,850 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:46,851 INFO  mapreduce.Job - Job job_local274137970_0001 completed successfully
2020-05-02 12:30:46,869 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3921794
		FILE: Number of bytes written=6108643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=21711
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=21711
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1595408384
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39779
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:30:46,884 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:30:46, elapsed: 00:00:02
2020-05-02 12:30:47,987 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:48,451 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:30:48
2020-05-02 12:30:48,451 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:30:48,451 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502123035]
2020-05-02 12:30:48,452 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:30:48,453 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:30:48,454 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:30:48,454 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:30:48,464 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:30:49,378 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:49,383 INFO  mapreduce.Job - Running job: job_local1960616636_0001
2020-05-02 12:30:50,397 INFO  mapreduce.Job - Job job_local1960616636_0001 running in uber mode : false
2020-05-02 12:30:50,399 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:30:50,495 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:30:50,495 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:30:50,495 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:30:50,565 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:30:50,565 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:30:50,565 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:30:51,403 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:51,404 INFO  mapreduce.Job - Job job_local1960616636_0001 completed successfully
2020-05-02 12:30:51,429 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6630865
		FILE: Number of bytes written=10487185
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=206
		Map output records=206
		Map output bytes=15039
		Map output materialized bytes=1473
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=1473
		Reduce input records=206
		Reduce output records=134
		Spilled Records=412
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16738
	File Output Format Counters 
		Bytes Written=11780
2020-05-02 12:30:51,456 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:30:51, elapsed: 00:00:03
2020-05-02 12:30:52,724 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:53,138 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:30:53
2020-05-02 12:30:53,138 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:30:53,138 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:30:53,139 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:30:53,139 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:30:53,139 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502123035
2020-05-02 12:30:53,917 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:53,918 INFO  mapreduce.Job - Running job: job_local1892626895_0001
2020-05-02 12:30:54,924 INFO  mapreduce.Job - Job job_local1892626895_0001 running in uber mode : false
2020-05-02 12:30:54,926 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:54,927 INFO  mapreduce.Job - Job job_local1892626895_0001 completed successfully
2020-05-02 12:30:54,940 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2790511
		FILE: Number of bytes written=4481375
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=332
		Combine input records=1
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2442
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:30:54,941 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:30:55,225 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:55,225 INFO  mapreduce.Job - Running job: job_local947088815_0002
2020-05-02 12:30:55,540 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:30:55,617 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:30:56,230 INFO  mapreduce.Job - Job job_local947088815_0002 running in uber mode : false
2020-05-02 12:30:56,230 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:56,231 INFO  mapreduce.Job - Job job_local947088815_0002 completed successfully
2020-05-02 12:30:56,235 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5576026
		FILE: Number of bytes written=8956949
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:30:56,256 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:30:56, elapsed: 00:00:03
2020-05-02 12:30:57,220 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 12:30:57
2020-05-02 12:30:57,478 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:30:58,799 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:30:58,800 INFO  mapreduce.Job - Running job: job_local1223872680_0001
2020-05-02 12:30:59,805 INFO  mapreduce.Job - Job job_local1223872680_0001 running in uber mode : false
2020-05-02 12:30:59,806 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:30:59,807 INFO  mapreduce.Job - Job job_local1223872680_0001 completed successfully
2020-05-02 12:30:59,823 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2812628
		FILE: Number of bytes written=4485870
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=2
		Map output bytes=526
		Map output materialized bytes=544
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=544
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11307
	File Output Format Counters 
		Bytes Written=98
2020-05-02 12:30:59,829 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 12:30:59,829 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 12:31:00,131 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:31:00,131 INFO  mapreduce.Job - Running job: job_local1351690861_0002
2020-05-02 12:31:01,131 INFO  mapreduce.Job - Job job_local1351690861_0002 running in uber mode : false
2020-05-02 12:31:01,132 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:31:01,132 INFO  mapreduce.Job - Job job_local1351690861_0002 completed successfully
2020-05-02 12:31:01,137 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7533952
		FILE: Number of bytes written=12014349
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10163
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10163
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11405
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:31:01,160 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 12:31:01, elapsed: 00:00:03
2020-05-02 12:31:02,336 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:31:02,805 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123035.
2020-05-02 12:31:02,812 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:31:02
2020-05-02 12:31:02,839 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 12:31:02,843 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 12:31:02,843 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 12:31:02,845 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:31:02,845 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:31:02,845 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123035
2020-05-02 12:31:03,846 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:31:03,846 INFO  mapreduce.Job - Running job: job_local278292428_0001
2020-05-02 12:31:04,854 INFO  mapreduce.Job - Job job_local278292428_0001 running in uber mode : false
2020-05-02 12:31:04,856 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:31:05,437 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:31:05,468 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:31:05,789 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 12:31:06,406 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 29; The entity name must immediately follow the '&' in the entity reference.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanAttribute(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 12:31:06,419 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:31:06,427 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 12:31:06,431 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:31:06,432 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:31:06,866 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:31:06,866 INFO  mapreduce.Job - Job job_local278292428_0001 completed successfully
2020-05-02 12:31:06,891 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10918898
		FILE: Number of bytes written=17314239
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=343
		Map output records=343
		Map output bytes=77719
		Map output materialized bytes=78477
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=78477
		Reduce input records=343
		Reduce output records=2
		Spilled Records=686
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=249
		Total committed heap usage (bytes)=4905762816
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47833
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:31:06,892 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:31:06,898 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:31:06,936 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:31:06, elapsed: 00:00:04
2020-05-02 12:31:08,233 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 12:31:08
2020-05-02 12:31:08,490 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:31:09,647 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:31:09,647 INFO  mapreduce.Job - Running job: job_local691215537_0001
2020-05-02 12:31:10,536 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:31:10,563 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:31:10,654 INFO  mapreduce.Job - Job job_local691215537_0001 running in uber mode : false
2020-05-02 12:31:10,656 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:31:11,139 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 12:31:11,662 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:31:11,662 INFO  mapreduce.Job - Job job_local691215537_0001 completed successfully
2020-05-02 12:31:11,677 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1877012
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=109
		Total committed heap usage (bytes)=485490688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:31:11,697 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 12:31:11, elapsed: 00:00:03
2020-05-02 12:32:28,857 INFO  crawl.Injector - Injector: starting at 2020-05-02 12:32:28
2020-05-02 12:32:28,858 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 12:32:28,859 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 12:32:28,859 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 12:32:29,077 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:29,553 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 12:32:30,720 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:30,721 INFO  mapreduce.Job - Running job: job_local814469525_0001
2020-05-02 12:32:31,156 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 12:32:31,326 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 12:32:31,326 INFO  crawl.Injector - Injector: update: false
2020-05-02 12:32:31,731 INFO  mapreduce.Job - Job job_local814469525_0001 running in uber mode : false
2020-05-02 12:32:31,733 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:31,734 INFO  mapreduce.Job - Job job_local814469525_0001 completed successfully
2020-05-02 12:32:31,746 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855256
		FILE: Number of bytes written=2982521
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=136
		Map output materialized bytes=146
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=146
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=2
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=493
2020-05-02 12:32:31,756 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 12:32:31,756 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 2
2020-05-02 12:32:31,756 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 12:32:31,757 INFO  crawl.Injector - Injector: Total new urls injected: 2
2020-05-02 12:32:31,777 INFO  crawl.Injector - Injector: finished at 2020-05-02 12:32:31, elapsed: 00:00:02
2020-05-02 12:32:32,781 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:33,158 INFO  crawl.Generator - Generator: starting at 2020-05-02 12:32:33
2020-05-02 12:32:33,158 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 12:32:33,158 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 12:32:33,159 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 12:32:33,161 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 12:32:34,678 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:34,679 INFO  mapreduce.Job - Running job: job_local582083460_0001
2020-05-02 12:32:35,540 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:32:35,542 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:32:35,542 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:32:35,548 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 12:32:35,682 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 12:32:35,707 INFO  mapreduce.Job - Job job_local582083460_0001 running in uber mode : false
2020-05-02 12:32:35,709 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:32:36,712 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:36,713 INFO  mapreduce.Job - Job job_local582083460_0001 completed successfully
2020-05-02 12:32:36,727 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783168
		FILE: Number of bytes written=4485734
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=194
		Map output materialized bytes=116
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=116
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=250
	File Output Format Counters 
		Bytes Written=16
2020-05-02 12:32:36,727 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 12:32:36,732 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 12:32:37,738 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502123237
2020-05-02 12:32:37,989 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:37,989 INFO  mapreduce.Job - Running job: job_local792648426_0002
2020-05-02 12:32:38,995 INFO  mapreduce.Job - Job job_local792648426_0002 running in uber mode : false
2020-05-02 12:32:38,995 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:38,996 INFO  mapreduce.Job - Job job_local792648426_0002 completed successfully
2020-05-02 12:32:39,011 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3711250
		FILE: Number of bytes written=5976444
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=264
		Map output materialized bytes=106
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=106
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=330
	File Output Format Counters 
		Bytes Written=292
2020-05-02 12:32:39,030 INFO  crawl.Generator - Generator: finished at 2020-05-02 12:32:39, elapsed: 00:00:05
2020-05-02 12:32:40,156 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 12:32:40
2020-05-02 12:32:40,158 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502123237
2020-05-02 12:32:40,160 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588408360159  (2020-05-02 15:32:40)
2020-05-02 12:32:40,368 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:41,443 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:41,443 INFO  mapreduce.Job - Running job: job_local694669425_0001
2020-05-02 12:32:41,631 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 12:32:41,631 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 12:32:41,631 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 12:32:41,641 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records hit by time limit : 0
2020-05-02 12:32:41,892 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:41,916 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:41,916 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:41,917 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 12:32:42,132 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 12:32:42,134 INFO  http.Http - http.proxy.host = null
2020-05-02 12:32:42,134 INFO  http.Http - http.proxy.port = 8080
2020-05-02 12:32:42,135 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 12:32:42,135 INFO  http.Http - http.timeout = 30000
2020-05-02 12:32:42,135 INFO  http.Http - http.content.limit = -1
2020-05-02 12:32:42,135 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 12:32:42,135 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 12:32:42,135 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 12:32:42,135 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 12:32:42,135 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,147 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,148 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,148 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,149 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,150 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,151 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,152 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,154 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,154 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,155 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,156 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,156 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,157 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,158 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,159 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,160 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,161 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,162 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,163 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,164 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,165 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,165 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,166 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,168 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,168 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,169 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,169 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,170 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,170 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,171 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,172 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,172 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,173 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,173 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,175 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,176 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,177 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,177 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,178 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,180 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,181 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,182 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,182 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,183 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,183 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,184 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,184 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,185 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,186 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,186 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,187 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,188 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,189 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,190 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,192 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,194 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,195 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,197 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,198 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,198 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,200 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,201 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,202 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,203 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,207 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,207 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,209 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,209 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,210 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,211 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,211 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,214 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,214 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,215 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,215 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,216 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,217 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,218 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,219 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,220 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,220 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,221 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,222 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,222 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:42,223 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 12:32:42,223 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 12:32:42,224 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 12:32:42,224 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 12:32:42,453 INFO  mapreduce.Job - Job job_local694669425_0001 running in uber mode : false
2020-05-02 12:32:42,454 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:32:43,228 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588397561640
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   now           = 1588397563229
2020-05-02 12:32:43,229 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-se/specs/
2020-05-02 12:32:43,770 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=49
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 12:32:44,160 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=48
2020-05-02 12:32:44,161 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=47
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=45
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=41
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=43
2020-05-02 12:32:44,167 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=46
2020-05-02 12:32:44,168 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=42
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=39
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=38
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 12:32:44,181 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 12:32:44,181 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=35
2020-05-02 12:32:44,181 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=36
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=40
2020-05-02 12:32:44,180 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 12:32:44,182 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=34
2020-05-02 12:32:44,183 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 12:32:44,183 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=33
2020-05-02 12:32:44,190 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 12:32:44,190 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=32
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=30
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=29
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 12:32:44,193 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=28
2020-05-02 12:32:44,193 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=27
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 12:32:44,192 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=31
2020-05-02 12:32:44,193 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=26
2020-05-02 12:32:44,200 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=24
2020-05-02 12:32:44,200 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 12:32:44,200 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=23
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=25
2020-05-02 12:32:44,201 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=22
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 12:32:44,209 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=20
2020-05-02 12:32:44,209 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=19
2020-05-02 12:32:44,208 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=21
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=18
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=17
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=15
2020-05-02 12:32:44,218 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=16
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=14
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=13
2020-05-02 12:32:44,219 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 12:32:44,220 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=12
2020-05-02 12:32:44,223 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=10
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=8
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=9
2020-05-02 12:32:44,224 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=11
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=7
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=6
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 12:32:44,227 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=5
2020-05-02 12:32:44,226 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 12:32:44,227 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=4
2020-05-02 12:32:44,230 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 12:32:44,230 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 12:32:44,231 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=2
2020-05-02 12:32:44,231 INFO  fetcher.Fetcher - -activeThreads=2, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 12:32:44,230 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 12:32:44,231 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=1
2020-05-02 12:32:44,231 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=3
2020-05-02 12:32:44,921 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 12:32:44,921 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=0
2020-05-02 12:32:45,234 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 12:32:45,234 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 12:32:45,465 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 12:32:46,466 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:46,467 INFO  mapreduce.Job - Job job_local694669425_0001 completed successfully
2020-05-02 12:32:46,491 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2869161
		FILE: Number of bytes written=4667882
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=235541
		Map output materialized bytes=39056
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=39056
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=967311360
	FetcherStatus
		bytes_downloaded=233595
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=292
	File Output Format Counters 
		Bytes Written=41233
2020-05-02 12:32:46,492 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 12:32:46, elapsed: 00:00:06
2020-05-02 12:32:47,505 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:47,854 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:32:47
2020-05-02 12:32:47,863 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 12:32:48,712 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:48,713 INFO  mapreduce.Job - Running job: job_local1163383892_0001
2020-05-02 12:32:49,721 INFO  mapreduce.Job - Job job_local1163383892_0001 running in uber mode : false
2020-05-02 12:32:49,722 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:32:50,143 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:32:50,149 INFO  parse.ParseSegment - Parsed (964ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:32:50,246 INFO  parse.ParseSegment - Parsed (91ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:32:50,430 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:50,546 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:32:50,630 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:32:50,725 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:50,726 INFO  mapreduce.Job - Job job_local1163383892_0001 completed successfully
2020-05-02 12:32:50,745 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3922372
		FILE: Number of bytes written=6121332
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=73509
		Map output materialized bytes=22016
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=22016
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=1599602688
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:32:50,760 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:32:50, elapsed: 00:00:02
2020-05-02 12:32:51,854 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:52,286 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:32:52
2020-05-02 12:32:52,286 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:32:52,286 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502123237]
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:32:52,287 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:32:52,289 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:32:53,115 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:53,116 INFO  mapreduce.Job - Running job: job_local1976587974_0001
2020-05-02 12:32:54,092 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:32:54,092 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:32:54,092 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:32:54,122 INFO  mapreduce.Job - Job job_local1976587974_0001 running in uber mode : false
2020-05-02 12:32:54,123 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:54,161 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:32:54,161 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:32:54,161 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:32:55,128 INFO  mapreduce.Job - Job job_local1976587974_0001 completed successfully
2020-05-02 12:32:55,145 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6630934
		FILE: Number of bytes written=10487358
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=206
		Map output records=206
		Map output bytes=15039
		Map output materialized bytes=1492
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=1492
		Reduce input records=206
		Reduce output records=134
		Spilled Records=412
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16738
	File Output Format Counters 
		Bytes Written=11780
2020-05-02 12:32:55,161 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:32:55, elapsed: 00:00:02
2020-05-02 12:32:56,274 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:32:56,626 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:32:56
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:32:56,627 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502123237
2020-05-02 12:32:57,427 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:57,428 INFO  mapreduce.Job - Running job: job_local1984024131_0001
2020-05-02 12:32:58,435 INFO  mapreduce.Job - Job job_local1984024131_0001 running in uber mode : false
2020-05-02 12:32:58,436 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:58,438 INFO  mapreduce.Job - Job job_local1984024131_0001 completed successfully
2020-05-02 12:32:58,450 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2791318
		FILE: Number of bytes written=4481375
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=100
		Input split bytes=332
		Combine input records=1
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=100
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2711
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:32:58,451 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:32:58,718 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:32:58,718 INFO  mapreduce.Job - Running job: job_local235983396_0002
2020-05-02 12:32:59,057 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:32:59,136 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:32:59,724 INFO  mapreduce.Job - Job job_local235983396_0002 running in uber mode : false
2020-05-02 12:32:59,724 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:32:59,725 INFO  mapreduce.Job - Job job_local235983396_0002 completed successfully
2020-05-02 12:32:59,728 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5576833
		FILE: Number of bytes written=8956943
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:32:59,748 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:32:59, elapsed: 00:00:03
2020-05-02 12:33:00,811 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 12:33:00
2020-05-02 12:33:01,079 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:33:02,308 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:02,309 INFO  mapreduce.Job - Running job: job_local975607059_0001
2020-05-02 12:33:03,318 INFO  mapreduce.Job - Job job_local975607059_0001 running in uber mode : false
2020-05-02 12:33:03,319 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:03,320 INFO  mapreduce.Job - Job job_local975607059_0001 completed successfully
2020-05-02 12:33:03,337 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2812628
		FILE: Number of bytes written=4477680
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=2
		Map output bytes=526
		Map output materialized bytes=544
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=544
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11307
	File Output Format Counters 
		Bytes Written=98
2020-05-02 12:33:03,342 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 12:33:03,342 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 12:33:03,624 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:03,625 INFO  mapreduce.Job - Running job: job_local1590328680_0002
2020-05-02 12:33:04,625 INFO  mapreduce.Job - Job job_local1590328680_0002 running in uber mode : false
2020-05-02 12:33:04,626 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:04,626 INFO  mapreduce.Job - Job job_local1590328680_0002 completed successfully
2020-05-02 12:33:04,631 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7533952
		FILE: Number of bytes written=12003437
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10163
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10163
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11405
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:33:04,659 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 12:33:04, elapsed: 00:00:03
2020-05-02 12:33:05,855 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:33:06,257 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 12:33:06,261 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:33:06
2020-05-02 12:33:06,277 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 12:33:06,278 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 12:33:06,278 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 12:33:06,279 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:33:06,279 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:33:06,279 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 12:33:07,203 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:07,204 INFO  mapreduce.Job - Running job: job_local1345408470_0001
2020-05-02 12:33:08,211 INFO  mapreduce.Job - Job job_local1345408470_0001 running in uber mode : false
2020-05-02 12:33:08,212 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:33:08,818 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:33:08,853 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:33:09,212 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 12:33:09,765 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:33:09,765 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:33:10,219 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:10,219 INFO  mapreduce.Job - Job job_local1345408470_0001 completed successfully
2020-05-02 12:33:10,243 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10922547
		FILE: Number of bytes written=17351041
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=343
		Map output records=343
		Map output bytes=78469
		Map output materialized bytes=79227
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=79227
		Reduce input records=343
		Reduce output records=2
		Spilled Records=686
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=258
		Total committed heap usage (bytes)=4902617088
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=48102
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:33:10,243 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:33:10,251 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:33:10,270 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:33:10, elapsed: 00:00:03
2020-05-02 12:33:11,343 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 12:33:11
2020-05-02 12:33:11,556 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:33:12,729 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:33:12,730 INFO  mapreduce.Job - Running job: job_local1698280545_0001
2020-05-02 12:33:13,288 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:33:13,310 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:33:13,641 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 12:33:13,737 INFO  mapreduce.Job - Job job_local1698280545_0001 running in uber mode : false
2020-05-02 12:33:13,738 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:33:13,739 INFO  mapreduce.Job - Job job_local1698280545_0001 completed successfully
2020-05-02 12:33:13,756 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1877012
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=64
		Total committed heap usage (bytes)=480247808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:33:13,773 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 12:33:13, elapsed: 00:00:02
2020-05-02 12:34:54,673 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:34:55,001 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 12:34:54
2020-05-02 12:34:55,016 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 12:34:55,973 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:34:55,974 INFO  mapreduce.Job - Running job: job_local2091542275_0001
2020-05-02 12:34:56,994 INFO  mapreduce.Job - Job job_local2091542275_0001 running in uber mode : false
2020-05-02 12:34:56,995 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 12:34:57,495 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 12:34:57,512 INFO  parse.ParseSegment - Parsed (1077ms):https://www.apple.com/iphone-11/specs/
2020-05-02 12:34:57,594 INFO  parse.ParseSegment - Parsed (73ms):https://www.apple.com/iphone-se/specs/
2020-05-02 12:34:57,790 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 12:34:57,891 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 12:34:58,001 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:34:58,002 INFO  mapreduce.Job - Job job_local2091542275_0001 completed successfully
2020-05-02 12:34:58,021 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051485
		FILE: Number of bytes written=4815453
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74589
		Map output materialized bytes=74609
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74609
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=70
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:34:58,039 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 12:34:58, elapsed: 00:00:03
2020-05-02 12:34:59,135 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 12:34:59
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502123237]
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 12:34:59,521 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 12:34:59,523 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 12:35:00,310 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:00,310 INFO  mapreduce.Job - Running job: job_local818564524_0001
2020-05-02 12:35:01,176 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 12:35:01,177 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 12:35:01,177 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 12:35:01,319 INFO  mapreduce.Job - Job job_local818564524_0001 running in uber mode : false
2020-05-02 12:35:01,320 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:01,321 INFO  mapreduce.Job - Job job_local818564524_0001 completed successfully
2020-05-02 12:35:01,336 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=4821180
		FILE: Number of bytes written=7607986
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=338
		Map output records=338
		Map output bytes=24778
		Map output materialized bytes=25482
		Input split bytes=643
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=25482
		Reduce input records=338
		Reduce output records=134
		Spilled Records=676
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=2290614272
	CrawlDB status
		db_notmodified=2
		db_unfetched=132
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27570
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 12:35:01,358 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 12:35:01, elapsed: 00:00:01
2020-05-02 12:35:02,542 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:35:03,054 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 12:35:03
2020-05-02 12:35:03,054 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 12:35:03,054 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 12:35:03,055 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 12:35:03,055 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 12:35:03,055 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502123237
2020-05-02 12:35:03,057 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502123035
2020-05-02 12:35:03,058 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502113756
2020-05-02 12:35:03,058 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502122427
2020-05-02 12:35:03,923 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:03,924 INFO  mapreduce.Job - Running job: job_local1609115478_0001
2020-05-02 12:35:04,932 INFO  mapreduce.Job - Job job_local1609115478_0001 running in uber mode : false
2020-05-02 12:35:04,934 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:35:05,936 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:05,936 INFO  mapreduce.Job - Job job_local1609115478_0001 completed successfully
2020-05-02 12:35:05,959 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8494100
		FILE: Number of bytes written=13461278
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=11
		Map output records=5
		Map output bytes=430
		Map output materialized bytes=488
		Input split bytes=1328
		Combine input records=5
		Combine output records=5
		Reduce input groups=1
		Reduce shuffle bytes=488
		Reduce input records=5
		Reduce output records=1
		Spilled Records=10
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=126
		Total committed heap usage (bytes)=3997696000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14103
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:35:05,959 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 12:35:06,322 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:06,323 INFO  mapreduce.Job - Running job: job_local1707203967_0002
2020-05-02 12:35:06,569 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:35:06,647 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 12:35:07,325 INFO  mapreduce.Job - Job job_local1707203967_0002 running in uber mode : false
2020-05-02 12:35:07,326 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:07,326 INFO  mapreduce.Job - Job job_local1707203967_0002 completed successfully
2020-05-02 12:35:07,331 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5636847
		FILE: Number of bytes written=8972789
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=172
		Map output materialized bytes=188
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=188
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1003487232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=480
	File Output Format Counters 
		Bytes Written=486
2020-05-02 12:35:07,349 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 12:35:07, elapsed: 00:00:04
2020-05-02 12:35:08,594 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 12:35:09,022 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 12:35:09,026 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 12:35:09
2020-05-02 12:35:09,046 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 12:35:09,049 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 12:35:09,049 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 12:35:09,051 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 12:35:09,052 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 12:35:09,052 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 12:35:09,968 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 12:35:09,968 INFO  mapreduce.Job - Running job: job_local136365703_0001
2020-05-02 12:35:10,486 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,590 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,709 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,843 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,945 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:10,978 INFO  mapreduce.Job - Job job_local136365703_0001 running in uber mode : false
2020-05-02 12:35:10,980 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 12:35:11,044 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:11,126 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:11,169 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 12:35:11,316 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 12:35:11,344 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 12:35:11,767 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 12:35:12,356 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 12:35:12,357 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 12:35:12,985 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 12:35:12,986 INFO  mapreduce.Job - Job job_local136365703_0001 completed successfully
2020-05-02 12:35:13,021 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10175046
		FILE: Number of bytes written=16199521
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132815
		Map output materialized bytes=133583
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133583
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=158
		Total committed heap usage (bytes)=6192365568
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68280
	File Output Format Counters 
		Bytes Written=0
2020-05-02 12:35:13,021 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 12:35:13,032 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 12:35:13,057 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 12:35:13, elapsed: 00:00:04
2020-05-02 13:51:21,083 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:51:21,540 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 13:51:21
2020-05-02 13:51:21,553 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 13:51:22,766 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:51:22,767 INFO  mapreduce.Job - Running job: job_local1584879996_0001
2020-05-02 13:51:23,776 INFO  mapreduce.Job - Job job_local1584879996_0001 running in uber mode : false
2020-05-02 13:51:23,778 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 13:51:24,511 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
org.jsoup.select.Selector$SelectorParseException: Could not parse query 'li:nth-child': unexpected token at ':nth-child'
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:196)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:65)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.QueryParser.combinator(QueryParser.java:81)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:61)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 13:51:24,517 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 13:51:24,527 INFO  parse.ParseSegment - Parsed (1238ms):https://www.apple.com/iphone-11/specs/
2020-05-02 13:51:24,653 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
org.jsoup.select.Selector$SelectorParseException: Could not parse query 'li:nth-child': unexpected token at ':nth-child'
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:196)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:65)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.QueryParser.combinator(QueryParser.java:81)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:61)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 13:51:24,654 INFO  parse.ParseSegment - Parsed (121ms):https://www.apple.com/iphone-se/specs/
2020-05-02 13:51:24,781 INFO  mapreduce.Job -  map 50% reduce 0%
2020-05-02 13:51:24,910 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 13:51:25,030 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 13:51:25,784 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:51:25,785 INFO  mapreduce.Job - Job job_local1584879996_0001 completed successfully
2020-05-02 13:51:25,807 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3047825
		FILE: Number of bytes written=4806997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=72779
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=72779
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=93
		Total committed heap usage (bytes)=1094713344
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:51:25,827 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 13:51:25, elapsed: 00:00:04
2020-05-02 13:51:30,058 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:51:30,470 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 13:51:30,473 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 13:51:30
2020-05-02 13:51:30,490 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 13:51:30,491 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 13:51:30,491 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 13:51:30,494 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 13:51:30,494 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 13:51:30,494 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 13:51:31,417 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:51:31,418 INFO  mapreduce.Job - Running job: job_local1354606022_0001
2020-05-02 13:51:31,880 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:31,968 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,053 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,308 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,406 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,427 INFO  mapreduce.Job - Job job_local1354606022_0001 running in uber mode : false
2020-05-02 13:51:32,429 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 13:51:32,479 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,561 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,599 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:51:32,745 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 13:51:32,771 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 13:51:33,190 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 13:51:33,793 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 13:51:33,794 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 13:51:34,437 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:51:34,438 INFO  mapreduce.Job - Job job_local1354606022_0001 completed successfully
2020-05-02 13:51:34,457 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10164606
		FILE: Number of bytes written=16214801
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130985
		Map output materialized bytes=131753
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131753
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=151
		Total committed heap usage (bytes)=6202851328
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=67144
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:51:34,458 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 13:51:34,470 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 13:51:34,491 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 13:51:34, elapsed: 00:00:04
2020-05-02 13:55:27,978 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:55:28,376 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 13:55:28
2020-05-02 13:55:28,377 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 13:55:29,515 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:55:29,516 INFO  mapreduce.Job - Running job: job_local561342441_0001
2020-05-02 13:55:30,524 INFO  mapreduce.Job - Job job_local561342441_0001 running in uber mode : false
2020-05-02 13:55:30,526 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 13:55:31,677 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 13:55:31,685 INFO  parse.ParseSegment - Parsed (1342ms):https://www.apple.com/iphone-11/specs/
2020-05-02 13:55:31,823 INFO  parse.ParseSegment - Parsed (132ms):https://www.apple.com/iphone-se/specs/
2020-05-02 13:55:32,098 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 13:55:32,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 13:55:32,535 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:55:32,536 INFO  mapreduce.Job - Job job_local561342441_0001 completed successfully
2020-05-02 13:55:32,551 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051477
		FILE: Number of bytes written=4807251
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74585
		Map output materialized bytes=74605
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74605
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=85
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:55:32,565 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 13:55:32, elapsed: 00:00:04
2020-05-02 13:55:34,937 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 13:55:35,287 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 13:55:35,290 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 13:55:35
2020-05-02 13:55:35,300 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 13:55:35,300 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 13:55:35,300 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 13:55:35,302 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 13:55:35,302 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 13:55:35,302 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 13:55:36,213 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 13:55:36,213 INFO  mapreduce.Job - Running job: job_local1727010_0001
2020-05-02 13:55:36,673 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:36,775 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:36,944 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,175 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,219 INFO  mapreduce.Job - Job job_local1727010_0001 running in uber mode : false
2020-05-02 13:55:37,220 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 13:55:37,381 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,443 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,587 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,629 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 13:55:37,782 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 13:55:37,819 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 13:55:38,249 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 13:55:38,832 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 13:55:38,833 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 13:55:39,227 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 13:55:39,228 INFO  mapreduce.Job - Job job_local1727010_0001 completed successfully
2020-05-02 13:55:39,248 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10174864
		FILE: Number of bytes written=16144813
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132811
		Map output materialized bytes=133579
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133579
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=152
		Total committed heap usage (bytes)=6239551488
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68266
	File Output Format Counters 
		Bytes Written=0
2020-05-02 13:55:39,248 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 13:55:39,256 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 13:55:39,274 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 13:55:39, elapsed: 00:00:03
2020-05-02 14:12:07,926 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:12:08,451 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:12:08
2020-05-02 14:12:08,451 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:12:09,625 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:12:09,626 INFO  mapreduce.Job - Running job: job_local980336322_0001
2020-05-02 14:12:10,636 INFO  mapreduce.Job - Job job_local980336322_0001 running in uber mode : false
2020-05-02 14:12:10,637 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:12:11,647 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleEndElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.endElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.endElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.endElement(ValidatingUnmarshaller.java:106)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.endElement(SAXConnector.java:160)
	at org.apache.xerces.parsers.AbstractSAXParser.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 14:12:11,928 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 14:12:11,932 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:12:11,941 INFO  parse.ParseSegment - Parsed (1648ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:12:12,011 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 14:12:12,016 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:12:12,260 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:12:12,390 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:12:12,648 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:12:12,649 INFO  mapreduce.Job - Job job_local980336322_0001 completed successfully
2020-05-02 14:12:12,668 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3047825
		FILE: Number of bytes written=4798851
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=72759
		Map output materialized bytes=72779
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=72779
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=118
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:12:12,686 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:12:12, elapsed: 00:00:04
2020-05-02 14:12:14,608 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:12:15,018 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:12:15,021 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:12:15
2020-05-02 14:12:15,030 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:12:15,030 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:12:15,030 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:12:15,031 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:12:15,031 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:12:15,031 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:12:15,887 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:12:15,888 INFO  mapreduce.Job - Running job: job_local1180867473_0001
2020-05-02 14:12:16,345 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,433 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,509 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,749 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,865 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:16,894 INFO  mapreduce.Job - Job job_local1180867473_0001 running in uber mode : false
2020-05-02 14:12:16,896 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:12:17,032 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:17,107 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:17,144 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:12:17,262 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:12:17,288 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:12:17,683 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 14:12:18,175 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 43; columnNumber: 10; cvc-id.1: There is no ID/IDREF binding for IDREF 'test'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleEndElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.endElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.endElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.endElement(ValidatingUnmarshaller.java:106)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.endElement(SAXConnector.java:160)
	at org.apache.xerces.parsers.AbstractSAXParser.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 14:12:18,187 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 14:12:18,194 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 14:12:18,198 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:12:18,201 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:12:18,901 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:12:18,901 INFO  mapreduce.Job - Job job_local1180867473_0001 completed successfully
2020-05-02 14:12:18,923 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10164814
		FILE: Number of bytes written=16214821
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=130985
		Map output materialized bytes=131753
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=131753
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=171
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=67170
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:12:18,924 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:12:18,930 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:12:18,946 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:12:18, elapsed: 00:00:03
2020-05-02 14:13:05,302 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:13:05,637 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:13:05
2020-05-02 14:13:05,638 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:13:06,404 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:13:06,405 INFO  mapreduce.Job - Running job: job_local1171411644_0001
2020-05-02 14:13:07,411 INFO  mapreduce.Job - Job job_local1171411644_0001 running in uber mode : false
2020-05-02 14:13:07,412 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:13:07,891 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:13:07,898 INFO  parse.ParseSegment - Parsed (1037ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:13:08,041 INFO  parse.ParseSegment - Parsed (137ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:13:08,251 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:13:08,361 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:13:08,415 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:13:09,422 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:13:09,422 INFO  mapreduce.Job - Job job_local1171411644_0001 completed successfully
2020-05-02 14:13:09,436 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051437
		FILE: Number of bytes written=4815187
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74565
		Map output materialized bytes=74585
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74585
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:13:09,453 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:13:09, elapsed: 00:00:03
2020-05-02 14:13:12,006 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:13:12,340 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:13:12,346 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:13:12
2020-05-02 14:13:12,365 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:13:12,369 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:13:12,369 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:13:12,370 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:13:12,370 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:13:12,371 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:13:13,315 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:13:13,316 INFO  mapreduce.Job - Running job: job_local144629722_0001
2020-05-02 14:13:13,765 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:13,857 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:13,943 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,170 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,267 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,327 INFO  mapreduce.Job - Job job_local144629722_0001 running in uber mode : false
2020-05-02 14:13:14,327 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:13:14,351 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,409 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,447 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:13:14,597 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:13:14,627 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:13:15,052 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 14:13:15,692 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:13:15,706 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:13:16,334 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:13:16,335 INFO  mapreduce.Job - Job job_local144629722_0001 completed successfully
2020-05-02 14:13:16,362 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10173574
		FILE: Number of bytes written=16199373
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132791
		Map output materialized bytes=133559
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133559
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=167
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68110
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:13:16,362 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:13:16,369 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:13:16,388 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:13:16, elapsed: 00:00:04
2020-05-02 14:16:41,512 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:16:41,993 WARN  parse.ParseSegment - Segment: crawl/segments/20200502123237 already parsed!! Skipped parsing this segment!!
2020-05-02 14:16:57,891 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:16:58,264 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:16:58
2020-05-02 14:16:58,265 INFO  parse.ParseSegment - ParseSegment: segment: -h
2020-05-02 14:16:58,617 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/-h/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:261)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:308)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:280)

2020-05-02 14:18:01,756 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:18:02,086 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:18:02
2020-05-02 14:18:02,087 INFO  parse.ParseSegment - ParseSegment: segment: -h
2020-05-02 14:18:02,532 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/-h/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:261)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:308)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:280)

2020-05-02 14:18:19,943 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:18:20,303 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:18:20
2020-05-02 14:18:20,303 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:18:21,173 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:18:21,175 INFO  mapreduce.Job - Running job: job_local1591981312_0001
2020-05-02 14:18:22,181 INFO  mapreduce.Job - Job job_local1591981312_0001 running in uber mode : false
2020-05-02 14:18:22,182 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:18:22,740 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:18:22,758 INFO  parse.ParseSegment - Parsed (1118ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:18:22,912 INFO  parse.ParseSegment - Parsed (147ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:18:23,130 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:18:23,185 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:18:23,244 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:18:24,188 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:18:24,189 INFO  mapreduce.Job - Job job_local1591981312_0001 completed successfully
2020-05-02 14:18:24,204 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051437
		FILE: Number of bytes written=4815188
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74565
		Map output materialized bytes=74585
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74585
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=73
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:18:24,221 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:18:24, elapsed: 00:00:03
2020-05-02 14:18:26,506 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:18:26,872 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:18:26,875 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:18:26
2020-05-02 14:18:26,886 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:18:26,886 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:18:26,886 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:18:26,890 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:18:26,890 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:18:26,890 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:18:27,758 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:18:27,759 INFO  mapreduce.Job - Running job: job_local747192086_0001
2020-05-02 14:18:28,218 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,315 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,422 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,621 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,728 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,765 INFO  mapreduce.Job - Job job_local747192086_0001 running in uber mode : false
2020-05-02 14:18:28,766 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:18:28,842 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,918 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:28,966 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:18:29,114 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:18:29,142 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:18:29,597 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 14:18:30,248 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:18:30,249 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:18:30,780 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:18:30,780 INFO  mapreduce.Job - Job job_local747192086_0001 completed successfully
2020-05-02 14:18:30,798 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10173582
		FILE: Number of bytes written=16199373
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132791
		Map output materialized bytes=133559
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133559
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=165
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68111
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:18:30,799 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:18:30,809 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:18:30,834 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:18:30, elapsed: 00:00:03
2020-05-02 14:24:56,001 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:24:56,355 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 14:24:56
2020-05-02 14:24:56,355 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502123237
2020-05-02 14:24:57,345 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:24:57,346 INFO  mapreduce.Job - Running job: job_local659961292_0001
2020-05-02 14:24:58,354 INFO  mapreduce.Job - Job job_local659961292_0001 running in uber mode : false
2020-05-02 14:24:58,355 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 14:24:58,814 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 14:24:58,824 INFO  parse.ParseSegment - Parsed (1038ms):https://www.apple.com/iphone-11/specs/
2020-05-02 14:24:58,940 INFO  parse.ParseSegment - Parsed (110ms):https://www.apple.com/iphone-se/specs/
2020-05-02 14:24:59,139 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 14:24:59,236 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 14:24:59,362 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:24:59,363 INFO  mapreduce.Job - Job job_local659961292_0001 completed successfully
2020-05-02 14:24:59,378 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3051437
		FILE: Number of bytes written=4807115
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=74565
		Map output materialized bytes=74585
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=74585
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=90
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=39771
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:24:59,397 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 14:24:59, elapsed: 00:00:03
2020-05-02 14:25:07,074 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 14:25:07,621 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502123237.
2020-05-02 14:25:07,623 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 14:25:07
2020-05-02 14:25:07,648 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 14:25:07,650 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 14:25:07,650 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 14:25:07,652 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 14:25:07,652 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 14:25:07,652 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502123237
2020-05-02 14:25:08,949 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 14:25:08,950 INFO  mapreduce.Job - Running job: job_local1564197029_0001
2020-05-02 14:25:09,480 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:09,612 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:09,857 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:09,959 INFO  mapreduce.Job - Job job_local1564197029_0001 running in uber mode : false
2020-05-02 14:25:09,960 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 14:25:10,072 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,260 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,315 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,402 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,453 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 14:25:10,630 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 14:25:10,661 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 14:25:11,446 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 14:25:12,351 INFO  solr.SolrIndexWriter - Indexing 2/2 documents
2020-05-02 14:25:12,352 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 14:25:12,974 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 14:25:12,974 INFO  mapreduce.Job - Job job_local1564197029_0001 completed successfully
2020-05-02 14:25:12,998 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10174374
		FILE: Number of bytes written=16226713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=347
		Map output records=347
		Map output bytes=132791
		Map output materialized bytes=133559
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=133559
		Reduce input records=347
		Reduce output records=2
		Spilled Records=694
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=217
		Total committed heap usage (bytes)=6242172928
	IndexerStatus
		indexed (add/update)=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=68210
	File Output Format Counters 
		Bytes Written=0
2020-05-02 14:25:12,998 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 14:25:13,006 INFO  indexer.IndexingJob - Indexer:      2  indexed (add/update)
2020-05-02 14:25:13,025 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 14:25:13, elapsed: 00:00:05
2020-05-02 17:22:44,794 INFO  util.SitemapProcessor - SitemapProcessor: sitemap urls dir: urls
2020-05-02 17:22:44,795 INFO  util.SitemapProcessor - SitemapProcessor: threads: 50
2020-05-02 17:22:44,795 INFO  util.SitemapProcessor - SitemapProcessor: Starting at 2020-05-02 17:22:44
2020-05-02 17:22:44,968 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:22:46,573 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:46,574 INFO  mapreduce.Job - Running job: job_local515781573_0001
2020-05-02 17:22:47,514 INFO  regex.RegexURLNormalizer - can't find rules for scope 'default', using default
2020-05-02 17:22:47,585 INFO  mapreduce.Job - Job job_local515781573_0001 running in uber mode : false
2020-05-02 17:22:47,586 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:22:47,809 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:22:47,818 INFO  http.Http - http.proxy.host = null
2020-05-02 17:22:47,818 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:22:47,818 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:22:47,818 INFO  http.Http - http.timeout = 30000
2020-05-02 17:22:47,818 INFO  http.Http - http.content.limit = -1
2020-05-02 17:22:47,818 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:22:47,818 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:22:47,818 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:22:47,818 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:22:49,006 INFO  util.SitemapProcessor - Parsing sitemap file: https://www.apple.com/sitemap.xml
2020-05-02 17:22:49,594 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:22:49,594 INFO  mapreduce.Job - Job job_local515781573_0001 completed successfully
2020-05-02 17:22:49,611 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2838622
		FILE: Number of bytes written=4525994
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=135
		Map output records=134
		Map output bytes=9875
		Map output materialized bytes=10157
		Input split bytes=614
		Combine input records=0
		Combine output records=0
		Reduce input groups=134
		Reduce shuffle bytes=10157
		Reduce input records=134
		Reduce output records=134
		Spilled Records=268
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=119
		Total committed heap usage (bytes)=919601152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	Sitemap
		existing_sitemap_entries=134
		sitemap_seeds=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=11489
2020-05-02 17:22:49,632 INFO  util.SitemapProcessor - SitemapProcessor: Total records rejected by filters: 0
2020-05-02 17:22:49,632 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from host name: 0
2020-05-02 17:22:49,632 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from seed urls: 1
2020-05-02 17:22:49,633 INFO  util.SitemapProcessor - SitemapProcessor: Total failed sitemap fetches: 0
2020-05-02 17:22:49,633 INFO  util.SitemapProcessor - SitemapProcessor: Total new sitemap entries added: 0
2020-05-02 17:22:49,634 INFO  util.SitemapProcessor - SitemapProcessor: Finished at 2020-05-02 17:22:49, elapsed: 00:00:04
2020-05-02 17:22:51,130 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: starting at 2020-05-02 17:22:51
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 17:22:51,569 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 17:22:51,572 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 17:22:52,485 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:52,487 INFO  mapreduce.Job - Running job: job_local1699725899_0001
2020-05-02 17:22:53,328 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:22:53,329 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:22:53,329 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:22:53,338 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 17:22:53,497 INFO  mapreduce.Job - Job job_local1699725899_0001 running in uber mode : false
2020-05-02 17:22:53,498 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:22:53,567 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:22:53,703 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:22:54,502 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:22:54,503 INFO  mapreduce.Job - Job job_local1699725899_0001 completed successfully
2020-05-02 17:22:54,524 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2819156
		FILE: Number of bytes written=4526369
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=134
		Map output records=132
		Map output bytes=13247
		Map output materialized bytes=878
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=878
		Reduce input records=132
		Reduce output records=0
		Spilled Records=264
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=805306368
	Generator
		SCHEDULE_REJECTED=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11229
	File Output Format Counters 
		Bytes Written=16
2020-05-02 17:22:54,524 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 17:22:54,527 INFO  crawl.Generator - Generator:      2  SCHEDULE_REJECTED
2020-05-02 17:22:54,529 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 17:22:55,529 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502172255
2020-05-02 17:22:55,813 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:55,814 INFO  mapreduce.Job - Running job: job_local752281513_0002
2020-05-02 17:22:56,818 INFO  mapreduce.Job - Job job_local752281513_0002 running in uber mode : false
2020-05-02 17:22:56,818 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:22:56,819 INFO  mapreduce.Job - Job job_local752281513_0002 completed successfully
2020-05-02 17:22:56,825 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5651408
		FILE: Number of bytes written=9039336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=132
		Map output records=132
		Map output bytes=18310
		Map output materialized bytes=1344
		Input split bytes=366
		Combine input records=0
		Combine output records=0
		Reduce input groups=132
		Reduce shuffle bytes=1344
		Reduce input records=132
		Reduce output records=132
		Spilled Records=264
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1332215808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14775
	File Output Format Counters 
		Bytes Written=13569
2020-05-02 17:22:56,927 INFO  crawl.Generator - Generator: finished at 2020-05-02 17:22:56, elapsed: 00:00:05
2020-05-02 17:22:58,029 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 17:22:57
2020-05-02 17:22:58,030 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502172255
2020-05-02 17:22:58,030 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588425778030  (2020-05-02 20:22:58)
2020-05-02 17:22:58,270 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:22:59,421 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:22:59,422 INFO  mapreduce.Job - Running job: job_local1299448771_0001
2020-05-02 17:22:59,604 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 17:22:59,604 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 17:22:59,605 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 17:22:59,652 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 132 records hit by time limit : 0
2020-05-02 17:22:59,994 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,015 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,025 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,025 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com.cn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:00,273 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:23:00,277 INFO  http.Http - http.proxy.host = null
2020-05-02 17:23:00,277 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:23:00,277 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:23:00,277 INFO  http.Http - http.timeout = 30000
2020-05-02 17:23:00,278 INFO  http.Http - http.content.limit = -1
2020-05-02 17:23:00,278 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:23:00,278 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:23:00,278 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:23:00,278 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:23:00,278 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,280 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/ie/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:00,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,281 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,282 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,283 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,284 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,286 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,287 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,299 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,300 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,302 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,304 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,304 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,305 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,305 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,306 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,313 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,316 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,319 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,321 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,323 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,323 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,326 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,327 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,328 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,329 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,329 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,330 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,330 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,332 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,334 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,335 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,335 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,445 INFO  mapreduce.Job - Job job_local1299448771_0001 running in uber mode : false
2020-05-02 17:23:00,446 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:23:00,448 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,448 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,449 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,449 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,450 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,450 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,461 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,470 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,472 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,473 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,478 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,481 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,495 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,495 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,505 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,506 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,507 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,508 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,508 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,509 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,510 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,511 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,511 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,512 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,513 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,514 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,514 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,515 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,518 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,518 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,520 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,520 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,521 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,521 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,522 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,523 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,524 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,525 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,527 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,528 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,528 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,529 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,529 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,530 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,531 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,531 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,532 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,532 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,533 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,534 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,535 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,535 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:23:00,536 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:23:00,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 17:23:00,536 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 17:23:00,537 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 17:23:01,539 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=130, fetchQueues.getQueueCount=2
2020-05-02 17:23:01,822 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/li/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:02,543 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=129, fetchQueues.getQueueCount=1
2020-05-02 17:23:02,898 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/th/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:03,287 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/ca/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:03,546 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=127, fetchQueues.getQueueCount=1
2020-05-02 17:23:03,870 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/mk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:04,547 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/au/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:04,550 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=125, fetchQueues.getQueueCount=1
2020-05-02 17:23:05,551 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=125, fetchQueues.getQueueCount=1
2020-05-02 17:23:05,663 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/ee/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:06,555 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=124, fetchQueues.getQueueCount=1
2020-05-02 17:23:06,761 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/de/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:07,556 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=123, fetchQueues.getQueueCount=1
2020-05-02 17:23:07,812 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/eg-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:08,556 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=122, fetchQueues.getQueueCount=1
2020-05-02 17:23:09,037 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/hk/en/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:09,264 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/ph/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:09,540 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/kw-ar/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:09,557 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=119, fetchQueues.getQueueCount=1
2020-05-02 17:23:10,265 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/vn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:10,557 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=118, fetchQueues.getQueueCount=1
2020-05-02 17:23:10,972 INFO  fetcher.FetcherThread - FetcherThread 56 fetching https://www.apple.com/eg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:11,558 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=117, fetchQueues.getQueueCount=1
2020-05-02 17:23:11,814 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/mo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:12,470 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-02 17:23:12,475 INFO  fetcher.FetcherThread - FetcherThread 57 fetching https://www.apple.com/fi/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:12,558 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=115, fetchQueues.getQueueCount=1
2020-05-02 17:23:13,548 INFO  fetcher.FetcherThread - FetcherThread 68 fetching https://www.apple.com/hk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:13,560 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=114, fetchQueues.getQueueCount=1
2020-05-02 17:23:14,484 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/ae-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:14,560 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=113, fetchQueues.getQueueCount=1
2020-05-02 17:23:15,565 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=113, fetchQueues.getQueueCount=1
2020-05-02 17:23:15,594 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/ae/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:16,566 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=112, fetchQueues.getQueueCount=1
2020-05-02 17:23:16,836 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.apple.com/id/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:17,567 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=111, fetchQueues.getQueueCount=1
2020-05-02 17:23:17,830 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/jo-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:18,567 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=110, fetchQueues.getQueueCount=1
2020-05-02 17:23:18,843 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/bg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:19,572 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=109, fetchQueues.getQueueCount=1
2020-05-02 17:23:19,792 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/jo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:20,573 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=108, fetchQueues.getQueueCount=1
2020-05-02 17:23:20,710 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/ca/fr/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:21,529 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/pl/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:21,576 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=106, fetchQueues.getQueueCount=1
2020-05-02 17:23:22,364 INFO  fetcher.FetcherThread - FetcherThread 47 fetching https://www.apple.com/ci/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:22,580 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=105, fetchQueues.getQueueCount=1
2020-05-02 17:23:23,580 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=50, fetchQueues.totalSize=105, fetchQueues.getQueueCount=1
2020-05-02 17:23:23,589 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/dk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:24,196 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/nl/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:24,581 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=103, fetchQueues.getQueueCount=1
2020-05-02 17:23:24,919 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/tr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:25,583 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=102, fetchQueues.getQueueCount=1
2020-05-02 17:23:25,860 INFO  fetcher.FetcherThread - FetcherThread 44 fetching https://www.apple.com/mu/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:26,460 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/lu/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:26,584 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=100, fetchQueues.getQueueCount=1
2020-05-02 17:23:27,495 INFO  fetcher.FetcherThread - FetcherThread 68 fetching https://www.apple.com/cm/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:27,584 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=99, fetchQueues.getQueueCount=1
2020-05-02 17:23:28,530 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/gq/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:28,586 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=98, fetchQueues.getQueueCount=1
2020-05-02 17:23:29,520 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/hk/en/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:29,587 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=97, fetchQueues.getQueueCount=1
2020-05-02 17:23:29,785 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/kw-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:30,589 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=96, fetchQueues.getQueueCount=1
2020-05-02 17:23:30,659 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/am/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:31,592 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=95, fetchQueues.getQueueCount=1
2020-05-02 17:23:31,757 INFO  fetcher.FetcherThread - FetcherThread 56 fetching https://www.apple.com/co/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:32,490 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/kw/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:32,596 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=93, fetchQueues.getQueueCount=1
2020-05-02 17:23:33,289 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.apple.com/my/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:33,601 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=92, fetchQueues.getQueueCount=1
2020-05-02 17:23:34,304 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/hu/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:34,603 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=91, fetchQueues.getQueueCount=1
2020-05-02 17:23:35,364 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/pt/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:35,606 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=90, fetchQueues.getQueueCount=1
2020-05-02 17:23:36,421 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/es/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:36,610 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=89, fetchQueues.getQueueCount=1
2020-05-02 17:23:37,101 INFO  fetcher.FetcherThread - FetcherThread 60 fetching https://www.apple.com/in/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:37,360 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/bh/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:37,611 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=87, fetchQueues.getQueueCount=1
2020-05-02 17:23:38,428 INFO  fetcher.FetcherThread - FetcherThread 46 fetching https://www.apple.com/jp/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:38,614 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=86, fetchQueues.getQueueCount=1
2020-05-02 17:23:39,467 INFO  fetcher.FetcherThread - FetcherThread 55 fetching https://www.apple.com/gw/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:39,615 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=85, fetchQueues.getQueueCount=1
2020-05-02 17:23:40,620 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=85, fetchQueues.getQueueCount=1
2020-05-02 17:23:41,214 INFO  fetcher.FetcherThread - FetcherThread 59 fetching https://www.apple.com/kr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:41,626 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=84, fetchQueues.getQueueCount=1
2020-05-02 17:23:41,941 INFO  fetcher.FetcherThread - FetcherThread 48 fetching https://www.apple.com/cl/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:42,621 INFO  fetcher.FetcherThread - FetcherThread 48 fetching https://www.apple.com/au/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:42,630 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=82, fetchQueues.getQueueCount=1
2020-05-02 17:23:43,242 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/it/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:43,635 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=81, fetchQueues.getQueueCount=1
2020-05-02 17:23:44,405 INFO  fetcher.FetcherThread - FetcherThread 60 fetching https://www.apple.com/mx/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:44,639 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=80, fetchQueues.getQueueCount=1
2020-05-02 17:23:45,134 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/bw/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:45,642 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=79, fetchQueues.getQueueCount=1
2020-05-02 17:23:46,147 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/fr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:46,643 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=78, fetchQueues.getQueueCount=1
2020-05-02 17:23:47,261 INFO  fetcher.FetcherThread - FetcherThread 48 fetching https://www.apple.com/nz/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:47,645 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=77, fetchQueues.getQueueCount=1
2020-05-02 17:23:48,162 INFO  fetcher.FetcherThread - FetcherThread 65 fetching https://www.apple.com/md/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:48,646 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=76, fetchQueues.getQueueCount=1
2020-05-02 17:23:49,491 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/sa/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:49,647 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=75, fetchQueues.getQueueCount=1
2020-05-02 17:23:49,744 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/qa/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:23:50,649 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=74, fetchQueues.getQueueCount=1
2020-05-02 17:23:50,731 INFO  fetcher.FetcherThread - FetcherThread 55 fetching https://www.apple.com/chfr/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:14,106 INFO  util.SitemapProcessor - SitemapProcessor: sitemap urls dir: urls
2020-05-02 17:25:14,106 INFO  util.SitemapProcessor - SitemapProcessor: threads: 50
2020-05-02 17:25:14,107 INFO  util.SitemapProcessor - SitemapProcessor: Starting at 2020-05-02 17:25:14
2020-05-02 17:25:14,556 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:25:16,202 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:16,203 INFO  mapreduce.Job - Running job: job_local584430198_0001
2020-05-02 17:25:16,901 INFO  regex.RegexURLNormalizer - can't find rules for scope 'default', using default
2020-05-02 17:25:17,100 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:25:17,103 INFO  http.Http - http.proxy.host = null
2020-05-02 17:25:17,103 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:25:17,103 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:25:17,103 INFO  http.Http - http.timeout = 30000
2020-05-02 17:25:17,103 INFO  http.Http - http.content.limit = -1
2020-05-02 17:25:17,103 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:25:17,103 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:25:17,103 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:25:17,103 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:25:17,214 INFO  mapreduce.Job - Job job_local584430198_0001 running in uber mode : false
2020-05-02 17:25:17,215 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:25:18,053 INFO  util.SitemapProcessor - Parsing sitemap file: https://www.apple.com/sitemap.xml
2020-05-02 17:25:19,221 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:25:19,221 INFO  mapreduce.Job - Job job_local584430198_0001 completed successfully
2020-05-02 17:25:19,242 INFO  mapreduce.Job - Counters: 33
	File System Counters
		FILE: Number of bytes read=2839050
		FILE: Number of bytes written=4526704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=135
		Map output records=137
		Map output bytes=10083
		Map output materialized bytes=10371
		Input split bytes=614
		Combine input records=0
		Combine output records=0
		Reduce input groups=135
		Reduce shuffle bytes=10371
		Reduce input records=137
		Reduce output records=135
		Spilled Records=274
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=93
		Total committed heap usage (bytes)=785907712
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	Sitemap
		existing_sitemap_entries=134
		new_sitemap_entries=1
		sitemap_seeds=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=11569
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total records rejected by filters: 0
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from host name: 0
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total sitemaps from seed urls: 1
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total failed sitemap fetches: 0
2020-05-02 17:25:19,264 INFO  util.SitemapProcessor - SitemapProcessor: Total new sitemap entries added: 1
2020-05-02 17:25:19,265 INFO  util.SitemapProcessor - SitemapProcessor: Finished at 2020-05-02 17:25:19, elapsed: 00:00:05
2020-05-02 17:25:20,496 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:25:20,934 INFO  crawl.Generator - Generator: starting at 2020-05-02 17:25:20
2020-05-02 17:25:20,934 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 17:25:20,934 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 17:25:20,935 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 17:25:20,940 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 17:25:21,806 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:21,807 INFO  mapreduce.Job - Running job: job_local432465634_0001
2020-05-02 17:25:22,298 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:25:22,299 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:25:22,299 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:25:22,306 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 17:25:22,550 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:25:22,665 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:25:22,824 INFO  mapreduce.Job - Job job_local432465634_0001 running in uber mode : false
2020-05-02 17:25:22,825 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:25:22,826 INFO  mapreduce.Job - Job job_local432465634_0001 completed successfully
2020-05-02 17:25:22,845 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2819496
		FILE: Number of bytes written=4518468
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=135
		Map output records=133
		Map output bytes=13348
		Map output materialized bytes=903
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=903
		Reduce input records=133
		Reduce output records=0
		Spilled Records=266
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=805306368
	Generator
		SCHEDULE_REJECTED=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11309
	File Output Format Counters 
		Bytes Written=16
2020-05-02 17:25:22,845 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 17:25:22,850 INFO  crawl.Generator - Generator:      2  SCHEDULE_REJECTED
2020-05-02 17:25:22,851 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 17:25:23,855 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502172523
2020-05-02 17:25:24,142 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:24,143 INFO  mapreduce.Job - Running job: job_local600580253_0002
2020-05-02 17:25:25,148 INFO  mapreduce.Job - Job job_local600580253_0002 running in uber mode : false
2020-05-02 17:25:25,148 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:25:25,149 INFO  mapreduce.Job - Job job_local600580253_0002 completed successfully
2020-05-02 17:25:25,154 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5652179
		FILE: Number of bytes written=9031778
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=133
		Map output records=133
		Map output bytes=18450
		Map output materialized bytes=1371
		Input split bytes=366
		Combine input records=0
		Combine output records=0
		Reduce input groups=133
		Reduce shuffle bytes=1371
		Reduce input records=133
		Reduce output records=133
		Spilled Records=266
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1332215808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14884
	File Output Format Counters 
		Bytes Written=13670
2020-05-02 17:25:25,239 INFO  crawl.Generator - Generator: finished at 2020-05-02 17:25:25, elapsed: 00:00:04
2020-05-02 17:25:26,298 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 17:25:26
2020-05-02 17:25:26,299 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502172523
2020-05-02 17:25:26,299 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588425926299  (2020-05-02 20:25:26)
2020-05-02 17:25:26,571 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:25:27,795 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:25:27,796 INFO  mapreduce.Job - Running job: job_local1940515069_0001
2020-05-02 17:25:27,978 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 17:25:27,978 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 17:25:27,979 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 17:25:28,014 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 133 records hit by time limit : 0
2020-05-02 17:25:28,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,301 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,302 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,302 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com.cn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:28,546 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:25:28,548 INFO  http.Http - http.proxy.host = null
2020-05-02 17:25:28,548 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:25:28,548 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:25:28,548 INFO  http.Http - http.timeout = 30000
2020-05-02 17:25:28,548 INFO  http.Http - http.content.limit = -1
2020-05-02 17:25:28,548 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:25:28,548 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:25:28,548 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:25:28,548 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:25:28,556 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,561 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/ie/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:28,564 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,565 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,580 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,592 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,593 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,711 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,712 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,712 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,713 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,714 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,714 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,715 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,716 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,716 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,717 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,717 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,718 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,719 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,719 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,720 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,720 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,721 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,722 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,722 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,723 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,724 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,725 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,726 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,726 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,727 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,727 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,727 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,732 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,732 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,733 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,734 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,735 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,736 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,736 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,737 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,738 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,738 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,739 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,739 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,740 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,740 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,740 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,741 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,742 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,743 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,744 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,744 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,745 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,746 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,746 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,747 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,748 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,749 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,749 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,750 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,750 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,752 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,753 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,754 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,754 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,755 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,755 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,756 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,756 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,757 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,757 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,758 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,759 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,760 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,760 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,761 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,767 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,770 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,776 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,776 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,777 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,778 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,779 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,780 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,780 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,782 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,784 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,787 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,787 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,788 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,789 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,789 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,790 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,790 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,791 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:25:28,792 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:25:28,792 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 17:25:28,792 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 17:25:28,792 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 17:25:28,801 INFO  mapreduce.Job - Job job_local1940515069_0001 running in uber mode : false
2020-05-02 17:25:28,802 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:25:29,470 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/li/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:29,728 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/th/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:29,793 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=129, fetchQueues.getQueueCount=1
2020-05-02 17:25:30,033 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/ca/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:30,295 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/mk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:30,543 INFO  fetcher.FetcherThread - FetcherThread 85 fetching https://www.apple.com/au/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:30,794 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=126, fetchQueues.getQueueCount=1
2020-05-02 17:25:30,976 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ee/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:31,248 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/de/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:31,586 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/eg-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:31,794 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=123, fetchQueues.getQueueCount=1
2020-05-02 17:25:32,006 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/hk/en/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:32,230 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/ph/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:32,795 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=121, fetchQueues.getQueueCount=1
2020-05-02 17:25:33,009 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/kw-ar/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:33,271 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/vn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:33,602 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/eg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:33,797 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=118, fetchQueues.getQueueCount=1
2020-05-02 17:25:34,024 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/mo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:34,279 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/fi/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:34,728 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/hk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:34,802 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=115, fetchQueues.getQueueCount=1
2020-05-02 17:25:34,986 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/ae-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:35,262 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/ae/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:35,544 INFO  fetcher.FetcherThread - FetcherThread 63 fetching https://www.apple.com/id/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:35,805 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=112, fetchQueues.getQueueCount=1
2020-05-02 17:25:36,519 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/jo-ar/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:36,804 INFO  fetcher.FetcherThread - FetcherThread 79 fetching https://www.apple.com/bg/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:25:36,808 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=110, fetchQueues.getQueueCount=1
2020-05-02 17:25:37,234 INFO  fetcher.FetcherThread - FetcherThread 44 fetching https://www.apple.com/jo/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:36,747 INFO  crawl.Injector - Injector: starting at 2020-05-02 17:38:36
2020-05-02 17:38:36,752 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 17:38:36,757 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 17:38:36,762 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 17:38:37,021 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:37,629 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 17:38:38,651 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:38,655 INFO  mapreduce.Job - Running job: job_local1501587315_0001
2020-05-02 17:38:39,370 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 17:38:39,640 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 17:38:39,640 INFO  crawl.Injector - Injector: update: false
2020-05-02 17:38:39,666 INFO  mapreduce.Job - Job job_local1501587315_0001 running in uber mode : false
2020-05-02 17:38:39,668 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:39,669 INFO  mapreduce.Job - Job job_local1501587315_0001 completed successfully
2020-05-02 17:38:39,689 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855710
		FILE: Number of bytes written=2988567
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=276
		Map output materialized bytes=290
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=290
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=4
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=653
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 4
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 17:38:39,706 INFO  crawl.Injector - Injector: Total new urls injected: 4
2020-05-02 17:38:39,736 INFO  crawl.Injector - Injector: finished at 2020-05-02 17:38:39, elapsed: 00:00:02
2020-05-02 17:38:41,186 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: starting at 2020-05-02 17:38:41
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 17:38:41,690 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 17:38:41,692 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 17:38:44,280 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:44,281 INFO  mapreduce.Job - Running job: job_local616860332_0001
2020-05-02 17:38:45,225 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:38:45,227 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:38:45,227 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:38:45,242 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 17:38:45,291 INFO  mapreduce.Job - Job job_local616860332_0001 running in uber mode : false
2020-05-02 17:38:45,293 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:38:45,654 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 17:38:46,298 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:46,299 INFO  mapreduce.Job - Job job_local616860332_0001 completed successfully
2020-05-02 17:38:46,351 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783711
		FILE: Number of bytes written=4486263
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=392
		Map output materialized bytes=134
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=739770368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=406
	File Output Format Counters 
		Bytes Written=16
2020-05-02 17:38:46,352 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 17:38:46,358 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 17:38:47,360 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502173847
2020-05-02 17:38:47,775 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:47,777 INFO  mapreduce.Job - Running job: job_local2116062707_0002
2020-05-02 17:38:48,777 INFO  mapreduce.Job - Job job_local2116062707_0002 running in uber mode : false
2020-05-02 17:38:48,778 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:48,778 INFO  mapreduce.Job - Job job_local2116062707_0002 completed successfully
2020-05-02 17:38:48,782 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3712126
		FILE: Number of bytes written=5982713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=536
		Map output materialized bytes=133
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=133
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=752877568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=548
	File Output Format Counters 
		Bytes Written=490
2020-05-02 17:38:48,805 INFO  crawl.Generator - Generator: finished at 2020-05-02 17:38:48, elapsed: 00:00:07
2020-05-02 17:38:50,069 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 17:38:50
2020-05-02 17:38:50,070 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502173847
2020-05-02 17:38:50,070 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588426730070  (2020-05-02 20:38:50)
2020-05-02 17:38:50,332 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:51,545 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:51,546 INFO  mapreduce.Job - Running job: job_local1926215383_0001
2020-05-02 17:38:51,758 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 17:38:51,759 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 17:38:51,759 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 17:38:51,769 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 4 records hit by time limit : 0
2020-05-02 17:38:52,095 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,116 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,117 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,117 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:52,329 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 17:38:52,330 INFO  http.Http - http.proxy.host = null
2020-05-02 17:38:52,331 INFO  http.Http - http.proxy.port = 8080
2020-05-02 17:38:52,331 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 17:38:52,331 INFO  http.Http - http.timeout = 30000
2020-05-02 17:38:52,331 INFO  http.Http - http.content.limit = -1
2020-05-02 17:38:52,331 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 17:38:52,331 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 17:38:52,331 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 17:38:52,331 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 17:38:52,332 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,334 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,335 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,335 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,336 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,337 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,337 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,338 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,338 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,339 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,340 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,346 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,347 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,349 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,359 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,359 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,363 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,364 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,365 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,365 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,366 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,379 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,380 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,382 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,389 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,389 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,390 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,398 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,399 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,399 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,400 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,405 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,405 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,406 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,407 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,409 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,414 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,415 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,416 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,417 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,417 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,422 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,422 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,423 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,424 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,425 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,430 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,431 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,432 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,433 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,533 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,534 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,534 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,535 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,536 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,536 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,537 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,552 INFO  mapreduce.Job - Job job_local1926215383_0001 running in uber mode : false
2020-05-02 17:38:52,554 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:38:52,557 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,558 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,562 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,564 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,565 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,568 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,568 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,569 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,573 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,574 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,580 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,581 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,582 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,585 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,585 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,586 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,587 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,589 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,591 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,596 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,597 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,597 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,598 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,598 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,599 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,600 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,601 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,602 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,609 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,610 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,613 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,614 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,615 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,624 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,631 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,633 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,634 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,638 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,638 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:38:52,639 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 17:38:52,639 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 17:38:52,640 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 17:38:52,640 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 17:38:53,364 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:53,643 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-02 17:38:53,643 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588415933362
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   now           = 1588415933644
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:38:53,644 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 17:38:54,084 INFO  fetcher.FetcherThread - FetcherThread 72 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:54,347 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 17:38:54,347 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=48
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=47
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 17:38:54,349 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 17:38:54,349 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=46
2020-05-02 17:38:54,348 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 17:38:54,349 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=45
2020-05-02 17:38:54,354 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 17:38:54,354 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 17:38:54,354 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 17:38:54,355 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=43
2020-05-02 17:38:54,365 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 17:38:54,366 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=42
2020-05-02 17:38:54,369 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 17:38:54,369 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 17:38:54,369 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=41
2020-05-02 17:38:54,370 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=40
2020-05-02 17:38:54,385 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 17:38:54,386 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=39
2020-05-02 17:38:54,387 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 17:38:54,387 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=38
2020-05-02 17:38:54,397 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 17:38:54,398 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=37
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=36
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 17:38:54,406 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=35
2020-05-02 17:38:54,411 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 17:38:54,411 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=34
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=33
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 17:38:54,412 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=32
2020-05-02 17:38:54,419 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 17:38:54,420 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=31
2020-05-02 17:38:54,419 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 17:38:54,420 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=30
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=29
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=28
2020-05-02 17:38:54,433 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 17:38:54,434 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=27
2020-05-02 17:38:54,438 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 17:38:54,438 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=26
2020-05-02 17:38:54,446 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 17:38:54,446 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=25
2020-05-02 17:38:54,534 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 17:38:54,535 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=23
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 17:38:54,546 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=22
2020-05-02 17:38:54,563 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 17:38:54,563 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=21
2020-05-02 17:38:54,574 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 17:38:54,575 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=20
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=19
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 17:38:54,581 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=17
2020-05-02 17:38:54,580 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=18
2020-05-02 17:38:54,586 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 17:38:54,586 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=16
2020-05-02 17:38:54,596 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 17:38:54,596 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=15
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=13
2020-05-02 17:38:54,600 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=14
2020-05-02 17:38:54,603 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 17:38:54,603 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=12
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=11
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=10
2020-05-02 17:38:54,607 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 17:38:54,608 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=9
2020-05-02 17:38:54,612 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 17:38:54,612 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=8
2020-05-02 17:38:54,615 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 17:38:54,616 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=7
2020-05-02 17:38:54,623 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 17:38:54,623 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=6
2020-05-02 17:38:54,629 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 17:38:54,630 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=5
2020-05-02 17:38:54,636 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 17:38:54,636 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=4
2020-05-02 17:38:54,642 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 17:38:54,642 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=3
2020-05-02 17:38:54,650 INFO  fetcher.Fetcher - -activeThreads=3, spinWaiting=3, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 17:38:54,651 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 17:38:54,651 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=2
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=1
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 17:38:54,652 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=0
2020-05-02 17:38:55,653 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 17:38:55,653 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 17:38:56,565 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:38:56,566 INFO  mapreduce.Job - Job job_local1926215383_0001 completed successfully
2020-05-02 17:38:56,583 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2945161
		FILE: Number of bytes written=4865953
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=8
		Map output bytes=461890
		Map output materialized bytes=76759
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=76759
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=100
		Total committed heap usage (bytes)=967311360
	FetcherStatus
		bytes_downloaded=457983
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=490
	File Output Format Counters 
		Bytes Written=80314
2020-05-02 17:38:56,583 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 17:38:56, elapsed: 00:00:06
2020-05-02 17:38:57,754 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:38:58,177 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:38:58
2020-05-02 17:38:58,177 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:38:59,130 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:38:59,132 INFO  mapreduce.Job - Running job: job_local493069373_0001
2020-05-02 17:39:00,141 INFO  mapreduce.Job - Job job_local493069373_0001 running in uber mode : false
2020-05-02 17:39:00,142 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:39:00,345 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:39:00,594 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,597 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:39:00,610 INFO  parse.ParseSegment - Parsed (992ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:39:00,687 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,688 INFO  parse.ParseSegment - Parsed (64ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:39:00,745 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,746 INFO  parse.ParseSegment - Parsed (54ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:39:00,804 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:39:00,805 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:39:01,021 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:39:01,144 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 17:39:01,155 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:39:01,255 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:39:02,145 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:02,146 INFO  mapreduce.Job - Job job_local493069373_0001 completed successfully
2020-05-02 17:39:02,165 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4113920
		FILE: Number of bytes written=6218941
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=40460
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=40460
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=1597505536
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:39:02,180 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:39:02, elapsed: 00:00:03
2020-05-02 17:39:03,292 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:03,714 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 17:39:03
2020-05-02 17:39:03,714 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 17:39:03,714 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502173847]
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 17:39:03,715 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 17:39:03,720 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 17:39:04,669 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:04,670 INFO  mapreduce.Job - Running job: job_local1849642166_0001
2020-05-02 17:39:05,690 INFO  mapreduce.Job - Job job_local1849642166_0001 running in uber mode : false
2020-05-02 17:39:05,693 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:39:05,981 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:39:05,982 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:39:05,982 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:39:06,059 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 17:39:06,059 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 17:39:06,059 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 17:39:06,694 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:06,694 INFO  mapreduce.Job - Job job_local1849642166_0001 completed successfully
2020-05-02 17:39:06,722 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=6617375
		FILE: Number of bytes written=10466046
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=188
		Map output records=188
		Map output bytes=13684
		Map output materialized bytes=930
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=930
		Reduce input records=188
		Reduce output records=4
		Spilled Records=376
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=15223
	File Output Format Counters 
		Bytes Written=1540
2020-05-02 17:39:06,754 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 17:39:06, elapsed: 00:00:03
2020-05-02 17:39:08,180 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:08,566 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 17:39:08
2020-05-02 17:39:08,586 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 17:39:08,587 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 17:39:08,598 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 17:39:08,598 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 17:39:08,598 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502173847
2020-05-02 17:39:09,630 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:09,631 INFO  mapreduce.Job - Running job: job_local1848288729_0001
2020-05-02 17:39:10,147 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 17:39:10,642 INFO  mapreduce.Job - Job job_local1848288729_0001 running in uber mode : false
2020-05-02 17:39:10,643 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:10,644 INFO  mapreduce.Job - Job job_local1848288729_0001 completed successfully
2020-05-02 17:39:10,659 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2794787
		FILE: Number of bytes written=4483024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3926
	File Output Format Counters 
		Bytes Written=279
2020-05-02 17:39:10,676 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 17:39:10, elapsed: 00:00:02
2020-05-02 17:39:11,746 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 17:39:11
2020-05-02 17:39:12,037 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:13,405 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:13,405 INFO  mapreduce.Job - Running job: job_local1609343073_0001
2020-05-02 17:39:14,411 INFO  mapreduce.Job - Job job_local1609343073_0001 running in uber mode : false
2020-05-02 17:39:14,412 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:14,413 INFO  mapreduce.Job - Job job_local1609343073_0001 completed successfully
2020-05-02 17:39:14,429 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2788450
		FILE: Number of bytes written=4488534
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1056
		Map output materialized bytes=1080
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1080
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1152
	File Output Format Counters 
		Bytes Written=98
2020-05-02 17:39:14,435 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 17:39:14,435 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 17:39:14,756 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:14,756 INFO  mapreduce.Job - Running job: job_local653361765_0002
2020-05-02 17:39:15,757 INFO  mapreduce.Job - Job job_local653361765_0002 running in uber mode : false
2020-05-02 17:39:15,757 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:15,758 INFO  mapreduce.Job - Job job_local653361765_0002 completed successfully
2020-05-02 17:39:15,761 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7443762
		FILE: Number of bytes written=11956225
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=916
		Map output materialized bytes=946
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=946
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1250
	File Output Format Counters 
		Bytes Written=1301
2020-05-02 17:39:15,779 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 17:39:15, elapsed: 00:00:04
2020-05-02 17:39:16,942 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:17,429 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:39:17,434 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:39:17
2020-05-02 17:39:17,476 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 17:39:17,477 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 17:39:17,477 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 17:39:17,480 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:39:17,480 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:39:17,481 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:39:18,750 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:18,753 INFO  mapreduce.Job - Running job: job_local620731998_0001
2020-05-02 17:39:19,941 INFO  mapreduce.Job - Job job_local620731998_0001 running in uber mode : false
2020-05-02 17:39:19,943 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:39:20,757 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:39:20,798 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:39:21,177 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 17:39:21,777 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 40; cvc-id.2: There are multiple occurrences of ID value 'Capacity'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:39:21,787 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,800 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,801 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,803 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:39:21,804 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:39:21,804 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:39:22,950 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:22,951 INFO  mapreduce.Job - Job job_local620731998_0001 completed successfully
2020-05-02 17:39:22,980 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=11078440
		FILE: Number of bytes written=17739177
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=196
		Map output records=196
		Map output bytes=111275
		Map output materialized bytes=111751
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=111751
		Reduce input records=196
		Reduce output records=4
		Spilled Records=392
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=310
		Total committed heap usage (bytes)=4910481408
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=54507
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:39:22,981 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:39:22,993 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:39:23,021 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:39:22, elapsed: 00:00:05
2020-05-02 17:39:24,243 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 17:39:24
2020-05-02 17:39:24,471 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:39:25,644 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:39:25,644 INFO  mapreduce.Job - Running job: job_local397672846_0001
2020-05-02 17:39:26,214 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:39:26,240 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:39:26,650 INFO  mapreduce.Job - Job job_local397672846_0001 running in uber mode : false
2020-05-02 17:39:26,651 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:39:26,666 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 17:39:27,654 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:39:27,655 INFO  mapreduce.Job - Job job_local397672846_0001 completed successfully
2020-05-02 17:39:27,675 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1856662
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=92
		Total committed heap usage (bytes)=481296384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1054
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:39:27,697 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 17:39:27, elapsed: 00:00:03
2020-05-02 17:41:48,137 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:41:48,559 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:41:48
2020-05-02 17:41:48,559 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:41:50,452 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:41:50,453 INFO  mapreduce.Job - Running job: job_local225455475_0001
2020-05-02 17:41:51,461 INFO  mapreduce.Job - Job job_local225455475_0001 running in uber mode : false
2020-05-02 17:41:51,462 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:41:51,785 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:41:52,198 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,204 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:41:52,214 INFO  parse.ParseSegment - Parsed (1184ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:41:52,321 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,323 INFO  parse.ParseSegment - Parsed (97ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:41:52,415 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,416 INFO  parse.ParseSegment - Parsed (90ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:41:52,522 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:41:52,523 INFO  parse.ParseSegment - Parsed (104ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:41:52,766 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:41:52,879 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:41:53,465 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:41:53,466 INFO  mapreduce.Job - Job job_local225455475_0001 completed successfully
2020-05-02 17:41:53,482 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5097210
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=90
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:41:53,498 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:41:53, elapsed: 00:00:04
2020-05-02 17:41:54,661 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:41:55,045 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:41:55,048 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:41:55
2020-05-02 17:41:55,059 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:41:55,059 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:41:55,061 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:41:55,064 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:41:55,064 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:41:55,064 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:41:56,003 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:41:56,004 INFO  mapreduce.Job - Running job: job_local2037565605_0001
2020-05-02 17:41:56,520 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:56,631 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:56,836 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,017 INFO  mapreduce.Job - Job job_local2037565605_0001 running in uber mode : false
2020-05-02 17:41:57,019 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:41:57,032 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,208 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,444 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,512 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:41:57,731 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:41:57,768 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:41:58,348 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 17:41:59,133 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 11; columnNumber: 38; cvc-id.2: There are multiple occurrences of ID value 'Weight'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:41:59,145 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,155 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,158 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,163 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:41:59,163 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:41:59,163 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:42:00,032 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:42:00,033 INFO  mapreduce.Job - Job job_local2037565605_0001 completed successfully
2020-05-02 17:42:00,073 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578437
		FILE: Number of bytes written=17057137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=191
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92299
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:42:00,073 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:42:00,081 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:42:00,114 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:42:00, elapsed: 00:00:05
2020-05-02 17:44:15,569 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:44:15,887 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:44:15
2020-05-02 17:44:15,895 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:44:17,077 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:44:17,081 INFO  mapreduce.Job - Running job: job_local1461421952_0001
2020-05-02 17:44:18,106 INFO  mapreduce.Job - Job job_local1461421952_0001 running in uber mode : false
2020-05-02 17:44:18,108 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:44:18,770 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:44:19,125 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,132 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:44:19,144 INFO  parse.ParseSegment - Parsed (1117ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:44:19,222 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,223 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:44:19,295 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,296 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:44:19,377 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:44:19,378 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:44:19,623 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:44:19,743 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:44:20,114 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:44:20,115 INFO  mapreduce.Job - Job job_local1461421952_0001 completed successfully
2020-05-02 17:44:20,143 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105381
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:44:20,162 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:44:20, elapsed: 00:00:04
2020-05-02 17:44:21,322 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:44:21,702 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:44:21,706 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:44:21
2020-05-02 17:44:21,722 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:44:21,722 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:44:21,722 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:44:21,723 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:44:21,724 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:44:21,729 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:44:22,826 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:44:22,827 INFO  mapreduce.Job - Running job: job_local169790368_0001
2020-05-02 17:44:23,598 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:23,825 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:23,834 INFO  mapreduce.Job - Job job_local169790368_0001 running in uber mode : false
2020-05-02 17:44:23,835 INFO  mapreduce.Job -  map 11% reduce 0%
2020-05-02 17:44:23,935 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,104 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,291 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,441 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,507 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:44:24,720 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:44:24,756 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:44:24,964 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:44:25,282 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 17:44:25,827 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 12; columnNumber: 65; cvc-datatype-valid.1.2.1: 'Splash, Water, and Dust Resistant' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:44:25,837 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,846 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,849 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,853 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:44:25,853 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:44:25,854 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:44:26,971 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:44:26,972 INFO  mapreduce.Job - Job job_local169790368_0001 completed successfully
2020-05-02 17:44:27,011 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578429
		FILE: Number of bytes written=17029817
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=176
		Total committed heap usage (bytes)=6195511296
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92298
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:44:27,011 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:44:27,019 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:44:27,042 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:44:27, elapsed: 00:00:05
2020-05-02 17:45:30,008 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:45:30,469 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:45:30
2020-05-02 17:45:30,470 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:45:31,790 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:45:31,794 INFO  mapreduce.Job - Running job: job_local882011035_0001
2020-05-02 17:45:32,809 INFO  mapreduce.Job - Job job_local882011035_0001 running in uber mode : false
2020-05-02 17:45:32,809 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:45:32,981 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:45:33,222 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,226 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:45:33,236 INFO  parse.ParseSegment - Parsed (833ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:45:33,316 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,317 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:45:33,368 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,369 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:45:33,417 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:45:33,418 INFO  parse.ParseSegment - Parsed (46ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:45:33,616 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:45:33,722 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:45:33,813 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:45:34,815 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:45:34,815 INFO  mapreduce.Job - Job job_local882011035_0001 completed successfully
2020-05-02 17:45:34,831 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5097214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=1165492224
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:45:34,844 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:45:34, elapsed: 00:00:04
2020-05-02 17:45:35,847 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:45:36,219 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:45:36,222 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:45:36
2020-05-02 17:45:36,244 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:45:36,244 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:45:36,244 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:45:36,247 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:45:36,247 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:45:36,247 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:45:37,137 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:45:37,138 INFO  mapreduce.Job - Running job: job_local130649158_0001
2020-05-02 17:45:37,588 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:37,683 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:37,778 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:37,960 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,032 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,134 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,144 INFO  mapreduce.Job - Job job_local130649158_0001 running in uber mode : false
2020-05-02 17:45:38,145 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:45:38,202 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:45:38,381 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:45:38,410 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:45:38,789 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 17:45:39,384 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 13; columnNumber: 47; cvc-datatype-valid.1.2.1: 'Video Recording' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:45:39,470 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,480 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,483 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,488 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:45:39,489 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:45:39,490 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:45:40,155 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:45:40,156 INFO  mapreduce.Job - Job job_local130649158_0001 completed successfully
2020-05-02 17:45:40,184 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578469
		FILE: Number of bytes written=17029817
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=168
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92303
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:45:40,185 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:45:40,193 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:45:40,213 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:45:40, elapsed: 00:00:03
2020-05-02 17:56:16,626 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:56:17,028 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:56:17
2020-05-02 17:56:17,028 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:56:18,017 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:56:18,018 INFO  mapreduce.Job - Running job: job_local1686074360_0001
2020-05-02 17:56:19,026 INFO  mapreduce.Job - Job job_local1686074360_0001 running in uber mode : false
2020-05-02 17:56:19,027 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:56:19,068 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:56:19,303 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,307 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:56:19,315 INFO  parse.ParseSegment - Parsed (846ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:56:19,395 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,396 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:56:19,504 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,505 INFO  parse.ParseSegment - Parsed (105ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:56:19,576 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:56:19,577 INFO  parse.ParseSegment - Parsed (69ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:56:19,803 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:56:19,938 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:56:20,034 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:56:21,036 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:56:21,036 INFO  mapreduce.Job - Job job_local1686074360_0001 completed successfully
2020-05-02 17:56:21,054 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105386
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=68
		Total committed heap usage (bytes)=1171783680
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:56:21,074 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:56:21, elapsed: 00:00:04
2020-05-02 17:56:22,342 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:56:22,753 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:56:22,756 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:56:22
2020-05-02 17:56:22,782 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:56:22,782 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:56:22,784 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:56:22,785 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:56:22,785 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:56:22,785 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:56:23,872 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:56:23,873 INFO  mapreduce.Job - Running job: job_local433490765_0001
2020-05-02 17:56:24,443 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:24,673 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:24,763 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:24,879 INFO  mapreduce.Job - Job job_local433490765_0001 running in uber mode : false
2020-05-02 17:56:24,880 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:56:24,908 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,060 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,278 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,456 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:56:25,803 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:56:25,843 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:56:26,374 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 17:56:26,943 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:56:26,954 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,964 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,966 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,969 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:56:26,970 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:56:26,970 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:56:27,887 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:56:27,889 INFO  mapreduce.Job - Job job_local433490765_0001 completed successfully
2020-05-02 17:56:27,939 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578469
		FILE: Number of bytes written=17029797
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=211
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92303
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:56:27,939 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:56:27,947 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:56:28,015 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:56:27, elapsed: 00:00:05
2020-05-02 17:57:37,134 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:57:37,693 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 17:57:37
2020-05-02 17:57:37,694 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 17:57:38,642 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:57:38,643 INFO  mapreduce.Job - Running job: job_local1379892038_0001
2020-05-02 17:57:39,651 INFO  mapreduce.Job - Job job_local1379892038_0001 running in uber mode : false
2020-05-02 17:57:39,652 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 17:57:39,733 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 17:57:39,972 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:39,976 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 17:57:39,984 INFO  parse.ParseSegment - Parsed (853ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 17:57:40,059 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:40,059 INFO  parse.ParseSegment - Parsed (50ms):https://www.apple.com/iphone-11/specs/
2020-05-02 17:57:40,135 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:40,136 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/iphone-se/specs/
2020-05-02 17:57:40,191 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 17:57:40,192 INFO  parse.ParseSegment - Parsed (54ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 17:57:40,384 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 17:57:40,521 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 17:57:40,657 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:57:41,661 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:57:41,662 INFO  mapreduce.Job - Job job_local1379892038_0001 completed successfully
2020-05-02 17:57:41,677 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:57:41,689 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 17:57:41, elapsed: 00:00:03
2020-05-02 17:57:42,771 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 17:57:43,168 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 17:57:43,171 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 17:57:43
2020-05-02 17:57:43,180 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 17:57:43,180 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 17:57:43,181 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 17:57:43,182 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 17:57:43,182 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 17:57:43,182 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 17:57:44,046 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 17:57:44,046 INFO  mapreduce.Job - Running job: job_local1270655222_0001
2020-05-02 17:57:44,788 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,055 INFO  mapreduce.Job - Job job_local1270655222_0001 running in uber mode : false
2020-05-02 17:57:45,056 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 17:57:45,095 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,278 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,631 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,782 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,913 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:45,993 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 17:57:46,309 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 17:57:46,356 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 17:57:46,799 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 17:57:47,416 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 3; columnNumber: 218; cvc-complex-type.3.2.2: Attribute 'xsi:schemalocation' is not allowed to appear in element 'config'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 17:57:47,428 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,436 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,438 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,445 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 17:57:47,445 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 17:57:47,466 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 17:57:48,071 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 17:57:48,072 INFO  mapreduce.Job - Job job_local1270655222_0001 completed successfully
2020-05-02 17:57:48,101 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578437
		FILE: Number of bytes written=17057137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=184
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92299
	File Output Format Counters 
		Bytes Written=0
2020-05-02 17:57:48,101 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 17:57:48,115 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 17:57:48,137 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 17:57:48, elapsed: 00:00:04
2020-05-02 18:00:51,106 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:00:51,452 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:00:51
2020-05-02 18:00:51,452 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:00:52,585 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:00:52,585 INFO  mapreduce.Job - Running job: job_local1265210216_0001
2020-05-02 18:00:53,593 INFO  mapreduce.Job - Job job_local1265210216_0001 running in uber mode : false
2020-05-02 18:00:53,594 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:00:53,785 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 18:00:54,128 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,132 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:00:54,142 INFO  parse.ParseSegment - Parsed (1028ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:00:54,222 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,223 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:00:54,355 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,356 INFO  parse.ParseSegment - Parsed (129ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:00:54,405 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:00:54,406 INFO  parse.ParseSegment - Parsed (45ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:00:54,600 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:00:54,602 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:00:54,727 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:00:55,603 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:00:55,603 INFO  mapreduce.Job - Job job_local1265210216_0001 completed successfully
2020-05-02 18:00:55,623 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5105382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=74
		Total committed heap usage (bytes)=1167065088
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:00:55,636 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:00:55, elapsed: 00:00:04
2020-05-02 18:00:56,706 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:00:57,152 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:00:57,155 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:00:57
2020-05-02 18:00:57,170 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:00:57,171 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:00:57,171 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:00:57,172 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:00:57,174 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:00:57,174 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:00:58,349 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:00:58,350 INFO  mapreduce.Job - Running job: job_local881184524_0001
2020-05-02 18:00:58,851 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,045 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,295 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,358 INFO  mapreduce.Job - Job job_local881184524_0001 running in uber mode : false
2020-05-02 18:00:59,360 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:00:59,528 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,665 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,880 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:00:59,938 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:00,154 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:01:00,185 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:01:00,673 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:01:01,333 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 18:01:01,372 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,386 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,388 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,392 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 18:01:01,393 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:01:01,393 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:01:02,403 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:01:02,405 INFO  mapreduce.Job - Job job_local881184524_0001 completed successfully
2020-05-02 18:01:02,434 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10578437
		FILE: Number of bytes written=17029777
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=208038
		Map output materialized bytes=208540
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=208540
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=198
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92299
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:01:02,434 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:01:02,448 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:01:02,504 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:01:02, elapsed: 00:00:05
2020-05-02 18:01:43,520 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:01:43,881 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:01:43
2020-05-02 18:01:43,881 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:01:44,734 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:01:44,735 INFO  mapreduce.Job - Running job: job_local42893344_0001
2020-05-02 18:01:45,743 INFO  mapreduce.Job - Job job_local42893344_0001 running in uber mode : false
2020-05-02 18:01:45,744 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:01:45,779 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 26; columnNumber: 64; cvc-datatype-valid.1.2.1: 'external-buttons -and-connectors' is not a valid value for 'NCName'.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processOneAttribute(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.processAttributes(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 18:01:46,012 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,016 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:01:46,024 INFO  parse.ParseSegment - Parsed (824ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:01:46,118 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,119 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:01:46,181 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,182 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:01:46,223 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 18:01:46,224 INFO  parse.ParseSegment - Parsed (40ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:01:46,448 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:01:46,578 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:01:46,750 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:01:47,755 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:01:47,756 INFO  mapreduce.Job - Job job_local42893344_0001 completed successfully
2020-05-02 18:01:47,770 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3304672
		FILE: Number of bytes written=5089042
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=143177
		Map output materialized bytes=143205
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=143205
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:01:47,786 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:01:47, elapsed: 00:00:03
2020-05-02 18:01:49,081 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:01:49,563 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:01:49,566 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:01:49
2020-05-02 18:01:49,587 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:01:49,594 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:01:49,594 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:01:49,595 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:01:49,595 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:01:49,596 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:01:50,741 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:01:50,742 INFO  mapreduce.Job - Running job: job_local698639243_0001
2020-05-02 18:01:51,355 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,517 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,684 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,754 INFO  mapreduce.Job - Job job_local698639243_0001 running in uber mode : false
2020-05-02 18:01:51,755 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:01:51,824 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:51,911 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:52,021 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:52,107 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:01:52,293 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:01:52,324 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:01:54,706 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:01:55,123 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:01:55
2020-05-02 18:01:55,124 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:01:56,083 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:01:56,084 INFO  mapreduce.Job - Running job: job_local1567022607_0001
2020-05-02 18:01:57,152 INFO  mapreduce.Job - Job job_local1567022607_0001 running in uber mode : false
2020-05-02 18:01:57,153 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:01:57,690 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:01:57,701 INFO  parse.ParseSegment - Parsed (1088ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:01:57,840 INFO  parse.ParseSegment - Parsed (131ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:01:57,936 INFO  parse.ParseSegment - Parsed (94ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:01:58,018 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:01:58,160 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:01:58,230 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:01:58,363 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:01:59,162 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:01:59,162 INFO  mapreduce.Job - Job job_local1567022607_0001 completed successfully
2020-05-02 18:01:59,179 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3382910
		FILE: Number of bytes written=5278241
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=182296
		Map output materialized bytes=182324
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=182324
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:01:59,202 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:01:59, elapsed: 00:00:04
2020-05-02 18:02:00,325 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:02:00,689 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:02:00,691 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:02:00
2020-05-02 18:02:00,704 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:02:00,705 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:02:00,705 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:02:00,720 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:02:00,720 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:02:00,721 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:02:01,693 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:02:01,710 INFO  mapreduce.Job - Running job: job_local1334941027_0001
2020-05-02 18:02:02,311 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,489 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,567 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,645 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,764 INFO  mapreduce.Job - Job job_local1334941027_0001 running in uber mode : false
2020-05-02 18:02:02,765 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:02:02,767 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,890 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:02,949 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:02:03,160 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:02:03,184 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:02:03,616 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:02:04,260 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:02:04,261 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:02:05,775 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:02:05,777 INFO  mapreduce.Job - Job job_local1334941027_0001 completed successfully
2020-05-02 18:02:05,805 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10777958
		FILE: Number of bytes written=17409157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=247157
		Map output materialized bytes=247659
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=247659
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=176
		Total committed heap usage (bytes)=6193414144
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108682
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:02:05,806 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:02:05,814 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:02:05,837 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:02:05, elapsed: 00:00:05
2020-05-02 18:06:40,449 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:06:40,790 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:06:40
2020-05-02 18:06:40,790 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502173847
2020-05-02 18:06:41,649 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:06:41,650 INFO  mapreduce.Job - Running job: job_local414727304_0001
2020-05-02 18:06:42,655 INFO  mapreduce.Job - Job job_local414727304_0001 running in uber mode : false
2020-05-02 18:06:42,656 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:06:43,119 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:06:43,130 INFO  parse.ParseSegment - Parsed (1020ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:06:43,264 INFO  parse.ParseSegment - Parsed (121ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:06:43,360 INFO  parse.ParseSegment - Parsed (93ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:06:43,431 INFO  parse.ParseSegment - Parsed (67ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:06:43,630 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:06:43,661 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:06:43,757 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:06:44,667 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:06:44,667 INFO  mapreduce.Job - Job job_local414727304_0001 completed successfully
2020-05-02 18:06:44,684 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3382910
		FILE: Number of bytes written=5269942
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=182296
		Map output materialized bytes=182324
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=182324
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78435
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:06:44,696 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:06:44, elapsed: 00:00:03
2020-05-02 18:06:45,720 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:06:46,080 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502173847.
2020-05-02 18:06:46,083 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:06:46
2020-05-02 18:06:46,138 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:06:46,140 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:06:46,156 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:06:46,173 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:06:46,174 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:06:46,174 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502173847
2020-05-02 18:06:47,144 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:06:47,145 INFO  mapreduce.Job - Running job: job_local1459157327_0001
2020-05-02 18:06:47,657 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:47,775 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:47,916 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,010 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,134 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,155 INFO  mapreduce.Job - Job job_local1459157327_0001 running in uber mode : false
2020-05-02 18:06:48,156 INFO  mapreduce.Job -  map 44% reduce 0%
2020-05-02 18:06:48,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,271 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:06:48,470 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:06:48,490 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:06:48,966 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:06:49,162 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:06:49,678 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:06:49,681 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:06:50,165 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:06:50,167 INFO  mapreduce.Job - Job job_local1459157327_0001 completed successfully
2020-05-02 18:06:50,186 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10777069
		FILE: Number of bytes written=17409137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=247157
		Map output materialized bytes=247659
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=247659
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=188
		Total committed heap usage (bytes)=6190268416
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108555
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:06:50,186 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:06:50,203 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:06:50,245 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:06:50, elapsed: 00:00:04
2020-05-02 18:08:52,524 INFO  crawl.Injector - Injector: starting at 2020-05-02 18:08:52
2020-05-02 18:08:52,525 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 18:08:52,525 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 18:08:52,525 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 18:08:52,678 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:08:53,077 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 18:08:54,033 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:08:54,034 INFO  mapreduce.Job - Running job: job_local408452337_0001
2020-05-02 18:08:54,488 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 18:08:54,696 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 18:08:54,696 INFO  crawl.Injector - Injector: update: false
2020-05-02 18:08:55,043 INFO  mapreduce.Job - Job job_local408452337_0001 running in uber mode : false
2020-05-02 18:08:55,044 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:08:55,047 INFO  mapreduce.Job - Job job_local408452337_0001 completed successfully
2020-05-02 18:08:55,059 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1855710
		FILE: Number of bytes written=2983115
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=276
		Map output materialized bytes=290
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=290
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=4
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=653
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 4
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 18:08:55,070 INFO  crawl.Injector - Injector: Total new urls injected: 4
2020-05-02 18:08:55,093 INFO  crawl.Injector - Injector: finished at 2020-05-02 18:08:55, elapsed: 00:00:02
2020-05-02 18:08:56,173 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: starting at 2020-05-02 18:08:56
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 18:08:56,569 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 18:08:56,571 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 18:08:57,472 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:08:57,474 INFO  mapreduce.Job - Running job: job_local279751828_0001
2020-05-02 18:08:57,949 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 18:08:57,949 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 18:08:57,949 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 18:08:57,955 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 18:08:58,116 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 18:08:58,482 INFO  mapreduce.Job - Job job_local279751828_0001 running in uber mode : false
2020-05-02 18:08:58,483 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:08:58,483 INFO  mapreduce.Job - Job job_local279751828_0001 completed successfully
2020-05-02 18:08:58,497 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783711
		FILE: Number of bytes written=4486263
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=392
		Map output materialized bytes=134
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=941621248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=406
	File Output Format Counters 
		Bytes Written=16
2020-05-02 18:08:58,497 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 18:08:58,505 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 18:08:59,510 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502180859
2020-05-02 18:08:59,774 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:08:59,776 INFO  mapreduce.Job - Running job: job_local1020610565_0002
2020-05-02 18:09:00,777 INFO  mapreduce.Job - Job job_local1020610565_0002 running in uber mode : false
2020-05-02 18:09:00,777 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:00,778 INFO  mapreduce.Job - Job job_local1020610565_0002 completed successfully
2020-05-02 18:09:00,783 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3712126
		FILE: Number of bytes written=5982713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=536
		Map output materialized bytes=133
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=133
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=883949568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=548
	File Output Format Counters 
		Bytes Written=490
2020-05-02 18:09:00,802 INFO  crawl.Generator - Generator: finished at 2020-05-02 18:09:00, elapsed: 00:00:04
2020-05-02 18:09:01,824 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 18:09:01
2020-05-02 18:09:01,825 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502180859
2020-05-02 18:09:01,825 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588428541825  (2020-05-02 21:09:01)
2020-05-02 18:09:02,050 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:03,144 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:03,145 INFO  mapreduce.Job - Running job: job_local602175612_0001
2020-05-02 18:09:03,353 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 18:09:03,353 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 18:09:03,354 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 18:09:03,364 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 4 records hit by time limit : 0
2020-05-02 18:09:03,664 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,689 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,690 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,690 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:03,910 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 18:09:03,913 INFO  http.Http - http.proxy.host = null
2020-05-02 18:09:03,913 INFO  http.Http - http.proxy.port = 8080
2020-05-02 18:09:03,913 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 18:09:03,913 INFO  http.Http - http.timeout = 30000
2020-05-02 18:09:03,913 INFO  http.Http - http.content.limit = -1
2020-05-02 18:09:03,913 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 18:09:03,913 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 18:09:03,913 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 18:09:03,913 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 18:09:03,914 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,927 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,928 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,942 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,945 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,947 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,959 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,960 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,961 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,962 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,963 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,963 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,964 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,965 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,987 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,990 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,991 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,993 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,994 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,996 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:03,997 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:03,998 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,012 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,014 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,015 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,015 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,016 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,030 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,030 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,137 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,137 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,138 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,139 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,148 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,149 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,151 INFO  mapreduce.Job - Job job_local602175612_0001 running in uber mode : false
2020-05-02 18:09:04,152 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:09:04,156 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,157 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,158 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,158 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,159 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,159 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,165 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,165 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,174 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,175 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,176 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,177 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,178 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,181 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,182 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,183 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,184 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,186 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,186 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,187 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,188 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,188 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,189 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,190 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,191 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,192 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,192 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,194 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,196 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,197 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,198 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,203 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,209 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,210 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,211 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,211 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,212 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,215 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,216 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,217 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,218 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,219 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,220 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,220 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,221 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,221 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,222 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,224 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,224 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,225 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,226 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,226 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:04,228 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 18:09:04,229 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 18:09:04,231 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 18:09:04,232 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 18:09:05,240 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588417743363
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   now           = 1588417745240
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-se/specs/
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:09:05,240 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/iphone-xr/specs/
2020-05-02 18:09:05,412 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:05,712 INFO  fetcher.FetcherThread - FetcherThread 75 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:06,244 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588417745710
2020-05-02 18:09:06,244 INFO  fetcher.FetchItemQueue -   now           = 1588417746244
2020-05-02 18:09:06,245 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-02 18:09:06,945 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 18:09:06,956 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 18:09:06,956 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 18:09:06,957 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 18:09:06,957 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=48
2020-05-02 18:09:06,979 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 18:09:06,980 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=47
2020-05-02 18:09:06,980 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 18:09:06,981 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=46
2020-05-02 18:09:06,979 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 18:09:06,982 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=45
2020-05-02 18:09:06,980 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 18:09:06,982 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=44
2020-05-02 18:09:07,011 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 18:09:07,011 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=43
2020-05-02 18:09:07,012 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 18:09:07,012 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=42
2020-05-02 18:09:07,011 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 18:09:07,012 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=41
2020-05-02 18:09:07,021 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 18:09:07,021 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=40
2020-05-02 18:09:07,035 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 18:09:07,035 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=39
2020-05-02 18:09:07,035 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 18:09:07,036 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=38
2020-05-02 18:09:07,046 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 18:09:07,046 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=37
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 18:09:07,161 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=35
2020-05-02 18:09:07,165 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 18:09:07,166 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=34
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=33
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=32
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 18:09:07,179 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=31
2020-05-02 18:09:07,178 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 18:09:07,179 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=30
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=29
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=28
2020-05-02 18:09:07,196 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=27
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=25
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 18:09:07,204 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=24
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 18:09:07,204 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=23
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=26
2020-05-02 18:09:07,203 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 18:09:07,205 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=22
2020-05-02 18:09:07,212 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 18:09:07,212 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=21
2020-05-02 18:09:07,213 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=20
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=19
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=18
2020-05-02 18:09:07,214 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 18:09:07,215 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 18:09:07,215 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 18:09:07,217 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=15
2020-05-02 18:09:07,216 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=17
2020-05-02 18:09:07,215 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 18:09:07,218 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=14
2020-05-02 18:09:07,216 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=16
2020-05-02 18:09:07,228 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=13
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=12
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=11
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 18:09:07,230 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=9
2020-05-02 18:09:07,230 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=9
2020-05-02 18:09:07,228 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 18:09:07,232 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=8
2020-05-02 18:09:07,229 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 18:09:07,232 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=7
2020-05-02 18:09:07,240 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=6
2020-05-02 18:09:07,240 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=5
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=4
2020-05-02 18:09:07,240 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 18:09:07,241 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=3
2020-05-02 18:09:07,246 INFO  fetcher.Fetcher - -activeThreads=3, spinWaiting=2, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 18:09:07,248 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 18:09:07,248 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=2
2020-05-02 18:09:07,361 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 18:09:07,362 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=1
2020-05-02 18:09:07,982 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 18:09:07,982 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=0
2020-05-02 18:09:08,247 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 18:09:08,249 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 18:09:09,176 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:09,177 INFO  mapreduce.Job - Job job_local602175612_0001 completed successfully
2020-05-02 18:09:09,196 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2945141
		FILE: Number of bytes written=4857741
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=8
		Map output bytes=461890
		Map output materialized bytes=76749
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=76749
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=120
		Total committed heap usage (bytes)=968884224
	FetcherStatus
		bytes_downloaded=457983
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=490
	File Output Format Counters 
		Bytes Written=80320
2020-05-02 18:09:09,196 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 18:09:09, elapsed: 00:00:07
2020-05-02 18:09:10,248 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:10,610 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:09:10
2020-05-02 18:09:10,610 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:09:11,452 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:11,453 INFO  mapreduce.Job - Running job: job_local1616095019_0001
2020-05-02 18:09:12,463 INFO  mapreduce.Job - Job job_local1616095019_0001 running in uber mode : false
2020-05-02 18:09:12,464 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:09:12,921 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:09:12,937 INFO  parse.ParseSegment - Parsed (1034ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:09:13,086 INFO  parse.ParseSegment - Parsed (144ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:09:13,202 INFO  parse.ParseSegment - Parsed (111ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:09:13,290 INFO  parse.ParseSegment - Parsed (87ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:09:13,471 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:13,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:13,608 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:09:13,710 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:09:14,472 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:14,473 INFO  mapreduce.Job - Job job_local1616095019_0001 completed successfully
2020-05-02 18:09:14,490 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4124022
		FILE: Number of bytes written=6271345
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=182296
		Map output materialized bytes=45503
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=45503
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=1595932672
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:09:14,508 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:09:14, elapsed: 00:00:03
2020-05-02 18:09:15,810 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:16,325 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 18:09:16
2020-05-02 18:09:16,328 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 18:09:16,328 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502180859]
2020-05-02 18:09:16,329 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 18:09:16,330 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 18:09:16,331 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 18:09:16,331 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 18:09:16,333 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 18:09:17,310 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:17,311 INFO  mapreduce.Job - Running job: job_local1696147252_0001
2020-05-02 18:09:18,318 INFO  mapreduce.Job - Job job_local1696147252_0001 running in uber mode : false
2020-05-02 18:09:18,319 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:18,412 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 18:09:18,412 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 18:09:18,412 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 18:09:18,463 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 18:09:18,463 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 18:09:18,463 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 18:09:19,322 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:19,323 INFO  mapreduce.Job - Job job_local1696147252_0001 completed successfully
2020-05-02 18:09:19,341 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=6616735
		FILE: Number of bytes written=10465970
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=188
		Map output records=188
		Map output bytes=13684
		Map output materialized bytes=922
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=922
		Reduce input records=188
		Reduce output records=4
		Spilled Records=376
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=15136
	File Output Format Counters 
		Bytes Written=1540
2020-05-02 18:09:19,364 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 18:09:19, elapsed: 00:00:03
2020-05-02 18:09:20,707 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:21,214 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 18:09:21
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 18:09:21,215 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502180859
2020-05-02 18:09:22,057 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:22,058 INFO  mapreduce.Job - Running job: job_local1631640523_0001
2020-05-02 18:09:22,576 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 18:09:23,066 INFO  mapreduce.Job - Job job_local1631640523_0001 running in uber mode : false
2020-05-02 18:09:23,067 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:23,069 INFO  mapreduce.Job - Job job_local1631640523_0001 completed successfully
2020-05-02 18:09:23,083 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2843933
		FILE: Number of bytes written=4483012
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=1084227584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=20308
	File Output Format Counters 
		Bytes Written=279
2020-05-02 18:09:23,103 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 18:09:23, elapsed: 00:00:01
2020-05-02 18:09:24,100 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 18:09:24
2020-05-02 18:09:24,353 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:25,523 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:25,524 INFO  mapreduce.Job - Running job: job_local1846916925_0001
2020-05-02 18:09:26,536 INFO  mapreduce.Job - Job job_local1846916925_0001 running in uber mode : false
2020-05-02 18:09:26,537 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:26,539 INFO  mapreduce.Job - Job job_local1846916925_0001 completed successfully
2020-05-02 18:09:26,551 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2788450
		FILE: Number of bytes written=4488534
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1056
		Map output materialized bytes=1080
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1080
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1152
	File Output Format Counters 
		Bytes Written=98
2020-05-02 18:09:26,557 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 18:09:26,557 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 18:09:26,891 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:26,891 INFO  mapreduce.Job - Running job: job_local797995204_0002
2020-05-02 18:09:27,893 INFO  mapreduce.Job - Job job_local797995204_0002 running in uber mode : false
2020-05-02 18:09:27,894 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:27,894 INFO  mapreduce.Job - Job job_local797995204_0002 completed successfully
2020-05-02 18:09:27,899 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7443762
		FILE: Number of bytes written=11956225
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=916
		Map output materialized bytes=946
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=946
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1250
	File Output Format Counters 
		Bytes Written=1301
2020-05-02 18:09:27,927 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 18:09:27, elapsed: 00:00:03
2020-05-02 18:09:29,271 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:29,744 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:09:29,748 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:09:29
2020-05-02 18:09:29,817 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 18:09:29,818 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 18:09:29,820 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 18:09:29,840 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:09:29,841 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:09:29,841 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:09:30,828 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:30,829 INFO  mapreduce.Job - Running job: job_local77765944_0001
2020-05-02 18:09:31,836 INFO  mapreduce.Job - Job job_local77765944_0001 running in uber mode : false
2020-05-02 18:09:31,837 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:32,383 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:09:32,404 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:09:32,707 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:09:33,442 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:09:33,442 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:09:33,842 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:33,842 INFO  mapreduce.Job - Job job_local77765944_0001 completed successfully
2020-05-02 18:09:33,873 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=11309924
		FILE: Number of bytes written=18139319
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=196
		Map output records=196
		Map output bytes=150394
		Map output materialized bytes=150870
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=150870
		Reduce input records=196
		Reduce output records=4
		Spilled Records=392
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=240
		Total committed heap usage (bytes)=4899995648
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=70802
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:09:33,873 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:09:33,891 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:09:33,946 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:09:33, elapsed: 00:00:04
2020-05-02 18:09:35,206 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 18:09:35
2020-05-02 18:09:35,485 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:09:36,978 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:09:36,986 INFO  mapreduce.Job - Running job: job_local872719421_0001
2020-05-02 18:09:37,738 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:09:37,764 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:09:38,016 INFO  mapreduce.Job - Job job_local872719421_0001 running in uber mode : false
2020-05-02 18:09:38,018 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:09:38,181 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 18:09:39,020 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:09:39,021 INFO  mapreduce.Job - Job job_local872719421_0001 completed successfully
2020-05-02 18:09:39,038 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1856662
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=478150656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1054
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:09:39,059 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 18:09:39, elapsed: 00:00:03
2020-05-02 18:17:42,386 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:17:42,772 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:17:42
2020-05-02 18:17:42,772 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:17:44,588 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:17:44,589 INFO  mapreduce.Job - Running job: job_local31739510_0001
2020-05-02 18:17:45,597 INFO  mapreduce.Job - Job job_local31739510_0001 running in uber mode : false
2020-05-02 18:17:45,598 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:17:46,284 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:17:46,295 INFO  parse.ParseSegment - Parsed (1159ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:17:46,433 INFO  parse.ParseSegment - Parsed (129ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:17:46,543 INFO  parse.ParseSegment - Parsed (107ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:17:46,620 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:17:46,822 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:17:46,931 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:17:47,606 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:17:47,607 INFO  mapreduce.Job - Job job_local31739510_0001 completed successfully
2020-05-02 18:17:47,622 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3394686
		FILE: Number of bytes written=5288044
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=188178
		Map output materialized bytes=188206
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=188206
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=74
		Total committed heap usage (bytes)=1165492224
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:17:47,638 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:17:47, elapsed: 00:00:04
2020-05-02 18:17:48,714 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:17:49,072 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:17:49,079 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:17:49
2020-05-02 18:17:49,109 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:17:49,110 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:17:49,110 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:17:49,115 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:17:49,115 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:17:49,115 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:17:50,207 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:17:50,207 INFO  mapreduce.Job - Running job: job_local767937080_0001
2020-05-02 18:17:50,889 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,184 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,217 INFO  mapreduce.Job - Job job_local767937080_0001 running in uber mode : false
2020-05-02 18:17:51,219 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:17:51,300 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,408 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,544 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,729 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,783 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:17:51,959 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:17:51,990 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:17:52,558 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:17:53,456 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:17:53,456 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:17:54,231 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:17:54,233 INFO  mapreduce.Job - Job job_local767937080_0001 completed successfully
2020-05-02 18:17:54,258 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10993897
		FILE: Number of bytes written=17747596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=292158
		Map output materialized bytes=292660
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=292660
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=162
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=127685
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:17:54,258 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:17:54,267 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:17:54,286 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:17:54, elapsed: 00:00:05
2020-05-02 18:30:10,114 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:30:11,314 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:30:11
2020-05-02 18:30:11,314 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:30:12,599 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:30:12,601 INFO  mapreduce.Job - Running job: job_local62392434_0001
2020-05-02 18:30:13,607 INFO  mapreduce.Job - Job job_local62392434_0001 running in uber mode : false
2020-05-02 18:30:13,608 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:30:14,131 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:30:14,138 INFO  parse.ParseSegment - Parsed (1002ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:30:14,235 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:30:14,309 INFO  parse.ParseSegment - Parsed (69ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:30:14,589 INFO  parse.ParseSegment - Parsed (276ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:30:14,816 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:30:14,952 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:30:15,613 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:30:15,613 INFO  mapreduce.Job - Job job_local62392434_0001 completed successfully
2020-05-02 18:30:15,634 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318220
		FILE: Number of bytes written=5119280
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149945
		Map output materialized bytes=149973
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149973
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=98
		Total committed heap usage (bytes)=1094713344
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:30:15,647 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:30:15, elapsed: 00:00:04
2020-05-02 18:30:16,868 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:30:17,256 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:30:17,258 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:30:17
2020-05-02 18:30:17,270 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:30:17,270 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:30:17,270 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:30:17,271 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:30:17,271 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:30:17,272 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:30:18,129 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:30:18,130 INFO  mapreduce.Job - Running job: job_local1486865289_0001
2020-05-02 18:30:18,625 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:18,770 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:18,953 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,050 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,140 INFO  mapreduce.Job - Job job_local1486865289_0001 running in uber mode : false
2020-05-02 18:30:19,141 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:30:19,210 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,332 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,410 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:30:19,583 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:30:19,616 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:30:20,101 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:30:20,762 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:30:20,769 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:30:21,160 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:30:21,161 INFO  mapreduce.Job - Job job_local1486865289_0001 completed successfully
2020-05-02 18:30:21,182 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810517
		FILE: Number of bytes written=17456513
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253925
		Map output materialized bytes=254427
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254427
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=203
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111853
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:30:21,182 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:30:21,188 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:30:21,216 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:30:21, elapsed: 00:00:03
2020-05-02 18:47:56,106 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:47:56,528 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:47:56
2020-05-02 18:47:56,528 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:47:57,575 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:47:57,576 INFO  mapreduce.Job - Running job: job_local1586198216_0001
2020-05-02 18:47:58,584 INFO  mapreduce.Job - Job job_local1586198216_0001 running in uber mode : false
2020-05-02 18:47:58,585 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:47:59,136 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:47:59,145 INFO  parse.ParseSegment - Parsed (1092ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:47:59,247 INFO  parse.ParseSegment - Parsed (86ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:47:59,323 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:47:59,726 INFO  parse.ParseSegment - Parsed (400ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:47:59,932 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:48:00,110 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:48:00,590 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:48:00,590 INFO  mapreduce.Job - Job job_local1586198216_0001 completed successfully
2020-05-02 18:48:00,610 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318222
		FILE: Number of bytes written=5135627
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149946
		Map output materialized bytes=149974
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149974
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=78
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:48:00,628 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:48:00, elapsed: 00:00:04
2020-05-02 18:48:01,843 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:48:02,325 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:48:02,329 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:48:02
2020-05-02 18:48:02,401 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:48:02,401 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:48:02,402 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:48:02,410 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:48:02,410 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:48:02,410 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:48:03,352 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:48:03,353 INFO  mapreduce.Job - Running job: job_local424997706_0001
2020-05-02 18:48:03,859 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:03,976 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,188 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,326 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,360 INFO  mapreduce.Job - Job job_local424997706_0001 running in uber mode : false
2020-05-02 18:48:04,361 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:48:04,530 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,733 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,799 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:04,964 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:48:04,991 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:48:05,414 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:48:05,933 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:48:05,934 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:48:06,370 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:48:06,373 INFO  mapreduce.Job - Job job_local424997706_0001 completed successfully
2020-05-02 18:48:06,396 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810511
		FILE: Number of bytes written=17429160
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253926
		Map output materialized bytes=254428
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254428
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=6191841280
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111852
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:48:06,396 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:48:06,406 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:48:06,429 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:48:06, elapsed: 00:00:04
2020-05-02 18:48:51,508 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:48:51,865 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:48:51
2020-05-02 18:48:51,866 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:48:52,701 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:48:52,702 INFO  mapreduce.Job - Running job: job_local453089167_0001
2020-05-02 18:48:53,712 INFO  mapreduce.Job - Job job_local453089167_0001 running in uber mode : false
2020-05-02 18:48:53,713 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:48:54,243 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:48:54,252 INFO  parse.ParseSegment - Parsed (1113ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:48:54,326 INFO  parse.ParseSegment - Parsed (67ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:48:54,405 INFO  parse.ParseSegment - Parsed (76ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:48:54,648 INFO  parse.ParseSegment - Parsed (241ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:48:54,718 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:48:54,890 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:48:55,017 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:48:55,721 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:48:55,722 INFO  mapreduce.Job - Job job_local453089167_0001 completed successfully
2020-05-02 18:48:55,737 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318230
		FILE: Number of bytes written=5127469
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149950
		Map output materialized bytes=149978
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149978
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=1176502272
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:48:55,753 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:48:55, elapsed: 00:00:03
2020-05-02 18:48:56,809 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:48:57,190 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:48:57,193 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:48:57
2020-05-02 18:48:57,205 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:48:57,206 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:48:57,206 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:48:57,208 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:48:57,208 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:48:57,208 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:48:58,111 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:48:58,112 INFO  mapreduce.Job - Running job: job_local969553989_0001
2020-05-02 18:48:58,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:58,689 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:58,796 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:58,910 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,045 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,122 INFO  mapreduce.Job - Job job_local969553989_0001 running in uber mode : false
2020-05-02 18:48:59,123 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:48:59,144 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,215 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:48:59,430 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:48:59,452 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:48:59,838 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:49:00,551 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:49:00,555 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:49:01,129 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:49:01,130 INFO  mapreduce.Job - Job job_local969553989_0001 completed successfully
2020-05-02 18:49:01,158 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810504
		FILE: Number of bytes written=17429208
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253930
		Map output materialized bytes=254432
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254432
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=146
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111850
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:49:01,158 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:49:01,168 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:49:01,196 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:49:01, elapsed: 00:00:03
2020-05-02 18:51:02,916 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:03,276 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:51:03
2020-05-02 18:51:03,277 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:51:04,275 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:04,276 INFO  mapreduce.Job - Running job: job_local1504282378_0001
2020-05-02 18:51:05,287 INFO  mapreduce.Job - Job job_local1504282378_0001 running in uber mode : false
2020-05-02 18:51:05,288 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:51:05,590 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:51:05,602 INFO  parse.ParseSegment - Parsed (875ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:51:05,797 INFO  parse.ParseSegment - Parsed (185ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:51:05,907 INFO  parse.ParseSegment - Parsed (106ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:51:06,125 INFO  parse.ParseSegment - Parsed (215ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:51:06,293 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:06,352 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:51:06,479 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:51:07,294 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:07,295 INFO  mapreduce.Job - Job job_local1504282378_0001 completed successfully
2020-05-02 18:51:07,312 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318230
		FILE: Number of bytes written=5135646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149950
		Map output materialized bytes=149978
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149978
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:07,332 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:51:07, elapsed: 00:00:04
2020-05-02 18:51:08,473 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:08,850 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:51:08,853 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:51:08
2020-05-02 18:51:08,870 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:51:08,870 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:51:08,870 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:51:08,872 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:51:08,872 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:51:08,872 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:51:09,799 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:09,800 INFO  mapreduce.Job - Running job: job_local982864338_0001
2020-05-02 18:51:10,291 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,393 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,577 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,672 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,783 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,807 INFO  mapreduce.Job - Job job_local982864338_0001 running in uber mode : false
2020-05-02 18:51:10,808 INFO  mapreduce.Job -  map 44% reduce 0%
2020-05-02 18:51:10,872 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:10,922 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:11,103 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:51:11,126 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:51:11,522 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:51:11,813 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:12,227 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:51:12,229 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:51:12,818 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:12,818 INFO  mapreduce.Job - Job job_local982864338_0001 completed successfully
2020-05-02 18:51:12,842 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810539
		FILE: Number of bytes written=17429228
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253930
		Map output materialized bytes=254432
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254432
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=162
		Total committed heap usage (bytes)=6193938432
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111855
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:12,843 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:51:12,850 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:51:12,870 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:51:12, elapsed: 00:00:04
2020-05-02 18:51:31,840 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:32,227 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 18:51:32
2020-05-02 18:51:32,227 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502180859
2020-05-02 18:51:33,221 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:33,223 INFO  mapreduce.Job - Running job: job_local1297613748_0001
2020-05-02 18:51:34,229 INFO  mapreduce.Job - Job job_local1297613748_0001 running in uber mode : false
2020-05-02 18:51:34,230 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 18:51:34,684 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 18:51:34,695 INFO  parse.ParseSegment - Parsed (937ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 18:51:34,790 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11/specs/
2020-05-02 18:51:34,852 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/iphone-se/specs/
2020-05-02 18:51:35,152 INFO  parse.ParseSegment - Parsed (287ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 18:51:35,236 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:35,413 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 18:51:35,540 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 18:51:36,238 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:36,239 INFO  mapreduce.Job - Job job_local1297613748_0001 completed successfully
2020-05-02 18:51:36,253 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318230
		FILE: Number of bytes written=5135617
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149950
		Map output materialized bytes=149978
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149978
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1168637952
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78439
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:36,267 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 18:51:36, elapsed: 00:00:04
2020-05-02 18:51:37,355 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 18:51:37,750 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502180859.
2020-05-02 18:51:37,753 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 18:51:37
2020-05-02 18:51:37,782 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 18:51:37,783 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 18:51:37,783 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 18:51:37,784 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 18:51:37,784 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 18:51:37,784 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502180859
2020-05-02 18:51:38,758 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 18:51:38,759 INFO  mapreduce.Job - Running job: job_local983337037_0001
2020-05-02 18:51:39,251 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,357 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,503 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,634 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,771 INFO  mapreduce.Job - Job job_local983337037_0001 running in uber mode : false
2020-05-02 18:51:39,773 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 18:51:39,807 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:39,922 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:40,067 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 18:51:40,408 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 18:51:40,438 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 18:51:40,885 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 18:51:42,099 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 18:51:42,099 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 18:51:42,781 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 18:51:42,783 INFO  mapreduce.Job - Job job_local983337037_0001 completed successfully
2020-05-02 18:51:42,819 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10810336
		FILE: Number of bytes written=17429188
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=253930
		Map output materialized bytes=254432
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=254432
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=176
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111826
	File Output Format Counters 
		Bytes Written=0
2020-05-02 18:51:42,819 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 18:51:42,831 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 18:51:42,851 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 18:51:42, elapsed: 00:00:05
2020-05-02 19:07:03,271 INFO  crawl.Injector - Injector: starting at 2020-05-02 19:07:03
2020-05-02 19:07:03,272 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 19:07:03,272 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 19:07:03,282 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 19:07:03,460 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:04,022 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 19:07:05,107 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:05,109 INFO  mapreduce.Job - Running job: job_local1023143491_0001
2020-05-02 19:07:05,730 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 19:07:05,970 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 19:07:05,970 INFO  crawl.Injector - Injector: update: false
2020-05-02 19:07:06,118 INFO  mapreduce.Job - Job job_local1023143491_0001 running in uber mode : false
2020-05-02 19:07:06,119 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:06,119 INFO  mapreduce.Job - Job job_local1023143491_0001 completed successfully
2020-05-02 19:07:06,133 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1856344
		FILE: Number of bytes written=2988565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=4
		Map output bytes=276
		Map output materialized bytes=290
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=290
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_filtered=8
		urls_injected=4
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=653
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total urls rejected by filters: 8
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 4
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 19:07:06,145 INFO  crawl.Injector - Injector: Total new urls injected: 4
2020-05-02 19:07:06,166 INFO  crawl.Injector - Injector: finished at 2020-05-02 19:07:06, elapsed: 00:00:02
2020-05-02 19:07:07,248 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:07,701 INFO  crawl.Generator - Generator: starting at 2020-05-02 19:07:07
2020-05-02 19:07:07,702 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 19:07:07,702 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 19:07:07,702 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 19:07:07,705 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 19:07:08,572 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:08,573 INFO  mapreduce.Job - Running job: job_local655348898_0001
2020-05-02 19:07:09,051 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:07:09,052 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:07:09,052 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:07:09,062 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 19:07:09,299 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 19:07:09,578 INFO  mapreduce.Job - Job job_local655348898_0001 running in uber mode : false
2020-05-02 19:07:09,580 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:09,581 INFO  mapreduce.Job - Job job_local655348898_0001 completed successfully
2020-05-02 19:07:09,594 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2783711
		FILE: Number of bytes written=4486263
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=392
		Map output materialized bytes=134
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=406
	File Output Format Counters 
		Bytes Written=16
2020-05-02 19:07:09,594 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 19:07:09,599 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 19:07:10,604 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502190710
2020-05-02 19:07:10,880 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:10,880 INFO  mapreduce.Job - Running job: job_local1094954066_0002
2020-05-02 19:07:11,881 INFO  mapreduce.Job - Job job_local1094954066_0002 running in uber mode : false
2020-05-02 19:07:11,881 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:11,882 INFO  mapreduce.Job - Job job_local1094954066_0002 completed successfully
2020-05-02 19:07:11,885 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3712126
		FILE: Number of bytes written=5982713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=536
		Map output materialized bytes=133
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=133
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=548
	File Output Format Counters 
		Bytes Written=490
2020-05-02 19:07:11,904 INFO  crawl.Generator - Generator: finished at 2020-05-02 19:07:11, elapsed: 00:00:04
2020-05-02 19:07:13,030 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 19:07:13
2020-05-02 19:07:13,031 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502190710
2020-05-02 19:07:13,031 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588432033031  (2020-05-02 22:07:13)
2020-05-02 19:07:13,318 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:14,468 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:14,469 INFO  mapreduce.Job - Running job: job_local1651248860_0001
2020-05-02 19:07:14,641 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 19:07:14,641 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 19:07:14,642 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 19:07:14,654 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 4 records hit by time limit : 0
2020-05-02 19:07:14,910 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:14,933 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:14,933 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:14,934 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:14,934 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:14,935 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,176 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 19:07:15,180 INFO  http.Http - http.proxy.host = null
2020-05-02 19:07:15,180 INFO  http.Http - http.proxy.port = 8080
2020-05-02 19:07:15,180 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 19:07:15,180 INFO  http.Http - http.timeout = 30000
2020-05-02 19:07:15,180 INFO  http.Http - http.content.limit = -1
2020-05-02 19:07:15,180 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 19:07:15,180 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 19:07:15,180 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 19:07:15,180 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 19:07:15,181 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,181 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,182 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,183 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,183 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,184 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,184 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,185 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,186 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,186 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,187 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,188 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,191 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,191 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,192 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,192 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,194 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,194 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,195 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,196 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,196 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,197 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,198 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,198 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,199 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,200 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,201 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,202 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,202 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,203 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,204 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,205 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,206 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,207 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,208 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,209 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,211 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,215 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,216 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,220 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,221 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,229 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,231 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,231 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,232 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,235 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,238 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,238 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,239 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,239 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,240 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,240 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,241 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,242 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,244 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,245 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,246 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,246 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,247 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,247 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,248 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,249 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,250 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,250 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,251 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,253 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,254 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,254 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,255 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,255 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,255 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,256 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,256 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,257 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,257 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,257 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,258 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,259 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,260 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,260 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,261 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,261 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,262 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,262 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:15,264 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:07:15,264 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 19:07:15,265 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 19:07:15,265 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 19:07:15,480 INFO  mapreduce.Job - Job job_local1651248860_0001 running in uber mode : false
2020-05-02 19:07:15,481 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:07:16,271 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421234649
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   now           = 1588421236271
2020-05-02 19:07:16,271 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-se/specs/
2020-05-02 19:07:16,272 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:07:16,272 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:16,836 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:17,274 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421236836
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   now           = 1588421237275
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:07:17,275 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:17,451 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:18,277 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421237404
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   now           = 1588421238278
2020-05-02 19:07:18,278 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:18,565 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 19:07:18,704 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=48
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-02 19:07:18,703 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 19:07:18,706 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=47
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 19:07:18,714 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=41
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=42
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 19:07:18,714 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=40
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 19:07:18,714 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=39
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=45
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 19:07:18,716 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:07:18,713 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-02 19:07:18,716 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=38
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=36
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=35
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=32
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=30
2020-05-02 19:07:18,724 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=29
2020-05-02 19:07:18,725 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 19:07:18,720 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=33
2020-05-02 19:07:18,722 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=34
2020-05-02 19:07:18,725 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=28
2020-05-02 19:07:18,729 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 19:07:18,731 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=26
2020-05-02 19:07:18,725 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=27
2020-05-02 19:07:18,740 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=24
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=25
2020-05-02 19:07:18,741 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=23
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=22
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=21
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 19:07:18,758 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=20
2020-05-02 19:07:18,759 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 19:07:18,759 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=19
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=18
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 19:07:18,767 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=17
2020-05-02 19:07:18,768 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=16
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 19:07:18,768 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=15
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=11
2020-05-02 19:07:18,766 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 19:07:18,772 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=9
2020-05-02 19:07:18,772 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=10
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=14
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=12
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 19:07:18,774 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=8
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=13
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 19:07:18,775 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=7
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 19:07:18,781 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=6
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 19:07:18,786 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=5
2020-05-02 19:07:18,783 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 19:07:18,782 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 19:07:18,787 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=4
2020-05-02 19:07:18,787 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=3
2020-05-02 19:07:18,771 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 19:07:18,788 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=2
2020-05-02 19:07:18,911 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 19:07:18,912 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=1
2020-05-02 19:07:19,281 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 19:07:19,483 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 19:07:19,483 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=0
2020-05-02 19:07:20,286 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 19:07:20,287 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 19:07:20,499 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:21,499 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:21,500 INFO  mapreduce.Job - Job job_local1651248860_0001 completed successfully
2020-05-02 19:07:21,520 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2945147
		FILE: Number of bytes written=4865926
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=8
		Map output bytes=461891
		Map output materialized bytes=76752
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=76752
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=86
		Total committed heap usage (bytes)=976748544
	FetcherStatus
		bytes_downloaded=457983
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=490
	File Output Format Counters 
		Bytes Written=80315
2020-05-02 19:07:21,520 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 19:07:21, elapsed: 00:00:08
2020-05-02 19:07:22,654 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:23,039 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:07:23
2020-05-02 19:07:23,041 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190710
2020-05-02 19:07:24,004 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:24,005 INFO  mapreduce.Job - Running job: job_local974578749_0001
2020-05-02 19:07:25,011 INFO  mapreduce.Job - Job job_local974578749_0001 running in uber mode : false
2020-05-02 19:07:25,012 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:07:25,387 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:07:25,393 INFO  parse.ParseSegment - Parsed (907ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:07:25,464 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:07:25,551 INFO  parse.ParseSegment - Parsed (84ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:07:25,843 INFO  parse.ParseSegment - Parsed (290ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:07:26,018 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:26,041 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:26,160 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:07:26,245 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:07:27,019 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:27,019 INFO  mapreduce.Job - Job job_local974578749_0001 completed successfully
2020-05-02 19:07:27,044 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4116848
		FILE: Number of bytes written=6229428
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149951
		Map output materialized bytes=41928
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=41928
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1589116928
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78433
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:07:27,068 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:07:27, elapsed: 00:00:04
2020-05-02 19:07:28,383 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:28,950 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 19:07:28
2020-05-02 19:07:28,951 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 19:07:28,951 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502190710]
2020-05-02 19:07:28,951 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 19:07:28,952 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 19:07:28,953 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 19:07:28,953 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 19:07:28,960 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 19:07:29,909 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:29,910 INFO  mapreduce.Job - Running job: job_local1238561642_0001
2020-05-02 19:07:30,919 INFO  mapreduce.Job - Job job_local1238561642_0001 running in uber mode : false
2020-05-02 19:07:30,921 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:31,043 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:07:31,044 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:07:31,044 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:07:31,117 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:07:31,117 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:07:31,117 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:07:31,923 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:31,923 INFO  mapreduce.Job - Job job_local1238561642_0001 completed successfully
2020-05-02 19:07:31,952 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=6617094
		FILE: Number of bytes written=10465693
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=188
		Map output records=188
		Map output bytes=13684
		Map output materialized bytes=889
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=889
		Reduce input records=188
		Reduce output records=4
		Spilled Records=376
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=15208
	File Output Format Counters 
		Bytes Written=1540
2020-05-02 19:07:31,980 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 19:07:31, elapsed: 00:00:03
2020-05-02 19:07:33,490 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:33,932 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 19:07:33
2020-05-02 19:07:33,932 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 19:07:33,932 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 19:07:33,933 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 19:07:33,933 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 19:07:33,933 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502190710
2020-05-02 19:07:35,385 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:35,386 INFO  mapreduce.Job - Running job: job_local1603073375_0001
2020-05-02 19:07:36,397 INFO  mapreduce.Job - Job job_local1603073375_0001 running in uber mode : false
2020-05-02 19:07:36,398 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:36,399 INFO  mapreduce.Job - Job job_local1603073375_0001 completed successfully
2020-05-02 19:07:36,414 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2804282
		FILE: Number of bytes written=4480816
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=332
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=7091
	File Output Format Counters 
		Bytes Written=279
2020-05-02 19:07:36,414 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 19:07:36,830 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:36,830 INFO  mapreduce.Job - Running job: job_local1736692884_0002
2020-05-02 19:07:37,831 INFO  mapreduce.Job - Job job_local1736692884_0002 running in uber mode : false
2020-05-02 19:07:37,831 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:37,832 INFO  mapreduce.Job - Job job_local1736692884_0002 completed successfully
2020-05-02 19:07:37,837 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5588577
		FILE: Number of bytes written=8963155
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=276
	File Output Format Counters 
		Bytes Written=279
2020-05-02 19:07:37,858 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 19:07:37, elapsed: 00:00:03
2020-05-02 19:07:39,060 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 19:07:39
2020-05-02 19:07:39,430 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:40,813 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:40,814 INFO  mapreduce.Job - Running job: job_local769570520_0001
2020-05-02 19:07:41,821 INFO  mapreduce.Job - Job job_local769570520_0001 running in uber mode : false
2020-05-02 19:07:41,823 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:41,825 INFO  mapreduce.Job - Job job_local769570520_0001 completed successfully
2020-05-02 19:07:41,838 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2788450
		FILE: Number of bytes written=4480350
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1056
		Map output materialized bytes=1080
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1080
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1152
	File Output Format Counters 
		Bytes Written=98
2020-05-02 19:07:41,843 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 19:07:41,843 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 19:07:42,169 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:42,169 INFO  mapreduce.Job - Running job: job_local1297836942_0002
2020-05-02 19:07:43,173 INFO  mapreduce.Job - Job job_local1297836942_0002 running in uber mode : false
2020-05-02 19:07:43,174 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:43,174 INFO  mapreduce.Job - Job job_local1297836942_0002 completed successfully
2020-05-02 19:07:43,180 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7443771
		FILE: Number of bytes written=11956213
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=916
		Map output materialized bytes=946
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=946
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1250
	File Output Format Counters 
		Bytes Written=1301
2020-05-02 19:07:43,202 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 19:07:43, elapsed: 00:00:04
2020-05-02 19:07:44,533 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:45,031 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190710.
2020-05-02 19:07:45,034 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:07:45
2020-05-02 19:07:45,045 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 19:07:45,046 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 19:07:45,046 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 19:07:45,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:07:45,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:07:45,047 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190710
2020-05-02 19:07:46,244 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:46,245 INFO  mapreduce.Job - Running job: job_local400380403_0001
2020-05-02 19:07:47,251 INFO  mapreduce.Job - Job job_local400380403_0001 running in uber mode : false
2020-05-02 19:07:47,252 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:48,116 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:07:48,163 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:07:48,574 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:07:49,406 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 19:07:49,407 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:07:50,259 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:50,260 INFO  mapreduce.Job - Job job_local400380403_0001 completed successfully
2020-05-02 19:07:50,287 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=11120314
		FILE: Number of bytes written=17806895
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=196
		Map output records=196
		Map output bytes=118049
		Map output materialized bytes=118525
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=118525
		Reduce input records=196
		Reduce output records=4
		Spilled Records=392
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=281
		Total committed heap usage (bytes)=4902617088
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=57657
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:07:50,287 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:07:50,296 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 19:07:50,312 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:07:50, elapsed: 00:00:05
2020-05-02 19:07:52,010 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 19:07:52
2020-05-02 19:07:52,305 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:07:53,825 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:07:53,826 INFO  mapreduce.Job - Running job: job_local2104914791_0001
2020-05-02 19:07:54,448 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:07:54,469 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:07:54,836 INFO  mapreduce.Job - Job job_local2104914791_0001 running in uber mode : false
2020-05-02 19:07:54,837 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:07:54,875 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 19:07:55,838 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:07:55,839 INFO  mapreduce.Job - Job job_local2104914791_0001 completed successfully
2020-05-02 19:07:55,853 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1856662
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=477626368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1054
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:07:55,873 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 19:07:55, elapsed: 00:00:03
2020-05-02 19:08:07,766 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:08,170 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:08:08
2020-05-02 19:08:08,170 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190710
2020-05-02 19:08:09,180 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:09,181 INFO  mapreduce.Job - Running job: job_local1047573533_0001
2020-05-02 19:08:10,189 INFO  mapreduce.Job - Job job_local1047573533_0001 running in uber mode : false
2020-05-02 19:08:10,190 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:08:10,511 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:08:10,518 INFO  parse.ParseSegment - Parsed (853ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:08:10,598 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:08:10,660 INFO  parse.ParseSegment - Parsed (58ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:08:10,904 INFO  parse.ParseSegment - Parsed (242ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:08:11,105 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:08:11,194 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:08:11,222 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:08:12,198 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:08:12,199 INFO  mapreduce.Job - Job job_local1047573533_0001 completed successfully
2020-05-02 19:08:12,226 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318214
		FILE: Number of bytes written=5135506
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149951
		Map output materialized bytes=149979
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149979
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=71
		Total committed heap usage (bytes)=1171783680
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78433
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:08:12,244 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:08:12, elapsed: 00:00:04
2020-05-02 19:08:13,331 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:13,717 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190710.
2020-05-02 19:08:13,719 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:08:13
2020-05-02 19:08:13,729 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:08:13,730 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:08:13,730 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:08:13,732 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:08:13,732 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:08:13,732 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190710
2020-05-02 19:08:14,667 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:14,668 INFO  mapreduce.Job - Running job: job_local113251858_0001
2020-05-02 19:08:15,178 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,298 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,410 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,547 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,624 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,674 INFO  mapreduce.Job - Job job_local113251858_0001 running in uber mode : false
2020-05-02 19:08:15,675 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:08:15,761 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:15,854 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:08:16,056 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:08:16,088 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:08:16,522 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:08:17,131 INFO  solr.SolrIndexWriter - Indexing 4/4 documents
2020-05-02 19:08:17,132 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:08:17,682 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:08:17,683 INFO  mapreduce.Job - Job job_local113251858_0001 completed successfully
2020-05-02 19:08:17,711 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=10645594
		FILE: Number of bytes written=17131387
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=204
		Map output records=204
		Map output bytes=221586
		Map output materialized bytes=222088
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=222088
		Reduce input records=204
		Reduce output records=4
		Spilled Records=408
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=180
		Total committed heap usage (bytes)=6193414144
	IndexerStatus
		indexed (add/update)=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=98495
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:08:17,711 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:08:17,719 INFO  indexer.IndexingJob - Indexer:      4  indexed (add/update)
2020-05-02 19:08:17,747 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:08:17, elapsed: 00:00:04
2020-05-02 19:08:46,382 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:46,737 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:08:46
2020-05-02 19:08:46,750 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190710
2020-05-02 19:08:47,829 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:47,830 INFO  mapreduce.Job - Running job: job_local1186634806_0001
2020-05-02 19:08:48,837 INFO  mapreduce.Job - Job job_local1186634806_0001 running in uber mode : false
2020-05-02 19:08:48,838 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:08:49,452 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:08:49,461 INFO  parse.ParseSegment - Parsed (1104ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:08:49,556 INFO  parse.ParseSegment - Parsed (87ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:08:49,628 INFO  parse.ParseSegment - Parsed (69ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:08:49,916 INFO  parse.ParseSegment - Parsed (286ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:08:50,136 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:08:50,280 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:08:50,844 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:08:50,845 INFO  mapreduce.Job - Job job_local1186634806_0001 completed successfully
2020-05-02 19:08:50,862 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3318214
		FILE: Number of bytes written=5135626
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=149951
		Map output materialized bytes=149979
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=149979
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=78433
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:08:50,878 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:08:50, elapsed: 00:00:04
2020-05-02 19:08:51,969 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:08:52,464 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190710.
2020-05-02 19:08:52,466 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:08:52
2020-05-02 19:08:52,475 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:08:52,475 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:08:52,475 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:08:52,477 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:08:52,477 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:08:52,477 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190710
2020-05-02 19:08:53,404 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:08:53,405 INFO  mapreduce.Job - Running job: job_local1081988311_0001
2020-05-02 19:09:32,018 INFO  crawl.Injector - Injector: starting at 2020-05-02 19:09:32
2020-05-02 19:09:32,019 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 19:09:32,019 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 19:09:32,019 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 19:09:32,161 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:32,568 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 19:09:33,366 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:33,366 INFO  mapreduce.Job - Running job: job_local1572039161_0001
2020-05-02 19:09:33,803 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 19:09:34,024 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 19:09:34,024 INFO  crawl.Injector - Injector: update: false
2020-05-02 19:09:34,376 INFO  mapreduce.Job - Job job_local1572039161_0001 running in uber mode : false
2020-05-02 19:09:34,378 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:34,379 INFO  mapreduce.Job - Job job_local1572039161_0001 completed successfully
2020-05-02 19:09:34,392 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1857472
		FILE: Number of bytes written=2990872
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=824
		Map output materialized bytes=854
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=854
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=12
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1264
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 12
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 19:09:34,404 INFO  crawl.Injector - Injector: Total new urls injected: 12
2020-05-02 19:09:34,422 INFO  crawl.Injector - Injector: finished at 2020-05-02 19:09:34, elapsed: 00:00:02
2020-05-02 19:09:35,472 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:35,893 INFO  crawl.Generator - Generator: starting at 2020-05-02 19:09:35
2020-05-02 19:09:35,893 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 19:09:35,894 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 19:09:35,894 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 19:09:35,897 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 19:09:36,763 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:36,764 INFO  mapreduce.Job - Running job: job_local1949161384_0001
2020-05-02 19:09:37,205 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:09:37,205 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:09:37,205 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:09:37,212 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 19:09:37,423 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 19:09:37,782 INFO  mapreduce.Job - Job job_local1949161384_0001 running in uber mode : false
2020-05-02 19:09:37,784 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:37,786 INFO  mapreduce.Job - Job job_local1949161384_0001 completed successfully
2020-05-02 19:09:37,801 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785867
		FILE: Number of bytes written=4496588
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1172
		Map output materialized bytes=211
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=211
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1022
	File Output Format Counters 
		Bytes Written=16
2020-05-02 19:09:37,801 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 19:09:37,807 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 19:09:38,813 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502190938
2020-05-02 19:09:39,055 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:39,056 INFO  mapreduce.Job - Running job: job_local989571258_0002
2020-05-02 19:09:40,060 INFO  mapreduce.Job - Job job_local989571258_0002 running in uber mode : false
2020-05-02 19:09:40,061 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:40,061 INFO  mapreduce.Job - Job job_local989571258_0002 completed successfully
2020-05-02 19:09:40,066 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3715578
		FILE: Number of bytes written=5985853
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1600
		Map output materialized bytes=241
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=241
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1396
	File Output Format Counters 
		Bytes Written=1278
2020-05-02 19:09:40,086 INFO  crawl.Generator - Generator: finished at 2020-05-02 19:09:40, elapsed: 00:00:04
2020-05-02 19:09:41,086 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 19:09:41
2020-05-02 19:09:41,087 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502190938
2020-05-02 19:09:41,087 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588432181087  (2020-05-02 22:09:41)
2020-05-02 19:09:41,309 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:42,499 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:42,500 INFO  mapreduce.Job - Running job: job_local494711029_0001
2020-05-02 19:09:42,693 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 19:09:42,693 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 19:09:42,693 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 19:09:42,704 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 12 records hit by time limit : 0
2020-05-02 19:09:42,978 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,002 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,002 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,003 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:43,213 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 19:09:43,215 INFO  http.Http - http.proxy.host = null
2020-05-02 19:09:43,215 INFO  http.Http - http.proxy.port = 8080
2020-05-02 19:09:43,215 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 19:09:43,216 INFO  http.Http - http.timeout = 30000
2020-05-02 19:09:43,216 INFO  http.Http - http.content.limit = -1
2020-05-02 19:09:43,216 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 19:09:43,216 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 19:09:43,216 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 19:09:43,216 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 19:09:43,236 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,237 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,237 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,240 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,241 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,244 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,245 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,245 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,246 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,252 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,253 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,265 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,266 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,267 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,270 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,272 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,272 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,273 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,275 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,277 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,277 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,279 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,279 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,280 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,290 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,291 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,298 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,299 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,304 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,305 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,391 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,392 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,393 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,394 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,396 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,396 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,397 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,398 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,398 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,399 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,401 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,403 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,415 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,416 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,416 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,417 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,424 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,425 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,427 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,428 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,435 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,436 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,437 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,437 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,444 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,445 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,458 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,459 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,461 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,461 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,461 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,462 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,463 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,463 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,464 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,464 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,467 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,468 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,468 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,469 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,470 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,471 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,471 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,473 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,473 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,477 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,478 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,479 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,480 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,482 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,483 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,484 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,485 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,490 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,490 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,491 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,492 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,493 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:43,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:09:43,494 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 19:09:43,494 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 19:09:43,494 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 19:09:43,509 INFO  mapreduce.Job - Job job_local494711029_0001 running in uber mode : false
2020-05-02 19:09:43,511 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:09:44,499 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2020-05-02 19:09:45,003 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:45,303 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/imac-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:45,504 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-02 19:09:46,509 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-02 19:09:46,940 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:47,513 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2020-05-02 19:09:47,551 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/imac/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:48,517 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2020-05-02 19:09:48,725 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:49,509 INFO  fetcher.FetcherThread - FetcherThread 82 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:49,520 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-02 19:09:49,822 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:50,245 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:50,522 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:09:50,522 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421390081
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   now           = 1588421390523
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:09:50,523 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-02 19:09:50,940 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:51,208 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:51,528 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588421391208
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   now           = 1588421391528
2020-05-02 19:09:51,528 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/ipad-air/specs/
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=45
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=48
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=49
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 19:09:51,999 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=44
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 19:09:52,001 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 19:09:52,002 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=42
2020-05-02 19:09:51,997 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=47
2020-05-02 19:09:52,009 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 19:09:52,009 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=41
2020-05-02 19:09:52,019 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 19:09:52,019 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=40
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=39
2020-05-02 19:09:52,024 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=36
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=35
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=34
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=33
2020-05-02 19:09:52,025 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 19:09:52,026 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=32
2020-05-02 19:09:52,032 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 19:09:52,032 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:09:52,033 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 19:09:52,033 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=30
2020-05-02 19:09:52,086 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 19:09:52,087 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=29
2020-05-02 19:09:52,272 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 19:09:52,273 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=28
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=27
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=26
2020-05-02 19:09:52,290 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 19:09:52,291 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=25
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=24
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=23
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=22
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=21
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=20
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=19
2020-05-02 19:09:52,292 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=18
2020-05-02 19:09:52,317 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 19:09:52,317 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 19:09:52,318 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=17
2020-05-02 19:09:52,318 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=16
2020-05-02 19:09:52,342 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 19:09:52,342 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=15
2020-05-02 19:09:52,421 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 19:09:52,421 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 19:09:52,422 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=14
2020-05-02 19:09:52,422 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=13
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=9
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=8
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=7
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=6
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=10
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=11
2020-05-02 19:09:52,442 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=12
2020-05-02 19:09:52,443 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=5
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=4
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 19:09:52,453 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=3
2020-05-02 19:09:52,481 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 19:09:52,481 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=2
2020-05-02 19:09:52,494 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 19:09:52,494 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=1
2020-05-02 19:09:52,530 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 19:09:52,669 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 19:09:52,669 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=0
2020-05-02 19:09:53,531 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 19:09:53,531 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 19:09:54,552 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:09:54,552 INFO  mapreduce.Job - Job job_local494711029_0001 completed successfully
2020-05-02 19:09:54,584 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3319217
		FILE: Number of bytes written=5652874
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=24
		Map output bytes=1358473
		Map output materialized bytes=213453
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=213453
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=92
		Total committed heap usage (bytes)=968884224
	FetcherStatus
		bytes_downloaded=1346765
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1278
	File Output Format Counters 
		Bytes Written=221716
2020-05-02 19:09:54,585 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 19:09:54, elapsed: 00:00:13
2020-05-02 19:09:55,831 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:09:56,270 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:09:56
2020-05-02 19:09:56,270 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:09:57,250 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:09:57,251 INFO  mapreduce.Job - Running job: job_local1906531787_0001
2020-05-02 19:09:58,257 INFO  mapreduce.Job - Job job_local1906531787_0001 running in uber mode : false
2020-05-02 19:09:58,258 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:09:58,684 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:09:58,692 INFO  parse.ParseSegment - Parsed (948ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:09:58,763 INFO  parse.ParseSegment - Parsed (66ms):https://www.apple.com/imac/specs/
2020-05-02 19:09:58,823 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:09:58,885 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:09:58,941 INFO  parse.ParseSegment - Parsed (52ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:09:58,995 INFO  parse.ParseSegment - Parsed (52ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:09:59,045 INFO  parse.ParseSegment - Parsed (48ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:09:59,295 INFO  parse.ParseSegment - Parsed (248ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:09:59,359 INFO  parse.ParseSegment - Parsed (63ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:09:59,494 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:09:59,494 INFO  parse.ParseSegment - Parsed (30ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:09:59,525 INFO  parse.ParseSegment - Parsed (29ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:09:59,562 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:09:59,695 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:09:59,852 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:09:59,985 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:10:00,085 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:10:00,265 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 19:10:01,267 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:01,269 INFO  mapreduce.Job - Job job_local1906531787_0001 completed successfully
2020-05-02 19:10:01,291 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4773879
		FILE: Number of bytes written=6697388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=96972
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=96972
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=88
		Total committed heap usage (bytes)=1594359808
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:10:01,315 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:10:01, elapsed: 00:00:05
2020-05-02 19:10:02,833 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 19:10:03
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502190938]
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 19:10:03,261 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 19:10:03,266 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 19:10:04,083 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:04,085 INFO  mapreduce.Job - Running job: job_local1014735562_0001
2020-05-02 19:10:05,095 INFO  mapreduce.Job - Job job_local1014735562_0001 running in uber mode : false
2020-05-02 19:10:05,097 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:10:05,393 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:10:05,393 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:10:05,393 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:10:05,509 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:10:05,509 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:10:05,509 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:10:06,101 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:06,103 INFO  mapreduce.Job - Job job_local1014735562_0001 completed successfully
2020-05-02 19:10:06,137 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=7181133
		FILE: Number of bytes written=10616916
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1236
		Map output records=1236
		Map output bytes=90629
		Map output materialized bytes=7363
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=7363
		Reduce input records=1236
		Reduce output records=798
		Spilled Records=2472
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=12
		db_unfetched=786
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=96772
	File Output Format Counters 
		Bytes Written=67516
2020-05-02 19:10:06,161 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 19:10:06, elapsed: 00:00:02
2020-05-02 19:10:07,582 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:08,029 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 19:10:08
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 19:10:08,030 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502190938
2020-05-02 19:10:09,393 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:09,394 INFO  mapreduce.Job - Running job: job_local1735656804_0001
2020-05-02 19:10:10,401 INFO  mapreduce.Job - Job job_local1735656804_0001 running in uber mode : false
2020-05-02 19:10:10,402 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:10,404 INFO  mapreduce.Job - Job job_local1735656804_0001 completed successfully
2020-05-02 19:10:10,416 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2832981
		FILE: Number of bytes written=4484311
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=332
		Combine input records=7
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17291
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:10:10,416 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 19:10:10,724 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:10,725 INFO  mapreduce.Job - Running job: job_local1142832152_0002
2020-05-02 19:10:11,055 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 19:10:11,727 INFO  mapreduce.Job - Job job_local1142832152_0002 running in uber mode : false
2020-05-02 19:10:11,727 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:11,728 INFO  mapreduce.Job - Job job_local1142832152_0002 completed successfully
2020-05-02 19:10:11,733 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5626726
		FILE: Number of bytes written=8973139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1017
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:10:11,756 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 19:10:11, elapsed: 00:00:03
2020-05-02 19:10:12,724 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 19:10:12
2020-05-02 19:10:12,961 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:14,158 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:14,159 INFO  mapreduce.Job - Running job: job_local550841849_0001
2020-05-02 19:10:15,169 INFO  mapreduce.Job - Job job_local550841849_0001 running in uber mode : false
2020-05-02 19:10:15,170 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:15,172 INFO  mapreduce.Job - Job job_local550841849_0001 completed successfully
2020-05-02 19:10:15,188 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2956832
		FILE: Number of bytes written=4486482
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=12
		Map output bytes=3164
		Map output materialized bytes=3212
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=3212
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66898
	File Output Format Counters 
		Bytes Written=98
2020-05-02 19:10:15,193 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 19:10:15,194 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 19:10:15,533 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:15,533 INFO  mapreduce.Job - Running job: job_local443855507_0002
2020-05-02 19:10:16,535 INFO  mapreduce.Job - Job job_local443855507_0002 running in uber mode : false
2020-05-02 19:10:16,535 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:16,536 INFO  mapreduce.Job - Job job_local443855507_0002 completed successfully
2020-05-02 19:10:16,541 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8073400
		FILE: Number of bytes written=12297309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=798
		Map output bytes=59182
		Map output materialized bytes=60808
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=60808
		Reduce input records=798
		Reduce output records=798
		Spilled Records=1596
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=67156
2020-05-02 19:10:16,561 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 19:10:16, elapsed: 00:00:03
2020-05-02 19:10:17,633 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:18,007 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:10:18,027 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:10:18
2020-05-02 19:10:18,044 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 19:10:18,044 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 19:10:18,045 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 19:10:18,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:10:18,047 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:10:18,047 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:10:18,945 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:18,946 INFO  mapreduce.Job - Running job: job_local86927638_0001
2020-05-02 19:10:19,952 INFO  mapreduce.Job - Job job_local86927638_0001 running in uber mode : false
2020-05-02 19:10:19,953 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:10:20,640 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:10:20,677 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:10:21,009 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:10:21,626 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:10:21,626 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:10:21,961 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:21,962 INFO  mapreduce.Job - Job job_local86927638_0001 completed successfully
2020-05-02 19:10:21,980 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13607588
		FILE: Number of bytes written=20664976
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2053
		Map output records=2053
		Map output bytes=439257
		Map output materialized bytes=443495
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=443495
		Reduce input records=2053
		Reduce output records=12
		Spilled Records=4106
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=242
		Total committed heap usage (bytes)=4902617088
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=262494
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:10:21,981 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:10:21,990 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:10:22,010 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:10:21, elapsed: 00:00:03
2020-05-02 19:10:22,990 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 19:10:22
2020-05-02 19:10:23,237 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:10:24,446 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:10:24,447 INFO  mapreduce.Job - Running job: job_local613133701_0001
2020-05-02 19:10:25,030 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:10:25,054 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:10:25,386 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 19:10:25,454 INFO  mapreduce.Job - Job job_local613133701_0001 running in uber mode : false
2020-05-02 19:10:25,455 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:10:25,456 INFO  mapreduce.Job - Job job_local613133701_0001 completed successfully
2020-05-02 19:10:25,471 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1988196
		FILE: Number of bytes written=2980390
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=79
		Total committed heap usage (bytes)=477626368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66820
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:10:25,491 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 19:10:25, elapsed: 00:00:02
2020-05-02 19:11:28,073 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:11:28,430 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:11:28
2020-05-02 19:11:28,432 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:11:29,676 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:11:29,677 INFO  mapreduce.Job - Running job: job_local4674744_0001
2020-05-02 19:11:30,744 INFO  mapreduce.Job - Job job_local4674744_0001 running in uber mode : false
2020-05-02 19:11:30,745 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:11:31,202 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:11:31,211 INFO  parse.ParseSegment - Parsed (942ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:11:31,316 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/imac/specs/
2020-05-02 19:11:31,395 INFO  parse.ParseSegment - Parsed (76ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:11:31,462 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:11:31,528 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:11:31,581 INFO  parse.ParseSegment - Parsed (51ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:11:31,634 INFO  parse.ParseSegment - Parsed (51ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:11:31,895 INFO  parse.ParseSegment - Parsed (259ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:11:31,965 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:11:32,110 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:11:32,110 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:11:32,147 INFO  parse.ParseSegment - Parsed (34ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:11:32,190 INFO  parse.ParseSegment - Parsed (42ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:11:32,339 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:11:32,473 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:11:32,747 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:11:32,748 INFO  mapreduce.Job - Job job_local4674744_0001 completed successfully
2020-05-02 19:11:32,764 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205315
		FILE: Number of bytes written=6191777
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=410945
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410945
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=86
		Total committed heap usage (bytes)=1166016512
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:11:32,777 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:11:32, elapsed: 00:00:04
2020-05-02 19:11:33,846 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:11:34,227 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:11:34,230 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:11:34
2020-05-02 19:11:34,244 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:11:34,252 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:11:34,252 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:11:34,253 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:11:34,253 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:11:34,253 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:11:35,178 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:11:35,179 INFO  mapreduce.Job - Running job: job_local500473406_0001
2020-05-02 19:11:35,711 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,182 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,187 INFO  mapreduce.Job - Job job_local500473406_0001 running in uber mode : false
2020-05-02 19:11:36,189 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:11:36,278 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,465 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,552 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,655 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,742 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,802 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,837 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:11:36,982 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:11:37,019 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:11:37,466 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:11:38,169 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:11:38,169 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:11:39,197 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:11:39,198 INFO  mapreduce.Job - Job job_local500473406_0001 completed successfully
2020-05-02 19:11:39,234 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13500913
		FILE: Number of bytes written=20833479
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=662059
		Map output materialized bytes=666363
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=666363
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=169
		Total committed heap usage (bytes)=6195511296
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=339740
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:11:39,235 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:11:39,244 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:11:39,279 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:11:39, elapsed: 00:00:05
2020-05-02 19:14:12,393 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:12,853 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:14:12
2020-05-02 19:14:12,853 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:14:14,099 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:14,100 INFO  mapreduce.Job - Running job: job_local613504018_0001
2020-05-02 19:14:15,126 INFO  mapreduce.Job - Job job_local613504018_0001 running in uber mode : false
2020-05-02 19:14:15,127 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:14:15,552 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:15,559 INFO  parse.ParseSegment - Parsed (910ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:14:15,649 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/imac/specs/
2020-05-02 19:14:15,707 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:14:15,769 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:14:15,828 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:14:15,894 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:14:15,955 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:14:16,194 INFO  parse.ParseSegment - Parsed (237ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:14:16,297 INFO  parse.ParseSegment - Parsed (101ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:14:16,443 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:16,444 INFO  parse.ParseSegment - Parsed (39ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:14:16,481 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:14:16,529 INFO  parse.ParseSegment - Parsed (45ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:14:16,665 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:14:16,791 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:14:17,132 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:14:17,132 INFO  mapreduce.Job - Job job_local613504018_0001 completed successfully
2020-05-02 19:14:17,155 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205315
		FILE: Number of bytes written=6208106
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=410945
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410945
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=82
		Total committed heap usage (bytes)=1162870784
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:14:17,176 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:14:17, elapsed: 00:00:04
2020-05-02 19:14:18,409 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:18,869 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:14:18,874 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:14:18
2020-05-02 19:14:18,887 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:14:18,887 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:14:18,887 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:14:18,889 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:14:18,889 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:14:18,889 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:14:19,903 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:19,904 INFO  mapreduce.Job - Running job: job_local1357022972_0001
2020-05-02 19:14:20,459 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:20,911 INFO  mapreduce.Job - Job job_local1357022972_0001 running in uber mode : false
2020-05-02 19:14:20,912 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:14:21,071 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,172 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,475 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,681 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,829 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,909 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,917 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-02 19:14:21,957 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:21,993 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:14:22,103 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:14:22,130 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:14:22,613 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:14:22,921 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:14:23,293 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:14:23,295 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:14:23,927 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:14:23,927 INFO  mapreduce.Job - Job job_local1357022972_0001 completed successfully
2020-05-02 19:14:23,950 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13500643
		FILE: Number of bytes written=20860799
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=662059
		Map output materialized bytes=666363
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=666363
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=168
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=339713
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:14:23,950 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:14:23,967 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:14:23,999 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:14:23, elapsed: 00:00:05
2020-05-02 19:14:53,050 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:53,412 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:14:53
2020-05-02 19:14:53,412 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:14:54,179 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:54,180 INFO  mapreduce.Job - Running job: job_local1334528602_0001
2020-05-02 19:14:55,188 INFO  mapreduce.Job - Job job_local1334528602_0001 running in uber mode : false
2020-05-02 19:14:55,189 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:14:55,448 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:55,455 INFO  parse.ParseSegment - Parsed (809ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:14:55,529 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/imac/specs/
2020-05-02 19:14:55,594 INFO  parse.ParseSegment - Parsed (62ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:14:55,657 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:14:55,725 INFO  parse.ParseSegment - Parsed (66ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:14:55,788 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:14:55,844 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:14:56,071 INFO  parse.ParseSegment - Parsed (226ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:14:56,152 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:14:56,195 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:14:56,298 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:14:56,299 INFO  parse.ParseSegment - Parsed (34ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:14:56,324 INFO  parse.ParseSegment - Parsed (24ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:14:56,370 INFO  parse.ParseSegment - Parsed (44ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:14:56,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:14:56,616 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:14:57,200 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:14:57,201 INFO  mapreduce.Job - Job job_local1334528602_0001 completed successfully
2020-05-02 19:14:57,215 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205315
		FILE: Number of bytes written=6217093
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410885
		Map output materialized bytes=410945
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410945
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=1170735104
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:14:57,233 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:14:57, elapsed: 00:00:03
2020-05-02 19:14:58,237 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:14:58,588 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:14:58,591 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:14:58
2020-05-02 19:14:58,602 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:14:58,602 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:14:58,602 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:14:58,603 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:14:58,603 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:14:58,603 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:14:59,510 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:14:59,511 INFO  mapreduce.Job - Running job: job_local317017543_0001
2020-05-02 19:14:59,950 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,425 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,521 INFO  mapreduce.Job - Job job_local317017543_0001 running in uber mode : false
2020-05-02 19:15:00,522 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:15:00,544 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,660 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,755 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,837 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,923 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:00,964 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:01,000 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:01,113 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:15:01,135 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:15:01,541 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:15:02,137 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:15:02,138 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:15:02,528 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:15:02,529 INFO  mapreduce.Job - Job job_local317017543_0001 completed successfully
2020-05-02 19:15:02,559 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13508793
		FILE: Number of bytes written=20833459
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=662059
		Map output materialized bytes=666363
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=666363
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=161
		Total committed heap usage (bytes)=6167199744
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=340528
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:15:02,559 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:15:02,567 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:15:02,592 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:15:02, elapsed: 00:00:03
2020-05-02 19:15:11,984 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:15:12,364 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:15:12
2020-05-02 19:15:12,364 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502190938
2020-05-02 19:15:13,429 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:15:13,431 INFO  mapreduce.Job - Running job: job_local1958081519_0001
2020-05-02 19:15:14,439 INFO  mapreduce.Job - Job job_local1958081519_0001 running in uber mode : false
2020-05-02 19:15:14,440 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:15:14,884 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:15:14,895 INFO  parse.ParseSegment - Parsed (1003ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:15:15,035 INFO  parse.ParseSegment - Parsed (134ms):https://www.apple.com/imac/specs/
2020-05-02 19:15:15,122 INFO  parse.ParseSegment - Parsed (83ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:15:15,244 INFO  parse.ParseSegment - Parsed (120ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:15:15,337 INFO  parse.ParseSegment - Parsed (91ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:15:15,429 INFO  parse.ParseSegment - Parsed (90ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:15:15,504 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:15:15,569 INFO  parse.ParseSegment - Parsed (63ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:15:15,652 INFO  parse.ParseSegment - Parsed (81ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:15:15,739 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:15:15,740 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:15:15,771 INFO  parse.ParseSegment - Parsed (30ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:15:15,981 INFO  parse.ParseSegment - Parsed (208ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:15:16,105 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:15:16,219 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:15:16,451 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:15:16,451 INFO  mapreduce.Job - Job job_local1958081519_0001 completed successfully
2020-05-02 19:15:16,471 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4312539
		FILE: Number of bytes written=6449335
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=464497
		Map output materialized bytes=464557
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=464557
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=235
		Total committed heap usage (bytes)=1329594368
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217998
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:15:16,497 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:15:16, elapsed: 00:00:04
2020-05-02 19:15:17,534 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:15:17,896 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502190938.
2020-05-02 19:15:17,899 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:15:17
2020-05-02 19:15:17,915 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:15:17,915 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:15:17,916 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:15:17,917 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:15:17,917 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:15:17,918 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502190938
2020-05-02 19:15:19,162 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:15:19,165 INFO  mapreduce.Job - Running job: job_local1802074168_0001
2020-05-02 19:15:19,688 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,067 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,169 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,177 INFO  mapreduce.Job - Job job_local1802074168_0001 running in uber mode : false
2020-05-02 19:15:20,178 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:15:20,309 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,395 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,508 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,582 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,625 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,681 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:15:20,809 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:15:20,841 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:15:21,303 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:15:21,953 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:15:21,958 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:15:22,192 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:15:22,194 INFO  mapreduce.Job - Job job_local1802074168_0001 completed successfully
2020-05-02 19:15:22,225 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13754291
		FILE: Number of bytes written=21236083
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=715671
		Map output materialized bytes=719975
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=719975
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=168
		Total committed heap usage (bytes)=6165102592
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=363585
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:15:22,225 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:15:22,235 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:15:22,268 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:15:22, elapsed: 00:00:04
2020-05-02 19:22:14,193 INFO  crawl.Injector - Injector: starting at 2020-05-02 19:22:14
2020-05-02 19:22:14,193 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-02 19:22:14,194 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-02 19:22:14,194 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-02 19:22:14,361 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:14,753 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-02 19:22:15,845 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:15,846 INFO  mapreduce.Job - Running job: job_local1847089440_0001
2020-05-02 19:22:16,331 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-02 19:22:16,536 INFO  crawl.Injector - Injector: overwrite: false
2020-05-02 19:22:16,536 INFO  crawl.Injector - Injector: update: false
2020-05-02 19:22:16,852 INFO  mapreduce.Job - Job job_local1847089440_0001 running in uber mode : false
2020-05-02 19:22:16,853 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:16,855 INFO  mapreduce.Job - Job job_local1847089440_0001 completed successfully
2020-05-02 19:22:16,867 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1857472
		FILE: Number of bytes written=2990868
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=824
		Map output materialized bytes=854
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=854
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=12
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1264
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 12
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-02 19:22:16,880 INFO  crawl.Injector - Injector: Total new urls injected: 12
2020-05-02 19:22:16,901 INFO  crawl.Injector - Injector: finished at 2020-05-02 19:22:16, elapsed: 00:00:02
2020-05-02 19:22:18,022 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: starting at 2020-05-02 19:22:18
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: filtering: false
2020-05-02 19:22:18,457 INFO  crawl.Generator - Generator: normalizing: true
2020-05-02 19:22:18,460 INFO  crawl.Generator - Generator: topN: 50000
2020-05-02 19:22:19,334 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:19,334 INFO  mapreduce.Job - Running job: job_local564964933_0001
2020-05-02 19:22:19,779 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:22:19,779 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:22:19,779 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:22:19,788 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-02 19:22:19,964 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-02 19:22:20,343 INFO  mapreduce.Job - Job job_local564964933_0001 running in uber mode : false
2020-05-02 19:22:20,345 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:20,346 INFO  mapreduce.Job - Job job_local564964933_0001 completed successfully
2020-05-02 19:22:20,360 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785867
		FILE: Number of bytes written=4488344
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1172
		Map output materialized bytes=211
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=211
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1022
	File Output Format Counters 
		Bytes Written=16
2020-05-02 19:22:20,360 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-02 19:22:20,365 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-02 19:22:21,366 INFO  crawl.Generator - Generator: segment: crawl/segments/20200502192221
2020-05-02 19:22:21,622 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:21,622 INFO  mapreduce.Job - Running job: job_local1171300427_0002
2020-05-02 19:22:22,626 INFO  mapreduce.Job - Job job_local1171300427_0002 running in uber mode : false
2020-05-02 19:22:22,626 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:22,627 INFO  mapreduce.Job - Job job_local1171300427_0002 completed successfully
2020-05-02 19:22:22,631 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3715576
		FILE: Number of bytes written=5985822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=1600
		Map output materialized bytes=240
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=240
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1396
	File Output Format Counters 
		Bytes Written=1278
2020-05-02 19:22:22,649 INFO  crawl.Generator - Generator: finished at 2020-05-02 19:22:22, elapsed: 00:00:04
2020-05-02 19:22:23,740 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-02 19:22:23
2020-05-02 19:22:23,741 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200502192221
2020-05-02 19:22:23,741 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588432943741  (2020-05-02 22:22:23)
2020-05-02 19:22:24,056 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:25,442 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:25,443 INFO  mapreduce.Job - Running job: job_local455603076_0001
2020-05-02 19:22:25,641 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-02 19:22:25,641 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-02 19:22:25,641 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-02 19:22:25,656 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 12 records hit by time limit : 0
2020-05-02 19:22:25,938 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:25,960 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:25,960 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:25,961 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:26,195 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-02 19:22:26,198 INFO  http.Http - http.proxy.host = null
2020-05-02 19:22:26,198 INFO  http.Http - http.proxy.port = 8080
2020-05-02 19:22:26,198 INFO  http.Http - http.proxy.exception.list = false
2020-05-02 19:22:26,198 INFO  http.Http - http.timeout = 30000
2020-05-02 19:22:26,198 INFO  http.Http - http.content.limit = -1
2020-05-02 19:22:26,198 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-02 19:22:26,198 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-02 19:22:26,198 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-02 19:22:26,198 INFO  http.Http - http.enable.cookie.header = true
2020-05-02 19:22:26,206 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,208 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,209 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,210 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,217 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,218 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,219 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,219 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,221 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,224 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,227 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,228 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,233 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,234 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,234 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,235 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,236 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,266 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,273 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,273 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,274 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,277 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,279 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,281 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,281 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,282 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,283 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,284 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,285 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,286 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,287 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,289 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,290 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,292 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,293 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,294 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,296 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,304 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,396 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,397 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,398 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,399 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,399 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,401 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,401 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,403 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,404 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,405 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,406 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,412 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,412 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,413 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,414 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,422 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,424 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,434 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,434 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,436 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,436 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,451 INFO  mapreduce.Job - Job job_local455603076_0001 running in uber mode : false
2020-05-02 19:22:26,453 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:22:26,462 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,462 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,466 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,468 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,470 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,471 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,472 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,473 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,474 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,475 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,476 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,477 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,478 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,479 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,479 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,481 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,482 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,483 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,484 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,485 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,486 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,487 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,488 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,488 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,491 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,492 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,492 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,493 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,493 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,494 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:26,495 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-02 19:22:26,496 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-02 19:22:26,496 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-02 19:22:26,496 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-02 19:22:27,503 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2020-05-02 19:22:27,752 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:28,015 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/imac-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:28,503 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-02 19:22:28,719 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:29,504 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2020-05-02 19:22:29,686 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/imac/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:30,506 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2020-05-02 19:22:30,627 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:31,479 INFO  fetcher.FetcherThread - FetcherThread 71 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:31,511 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-02 19:22:31,726 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:32,484 INFO  fetcher.FetcherThread - FetcherThread 70 fetching https://www.apple.com/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:32,511 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:22:32,511 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422152473
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   now           = 1588422152512
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:32,512 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:33,516 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422152473
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   now           = 1588422153517
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:33,517 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:33,701 INFO  fetcher.FetcherThread - FetcherThread 70 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:34,519 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-02 19:22:34,519 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:34,519 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:34,519 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422153701
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   now           = 1588422154520
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:34,520 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:34,926 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:35,522 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588422154829
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   now           = 1588422155523
2020-05-02 19:22:35,523 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:35,853 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-02 19:22:35,928 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-02 19:22:35,928 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=49
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=48
2020-05-02 19:22:35,929 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:22:35,930 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=46
2020-05-02 19:22:35,933 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-02 19:22:35,933 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=45
2020-05-02 19:22:35,947 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-02 19:22:35,947 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-02 19:22:35,947 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:22:35,948 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=43
2020-05-02 19:22:35,948 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-02 19:22:35,948 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=42
2020-05-02 19:22:35,954 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-02 19:22:35,954 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=41
2020-05-02 19:22:35,957 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-02 19:22:35,957 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=40
2020-05-02 19:22:35,988 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-02 19:22:35,989 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=39
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=37
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=36
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=35
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=34
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=38
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-02 19:22:36,005 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=33
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-02 19:22:36,004 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-02 19:22:36,007 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:22:36,007 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=31
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=30
2020-05-02 19:22:36,015 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-02 19:22:36,024 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=28
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-02 19:22:36,026 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=27
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-02 19:22:36,027 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=25
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-02 19:22:36,028 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=24
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-02 19:22:36,028 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=23
2020-05-02 19:22:36,016 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=29
2020-05-02 19:22:36,027 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=26
2020-05-02 19:22:36,019 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-02 19:22:36,030 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=22
2020-05-02 19:22:36,135 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-02 19:22:36,135 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=21
2020-05-02 19:22:36,231 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-02 19:22:36,231 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-02 19:22:36,232 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=20
2020-05-02 19:22:36,232 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=19
2020-05-02 19:22:36,252 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=18
2020-05-02 19:22:36,252 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=16
2020-05-02 19:22:36,253 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=17
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=15
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-02 19:22:36,267 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=14
2020-05-02 19:22:36,266 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-02 19:22:36,267 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=13
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-02 19:22:36,297 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=12
2020-05-02 19:22:36,298 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=10
2020-05-02 19:22:36,298 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=11
2020-05-02 19:22:36,318 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-02 19:22:36,318 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=9
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=8
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=7
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=6
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=5
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=4
2020-05-02 19:22:36,319 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=3
2020-05-02 19:22:36,328 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-02 19:22:36,328 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=2
2020-05-02 19:22:36,333 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-02 19:22:36,333 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=1
2020-05-02 19:22:36,525 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-02 19:22:36,875 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-02 19:22:36,875 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=0
2020-05-02 19:22:37,529 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-02 19:22:37,530 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-02 19:22:38,487 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:38,488 INFO  mapreduce.Job - Job job_local455603076_0001 completed successfully
2020-05-02 19:22:38,509 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3319141
		FILE: Number of bytes written=5652685
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=24
		Map output bytes=1358472
		Map output materialized bytes=213415
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=213415
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=105
		Total committed heap usage (bytes)=968884224
	FetcherStatus
		bytes_downloaded=1346765
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1278
	File Output Format Counters 
		Bytes Written=221699
2020-05-02 19:22:38,510 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-02 19:22:38, elapsed: 00:00:14
2020-05-02 19:22:39,997 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:40,440 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:22:40
2020-05-02 19:22:40,440 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-02 19:22:41,393 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:41,394 INFO  mapreduce.Job - Running job: job_local851368484_0001
2020-05-02 19:22:42,405 INFO  mapreduce.Job - Job job_local851368484_0001 running in uber mode : false
2020-05-02 19:22:42,406 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:22:42,845 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:22:42,859 INFO  parse.ParseSegment - Parsed (1006ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:22:42,986 INFO  parse.ParseSegment - Parsed (119ms):https://www.apple.com/imac/specs/
2020-05-02 19:22:43,078 INFO  parse.ParseSegment - Parsed (87ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:22:43,161 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:22:43,235 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:22:43,332 INFO  parse.ParseSegment - Parsed (77ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:22:43,414 INFO  parse.ParseSegment - Parsed (78ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:22:43,489 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:22:43,572 INFO  parse.ParseSegment - Parsed (81ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:22:43,768 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:22:43,769 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:22:43,823 INFO  parse.ParseSegment - Parsed (51ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:22:43,903 INFO  parse.ParseSegment - Parsed (78ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:22:44,053 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:44,197 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:22:44,324 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:22:44,409 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-02 19:22:44,415 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:22:45,412 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:45,414 INFO  mapreduce.Job - Job job_local851368484_0001 completed successfully
2020-05-02 19:22:45,435 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4790970
		FILE: Number of bytes written=6750209
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=464496
		Map output materialized bytes=104407
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=104407
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=94
		Total committed heap usage (bytes)=1539833856
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:22:45,450 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:22:45, elapsed: 00:00:04
2020-05-02 19:22:46,810 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:47,355 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-02 19:22:47
2020-05-02 19:22:47,355 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-02 19:22:47,357 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200502192221]
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-02 19:22:47,358 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-02 19:22:47,362 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-02 19:22:48,364 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:48,365 INFO  mapreduce.Job - Running job: job_local859927944_0001
2020-05-02 19:22:49,376 INFO  mapreduce.Job - Job job_local859927944_0001 running in uber mode : false
2020-05-02 19:22:49,378 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:22:49,628 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:22:49,628 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:22:49,629 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:22:49,733 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-02 19:22:49,733 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-02 19:22:49,733 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-02 19:22:50,382 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:50,383 INFO  mapreduce.Job - Job job_local859927944_0001 completed successfully
2020-05-02 19:22:50,402 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=7185550
		FILE: Number of bytes written=10595485
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1236
		Map output records=1236
		Map output bytes=90629
		Map output materialized bytes=7088
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=7088
		Reduce input records=1236
		Reduce output records=798
		Spilled Records=2472
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=12
		db_unfetched=786
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=97550
	File Output Format Counters 
		Bytes Written=67516
2020-05-02 19:22:50,419 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-02 19:22:50, elapsed: 00:00:03
2020-05-02 19:22:51,852 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:52,297 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-02 19:22:52
2020-05-02 19:22:52,297 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-02 19:22:52,298 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-02 19:22:52,298 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-02 19:22:52,298 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-02 19:22:52,299 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200502192221
2020-05-02 19:22:53,277 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:53,278 INFO  mapreduce.Job - Running job: job_local496578145_0001
2020-05-02 19:22:54,288 INFO  mapreduce.Job - Job job_local496578145_0001 running in uber mode : false
2020-05-02 19:22:54,289 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:54,290 INFO  mapreduce.Job - Job job_local496578145_0001 completed successfully
2020-05-02 19:22:54,303 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2899796
		FILE: Number of bytes written=4476139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=332
		Combine input records=7
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=40360
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:22:54,304 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-02 19:22:54,616 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:54,616 INFO  mapreduce.Job - Running job: job_local1738814066_0002
2020-05-02 19:22:54,951 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 19:22:55,031 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-02 19:22:55,618 INFO  mapreduce.Job - Job job_local1738814066_0002 running in uber mode : false
2020-05-02 19:22:55,619 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:55,619 INFO  mapreduce.Job - Job job_local1738814066_0002 completed successfully
2020-05-02 19:22:55,624 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5698749
		FILE: Number of bytes written=8966965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=1300
		Map output materialized bytes=1340
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1340
		Reduce input records=14
		Reduce output records=7
		Spilled Records=28
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1758
	File Output Format Counters 
		Bytes Written=1109
2020-05-02 19:22:55,642 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-02 19:22:55, elapsed: 00:00:03
2020-05-02 19:22:56,674 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-02 19:22:56
2020-05-02 19:22:56,937 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:22:58,218 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:58,219 INFO  mapreduce.Job - Running job: job_local536792027_0001
2020-05-02 19:22:59,226 INFO  mapreduce.Job - Job job_local536792027_0001 running in uber mode : false
2020-05-02 19:22:59,228 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:22:59,229 INFO  mapreduce.Job - Job job_local536792027_0001 completed successfully
2020-05-02 19:22:59,256 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2956832
		FILE: Number of bytes written=4486488
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=12
		Map output bytes=3164
		Map output materialized bytes=3212
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=3212
		Reduce input records=12
		Reduce output records=0
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66898
	File Output Format Counters 
		Bytes Written=98
2020-05-02 19:22:59,263 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-02 19:22:59,263 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-02 19:22:59,602 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:22:59,602 INFO  mapreduce.Job - Running job: job_local1227513023_0002
2020-05-02 19:23:00,603 INFO  mapreduce.Job - Job job_local1227513023_0002 running in uber mode : false
2020-05-02 19:23:00,603 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:23:00,603 INFO  mapreduce.Job - Job job_local1227513023_0002 completed successfully
2020-05-02 19:23:00,608 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8073409
		FILE: Number of bytes written=12308217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=798
		Map output bytes=59182
		Map output materialized bytes=60808
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=60808
		Reduce input records=798
		Reduce output records=798
		Spilled Records=1596
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66996
	File Output Format Counters 
		Bytes Written=67156
2020-05-02 19:23:00,629 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-02 19:23:00, elapsed: 00:00:03
2020-05-02 19:23:01,769 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:23:02,199 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-02 19:23:02,203 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:23:02
2020-05-02 19:23:02,218 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-02 19:23:02,218 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-02 19:23:02,218 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-02 19:23:02,220 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:23:02,220 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:23:02,220 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-02 19:23:03,161 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:23:03,162 INFO  mapreduce.Job - Running job: job_local302354623_0001
2020-05-02 19:23:04,201 INFO  mapreduce.Job - Job job_local302354623_0001 running in uber mode : false
2020-05-02 19:23:04,204 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:23:05,047 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:23:05,108 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:23:05,490 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:23:06,331 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:23:06,332 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:23:07,212 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:23:07,213 INFO  mapreduce.Job - Job job_local302354623_0001 completed successfully
2020-05-02 19:23:07,255 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13885539
		FILE: Number of bytes written=21206670
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2053
		Map output records=2053
		Map output bytes=492868
		Map output materialized bytes=497106
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=497106
		Reduce input records=2053
		Reduce output records=12
		Spilled Records=4106
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=240
		Total committed heap usage (bytes)=4899471360
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=286341
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:23:07,255 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:23:07,269 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:23:07,302 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:23:07, elapsed: 00:00:05
2020-05-02 19:23:08,411 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-02 19:23:08
2020-05-02 19:23:08,662 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:23:09,878 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:23:09,879 INFO  mapreduce.Job - Running job: job_local1906528864_0001
2020-05-02 19:23:10,679 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:23:10,718 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:23:10,885 INFO  mapreduce.Job - Job job_local1906528864_0001 running in uber mode : false
2020-05-02 19:23:10,887 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:23:11,528 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-02 19:23:11,888 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:23:11,889 INFO  mapreduce.Job - Job job_local1906528864_0001 completed successfully
2020-05-02 19:23:11,910 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1988196
		FILE: Number of bytes written=2985838
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=798
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=479199232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=66820
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:23:11,929 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-02 19:23:11, elapsed: 00:00:03
2020-05-02 19:35:56,885 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:35:57,647 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-02 19:35:57
2020-05-02 19:35:57,648 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-02 19:36:00,087 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:36:00,088 INFO  mapreduce.Job - Running job: job_local643155353_0001
2020-05-02 19:36:01,152 INFO  mapreduce.Job - Job job_local643155353_0001 running in uber mode : false
2020-05-02 19:36:01,153 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-02 19:36:01,576 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-02 19:36:01,820 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/imac-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:01,824 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:36:01,832 INFO  parse.ParseSegment - Parsed (1066ms):https://www.apple.com/imac-pro/specs/
2020-05-02 19:36:01,912 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/imac/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:01,913 INFO  parse.ParseSegment - Parsed (73ms):https://www.apple.com/imac/specs/
2020-05-02 19:36:01,989 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-mini/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:01,990 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/ipad-mini/specs/
2020-05-02 19:36:02,065 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,066 INFO  parse.ParseSegment - Parsed (73ms):https://www.apple.com/ipad-pro/specs/
2020-05-02 19:36:02,140 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,141 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-02 19:36:02,210 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,211 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/iphone-11/specs/
2020-05-02 19:36:02,274 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,274 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-se/specs/
2020-05-02 19:36:02,315 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,316 INFO  parse.ParseSegment - Parsed (40ms):https://www.apple.com/iphone-xr/specs/
2020-05-02 19:36:02,366 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-16/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,367 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-02 19:36:02,520 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-air/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,520 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-02 19:36:02,521 INFO  parse.ParseSegment - Parsed (29ms):https://www.apple.com/ipad-air/specs/
2020-05-02 19:36:02,547 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-air/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,548 INFO  parse.ParseSegment - Parsed (23ms):https://www.apple.com/macbook-air/specs/
2020-05-02 19:36:02,595 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-13/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-02 19:36:02,596 INFO  parse.ParseSegment - Parsed (46ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-02 19:36:02,720 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-02 19:36:02,845 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-02 19:36:03,160 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:36:03,161 INFO  mapreduce.Job - Job job_local643155353_0001 completed successfully
2020-05-02 19:36:03,176 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4191715
		FILE: Number of bytes written=6178701
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=404111
		Map output materialized bytes=404171
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=404171
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=102
		Total committed heap usage (bytes)=1089994752
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:36:03,192 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-02 19:36:03, elapsed: 00:00:05
2020-05-02 19:36:04,217 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-02 19:36:04,610 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-02 19:36:04,623 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-02 19:36:04
2020-05-02 19:36:04,638 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-02 19:36:04,640 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-02 19:36:04,640 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-02 19:36:04,643 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-02 19:36:04,643 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-02 19:36:04,643 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-02 19:36:05,580 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-02 19:36:05,581 INFO  mapreduce.Job - Running job: job_local1084918957_0001
2020-05-02 19:36:06,047 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:06,443 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:06,587 INFO  mapreduce.Job - Job job_local1084918957_0001 running in uber mode : false
2020-05-02 19:36:06,588 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-02 19:36:06,632 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,037 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,153 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,277 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,383 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,437 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,484 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-02 19:36:07,629 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-02 19:36:07,660 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-02 19:36:08,148 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-02 19:36:08,796 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-02 19:36:08,826 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,841 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,841 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,843 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,851 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,854 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,855 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,862 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,949 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,962 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,963 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,964 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-02 19:36:08,967 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-02 19:36:08,967 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-02 19:36:09,600 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-02 19:36:09,601 INFO  mapreduce.Job - Job job_local1084918957_0001 completed successfully
2020-05-02 19:36:09,623 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13697135
		FILE: Number of bytes written=21141296
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=703633
		Map output materialized bytes=707937
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=707937
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=186
		Total committed heap usage (bytes)=6194987008
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=358083
	File Output Format Counters 
		Bytes Written=0
2020-05-02 19:36:09,623 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-02 19:36:09,631 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-02 19:36:09,650 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-02 19:36:09, elapsed: 00:00:05
