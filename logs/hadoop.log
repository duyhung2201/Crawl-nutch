2020-05-03 20:34:00,819 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:34:01,249 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 20:34:01
2020-05-03 20:34:01,250 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-03 20:34:02,347 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:34:02,348 INFO  mapreduce.Job - Running job: job_local110831534_0001
2020-05-03 20:34:03,359 INFO  mapreduce.Job - Job job_local110831534_0001 running in uber mode : false
2020-05-03 20:34:03,361 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 20:34:03,492 ERROR nutch.ExtractorParseFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.setConf(ExtractorParseFilter.java:102)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.parse.HtmlParseFilters.<init>(HtmlParseFilters.java:34)
	at org.apache.nutch.parse.html.HtmlParser.setConf(HtmlParser.java:364)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:126)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:270)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 24 more
2020-05-03 20:34:03,708 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/imac-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:03,712 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:34:03,720 INFO  parse.ParseSegment - Parsed (863ms):https://www.apple.com/imac-pro/specs/
2020-05-03 20:34:03,801 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/imac/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:03,802 INFO  parse.ParseSegment - Parsed (77ms):https://www.apple.com/imac/specs/
2020-05-03 20:34:03,867 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-mini/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:03,868 INFO  parse.ParseSegment - Parsed (63ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 20:34:03,941 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:03,942 INFO  parse.ParseSegment - Parsed (71ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 20:34:04,000 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11-pro/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,001 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 20:34:04,057 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-11/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,058 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/iphone-11/specs/
2020-05-03 20:34:04,123 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-se/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,124 INFO  parse.ParseSegment - Parsed (62ms):https://www.apple.com/iphone-se/specs/
2020-05-03 20:34:04,156 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/iphone-xr/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,157 INFO  parse.ParseSegment - Parsed (31ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 20:34:04,225 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-16/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,226 INFO  parse.ParseSegment - Parsed (66ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 20:34:04,363 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 20:34:04,395 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/ipad-air/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,395 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:34:04,396 INFO  parse.ParseSegment - Parsed (34ms):https://www.apple.com/ipad-air/specs/
2020-05-03 20:34:04,438 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-air/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,438 INFO  parse.ParseSegment - Parsed (34ms):https://www.apple.com/macbook-air/specs/
2020-05-03 20:34:04,480 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-13/specs/
java.lang.NullPointerException
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.findMatchingDocs(ExtractEngine.java:155)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:96)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 20:34:04,481 INFO  parse.ParseSegment - Parsed (41ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 20:34:04,593 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 20:34:04,714 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 20:34:05,366 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:34:05,367 INFO  mapreduce.Job - Job job_local110831534_0001 completed successfully
2020-05-03 20:34:05,385 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4191715
		FILE: Number of bytes written=6178684
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=404111
		Map output materialized bytes=404171
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=404171
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=81
		Total committed heap usage (bytes)=1093140480
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:34:05,401 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 20:34:05, elapsed: 00:00:04
2020-05-03 20:34:06,417 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:34:06,773 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-03 20:34:06,777 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 20:34:06
2020-05-03 20:34:06,793 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 20:34:06,793 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 20:34:06,794 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 20:34:06,797 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 20:34:06,797 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 20:34:06,798 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-03 20:34:07,700 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:34:07,701 INFO  mapreduce.Job - Running job: job_local1629283320_0001
2020-05-03 20:34:08,174 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:08,618 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:08,707 INFO  mapreduce.Job - Job job_local1629283320_0001 running in uber mode : false
2020-05-03 20:34:08,708 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 20:34:08,751 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:08,957 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:09,045 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:09,159 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:09,240 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:09,285 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:09,322 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:34:09,434 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 20:34:09,466 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 20:34:09,864 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 20:34:10,583 ERROR nutch.ExtractorIndexingFilter - 
javax.xml.bind.UnmarshalException
 - with linked exception:
[org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.]
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.createUnmarshalException(AbstractUnmarshallerImpl.java:335)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.createUnmarshalException(UnmarshallerImpl.java:523)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:189)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:157)
	at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:214)
	at ir.co.bayan.simorq.zal.extractor.model.ExtractorConfig.readConfig(ExtractorConfig.java:109)
	at ir.co.bayan.simorq.zal.extractor.nutch.NutchUtils.config(NutchUtils.java:30)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.initConfig(ExtractorIndexingFilter.java:52)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorIndexingFilter.setConf(ExtractorIndexingFilter.java:45)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.plugin.PluginRepository.getOrderedPlugins(PluginRepository.java:442)
	at org.apache.nutch.indexer.IndexingFilters.<init>(IndexingFilters.java:35)
	at org.apache.nutch.indexer.IndexerMapReduce$IndexerReducer.setup(IndexerMapReduce.java:200)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:168)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:346)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.xml.sax.SAXParseException; lineNumber: 618; columnNumber: 72; cvc-complex-type.2.4.d: Invalid content was found starting with element 'document'. No child element is expected at this point.
	at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)
	at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source)
	at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source)
	at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:101)
	at com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:152)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:216)
	... 20 more
2020-05-03 20:34:10,608 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,615 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,616 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,617 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,618 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,619 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,621 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,622 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,624 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,630 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,630 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,631 WARN  nutch.ExtractorIndexingFilter - Extractor config is not loaded.
2020-05-03 20:34:10,634 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-03 20:34:10,635 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 20:34:11,717 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:34:11,718 INFO  mapreduce.Job - Job job_local1629283320_0001 completed successfully
2020-05-03 20:34:11,740 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13696965
		FILE: Number of bytes written=21141276
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=703633
		Map output materialized bytes=707937
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=707937
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=162
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=358066
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:34:11,740 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 20:34:11,751 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-03 20:34:11,780 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 20:34:11, elapsed: 00:00:04
2020-05-03 20:37:42,439 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:37:42,779 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 20:37:42
2020-05-03 20:37:42,780 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-03 20:37:43,757 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:37:43,757 INFO  mapreduce.Job - Running job: job_local310930749_0001
2020-05-03 20:37:44,768 INFO  mapreduce.Job - Job job_local310930749_0001 running in uber mode : false
2020-05-03 20:37:44,769 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 20:37:45,019 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:37:45,027 INFO  parse.ParseSegment - Parsed (799ms):https://www.apple.com/imac-pro/specs/
2020-05-03 20:37:45,117 INFO  parse.ParseSegment - Parsed (85ms):https://www.apple.com/imac/specs/
2020-05-03 20:37:45,183 INFO  parse.ParseSegment - Parsed (63ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 20:37:45,239 INFO  parse.ParseSegment - Parsed (54ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 20:37:45,301 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 20:37:45,561 INFO  parse.ParseSegment - Parsed (258ms):https://www.apple.com/iphone-11/specs/
2020-05-03 20:37:45,610 INFO  parse.ParseSegment - Parsed (48ms):https://www.apple.com/iphone-se/specs/
2020-05-03 20:37:45,708 INFO  parse.ParseSegment - Parsed (96ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 20:37:45,766 INFO  parse.ParseSegment - Parsed (56ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 20:37:45,907 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:37:45,908 INFO  parse.ParseSegment - Parsed (47ms):https://www.apple.com/ipad-air/specs/
2020-05-03 20:37:45,952 INFO  parse.ParseSegment - Parsed (42ms):https://www.apple.com/macbook-air/specs/
2020-05-03 20:37:45,997 INFO  parse.ParseSegment - Parsed (44ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 20:37:46,121 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 20:37:46,244 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 20:37:46,780 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:37:46,781 INFO  mapreduce.Job - Job job_local310930749_0001 completed successfully
2020-05-03 20:37:46,795 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4207379
		FILE: Number of bytes written=6213742
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=411943
		Map output materialized bytes=412003
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=412003
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=1171783680
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:37:46,807 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 20:37:46, elapsed: 00:00:04
2020-05-03 20:37:47,793 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:37:48,152 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-03 20:37:48,155 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 20:37:48
2020-05-03 20:37:48,181 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 20:37:48,181 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 20:37:48,181 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 20:37:48,182 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 20:37:48,182 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 20:37:48,182 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-03 20:37:48,975 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:37:48,976 INFO  mapreduce.Job - Running job: job_local732415208_0001
2020-05-03 20:37:49,473 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:49,864 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:49,951 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:49,985 INFO  mapreduce.Job - Job job_local732415208_0001 running in uber mode : false
2020-05-03 20:37:49,986 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 20:37:50,105 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:50,179 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:50,298 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:50,386 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:50,433 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:50,470 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:37:50,592 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 20:37:50,619 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 20:37:51,028 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 20:37:51,641 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-03 20:37:51,647 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 20:37:51,992 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:37:52,998 INFO  mapreduce.Job - Job job_local732415208_0001 completed successfully
2020-05-03 20:37:53,024 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13731319
		FILE: Number of bytes written=21160948
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=711465
		Map output materialized bytes=715769
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=715769
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=155
		Total committed heap usage (bytes)=6191841280
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=361796
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:37:53,024 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 20:37:53,032 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-03 20:37:53,052 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 20:37:53, elapsed: 00:00:04
2020-05-03 20:47:43,296 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:47:43,754 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 20:47:43
2020-05-03 20:47:43,754 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-03 20:47:45,383 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:47:45,385 INFO  mapreduce.Job - Running job: job_local413103028_0001
2020-05-03 20:47:46,393 INFO  mapreduce.Job - Job job_local413103028_0001 running in uber mode : false
2020-05-03 20:47:46,396 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 20:47:47,075 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:47:47,083 INFO  parse.ParseSegment - Parsed (1173ms):https://www.apple.com/imac-pro/specs/
2020-05-03 20:47:47,166 INFO  parse.ParseSegment - Parsed (77ms):https://www.apple.com/imac/specs/
2020-05-03 20:47:47,228 INFO  parse.ParseSegment - Parsed (58ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 20:47:47,302 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 20:47:47,596 INFO  parse.ParseSegment - Parsed (292ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 20:47:47,651 INFO  parse.ParseSegment - Parsed (53ms):https://www.apple.com/iphone-11/specs/
2020-05-03 20:47:47,705 INFO  parse.ParseSegment - Parsed (52ms):https://www.apple.com/iphone-se/specs/
2020-05-03 20:47:47,806 INFO  parse.ParseSegment - Parsed (99ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 20:47:47,874 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 20:47:48,037 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:47:48,037 INFO  parse.ParseSegment - Parsed (32ms):https://www.apple.com/ipad-air/specs/
2020-05-03 20:47:48,066 INFO  parse.ParseSegment - Parsed (27ms):https://www.apple.com/macbook-air/specs/
2020-05-03 20:47:48,111 INFO  parse.ParseSegment - Parsed (44ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 20:47:48,249 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 20:47:48,353 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 20:47:48,405 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 20:47:49,407 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:47:49,409 INFO  mapreduce.Job - Job job_local413103028_0001 completed successfully
2020-05-03 20:47:49,432 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4207711
		FILE: Number of bytes written=6214494
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=412109
		Map output materialized bytes=412169
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=412169
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=98
		Total committed heap usage (bytes)=1162870784
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:47:49,445 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 20:47:49, elapsed: 00:00:05
2020-05-03 20:47:50,497 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:47:50,838 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-03 20:47:50,841 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 20:47:50
2020-05-03 20:47:50,857 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 20:47:50,857 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 20:47:50,857 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 20:47:50,859 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 20:47:50,859 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 20:47:50,859 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-03 20:47:51,680 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:47:51,681 INFO  mapreduce.Job - Running job: job_local562727315_0001
2020-05-03 20:47:52,149 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:52,562 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:52,643 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:52,691 INFO  mapreduce.Job - Job job_local562727315_0001 running in uber mode : false
2020-05-03 20:47:52,693 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 20:47:52,809 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:52,908 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:53,010 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:53,093 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:53,139 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:53,177 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:47:53,282 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 20:47:53,312 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 20:47:53,760 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 20:47:54,352 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-03 20:47:54,364 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 20:47:54,698 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:47:54,699 INFO  mapreduce.Job - Job job_local562727315_0001 completed successfully
2020-05-03 20:47:54,721 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13732151
		FILE: Number of bytes written=21161964
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=711631
		Map output materialized bytes=715935
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=715935
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=172
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=361884
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:47:54,721 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 20:47:54,726 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-03 20:47:54,754 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 20:47:54, elapsed: 00:00:03
2020-05-03 20:49:51,146 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:49:51,489 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 20:49:51
2020-05-03 20:49:51,489 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-03 20:49:52,398 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:49:52,399 INFO  mapreduce.Job - Running job: job_local2002420599_0001
2020-05-03 20:49:53,404 INFO  mapreduce.Job - Job job_local2002420599_0001 running in uber mode : false
2020-05-03 20:49:53,406 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 20:49:53,658 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:49:53,669 INFO  parse.ParseSegment - Parsed (844ms):https://www.apple.com/imac-pro/specs/
2020-05-03 20:49:53,746 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/imac/specs/
2020-05-03 20:49:53,810 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 20:49:53,873 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 20:49:54,115 INFO  parse.ParseSegment - Parsed (239ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 20:49:54,167 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/iphone-11/specs/
2020-05-03 20:49:54,217 INFO  parse.ParseSegment - Parsed (48ms):https://www.apple.com/iphone-se/specs/
2020-05-03 20:49:54,309 INFO  parse.ParseSegment - Parsed (90ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 20:49:54,371 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 20:49:54,413 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 20:49:54,524 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 20:49:54,525 INFO  parse.ParseSegment - Parsed (39ms):https://www.apple.com/ipad-air/specs/
2020-05-03 20:49:54,558 INFO  parse.ParseSegment - Parsed (32ms):https://www.apple.com/macbook-air/specs/
2020-05-03 20:49:54,606 INFO  parse.ParseSegment - Parsed (46ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 20:49:54,728 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 20:49:54,845 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 20:49:55,419 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:49:55,420 INFO  mapreduce.Job - Job job_local2002420599_0001 completed successfully
2020-05-03 20:49:55,441 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4207709
		FILE: Number of bytes written=6222641
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=412108
		Map output materialized bytes=412168
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=412168
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:49:55,454 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 20:49:55, elapsed: 00:00:03
2020-05-03 20:49:56,437 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 20:49:56,799 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-03 20:49:56,802 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 20:49:56
2020-05-03 20:49:56,816 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 20:49:56,816 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 20:49:56,817 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 20:49:56,818 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 20:49:56,818 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 20:49:56,819 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-03 20:49:57,660 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 20:49:57,661 INFO  mapreduce.Job - Running job: job_local446174374_0001
2020-05-03 20:49:58,121 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:58,552 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:58,636 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:58,667 INFO  mapreduce.Job - Job job_local446174374_0001 running in uber mode : false
2020-05-03 20:49:58,668 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 20:49:58,794 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:58,873 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:58,969 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:59,039 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:59,142 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:59,269 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 20:49:59,428 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 20:49:59,452 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 20:49:59,845 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 20:50:00,441 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-03 20:50:00,442 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 20:50:01,687 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 20:50:01,687 INFO  mapreduce.Job - Job job_local446174374_0001 completed successfully
2020-05-03 20:50:01,709 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13731939
		FILE: Number of bytes written=21161938
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=711630
		Map output materialized bytes=715934
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=715934
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=164
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=361863
	File Output Format Counters 
		Bytes Written=0
2020-05-03 20:50:01,709 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 20:50:01,716 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-03 20:50:01,747 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 20:50:01, elapsed: 00:00:04
2020-05-03 21:00:53,386 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:00:53,873 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:00:53
2020-05-03 21:00:53,875 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-03 21:00:55,331 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:00:55,333 INFO  mapreduce.Job - Running job: job_local1594838718_0001
2020-05-03 21:00:56,345 INFO  mapreduce.Job - Job job_local1594838718_0001 running in uber mode : false
2020-05-03 21:00:56,346 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:00:57,014 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:00:57,022 INFO  parse.ParseSegment - Parsed (1082ms):https://www.apple.com/imac-pro/specs/
2020-05-03 21:00:57,113 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/imac/specs/
2020-05-03 21:00:57,221 INFO  parse.ParseSegment - Parsed (104ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:00:57,292 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:00:57,368 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:00:57,408 INFO  parse.ParseSegment - Parsed (38ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:00:57,454 INFO  parse.ParseSegment - Parsed (44ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:00:57,723 INFO  parse.ParseSegment - Parsed (266ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:00:57,781 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:00:58,020 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:00:58,021 INFO  parse.ParseSegment - Parsed (37ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:00:58,052 INFO  parse.ParseSegment - Parsed (29ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:00:58,092 INFO  parse.ParseSegment - Parsed (39ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:00:58,226 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:00:58,350 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:00:58,373 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:00:59,355 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:00:59,357 INFO  mapreduce.Job - Job job_local1594838718_0001 completed successfully
2020-05-03 21:00:59,375 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205255
		FILE: Number of bytes written=6217052
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410881
		Map output materialized bytes=410941
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410941
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=94
		Total committed heap usage (bytes)=1162870784
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:00:59,390 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:00:59, elapsed: 00:00:05
2020-05-03 21:01:00,449 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:01:00,811 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-03 21:01:00,813 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:01:00
2020-05-03 21:01:00,825 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 21:01:00,825 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 21:01:00,825 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 21:01:00,827 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:01:00,827 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:01:00,827 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-03 21:01:01,696 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:01:01,698 INFO  mapreduce.Job - Running job: job_local1279676545_0001
2020-05-03 21:01:02,219 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:02,626 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:02,712 INFO  mapreduce.Job - Job job_local1279676545_0001 running in uber mode : false
2020-05-03 21:01:02,714 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:01:02,754 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:02,921 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:03,014 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:03,127 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:03,216 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:03,258 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:03,292 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:01:03,406 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:01:03,435 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:01:03,834 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:01:04,360 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-03 21:01:04,360 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:01:04,717 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:01:04,718 INFO  mapreduce.Job - Job job_local1279676545_0001 completed successfully
2020-05-03 21:01:04,742 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13726125
		FILE: Number of bytes written=21181916
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=710403
		Map output materialized bytes=714707
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=714707
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=156
		Total committed heap usage (bytes)=6192365568
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=361182
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:01:04,744 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:01:04,750 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-03 21:01:04,768 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:01:04, elapsed: 00:00:03
2020-05-03 21:02:35,298 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:02:35,653 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:02:35
2020-05-03 21:02:35,653 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-03 21:02:36,462 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:02:36,463 INFO  mapreduce.Job - Running job: job_local2122922106_0001
2020-05-03 21:02:37,470 INFO  mapreduce.Job - Job job_local2122922106_0001 running in uber mode : false
2020-05-03 21:02:37,471 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:02:37,691 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:02:37,701 INFO  parse.ParseSegment - Parsed (771ms):https://www.apple.com/imac-pro/specs/
2020-05-03 21:02:37,779 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/imac/specs/
2020-05-03 21:02:37,838 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:02:37,896 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:02:37,954 INFO  parse.ParseSegment - Parsed (56ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:02:38,017 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:02:38,077 INFO  parse.ParseSegment - Parsed (58ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:02:38,303 INFO  parse.ParseSegment - Parsed (224ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:02:38,373 INFO  parse.ParseSegment - Parsed (67ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:02:38,473 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:02:38,505 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:02:38,505 INFO  parse.ParseSegment - Parsed (34ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:02:38,535 INFO  parse.ParseSegment - Parsed (28ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:02:38,580 INFO  parse.ParseSegment - Parsed (43ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:02:38,695 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:02:38,808 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:02:39,475 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:02:39,476 INFO  mapreduce.Job - Job job_local2122922106_0001 completed successfully
2020-05-03 21:02:39,491 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205255
		FILE: Number of bytes written=6217060
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410881
		Map output materialized bytes=410941
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410941
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=79
		Total committed heap usage (bytes)=1167589376
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:02:39,503 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:02:39, elapsed: 00:00:03
2020-05-03 21:02:40,485 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:02:40,888 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-03 21:02:40,892 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:02:40
2020-05-03 21:02:40,924 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 21:02:40,924 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 21:02:40,926 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 21:02:40,928 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:02:40,928 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:02:40,928 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-03 21:02:41,920 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:02:41,921 INFO  mapreduce.Job - Running job: job_local704709472_0001
2020-05-03 21:02:42,465 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:42,880 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:42,930 INFO  mapreduce.Job - Job job_local704709472_0001 running in uber mode : false
2020-05-03 21:02:42,931 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:02:42,962 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:43,141 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:43,238 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:43,327 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:43,400 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:43,444 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:43,486 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:02:43,601 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:02:43,631 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:02:44,082 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:02:44,744 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-03 21:02:44,746 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:02:45,939 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:02:45,941 INFO  mapreduce.Job - Job job_local704709472_0001 completed successfully
2020-05-03 21:02:45,982 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13726205
		FILE: Number of bytes written=21154576
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=710403
		Map output materialized bytes=714707
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=714707
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=158
		Total committed heap usage (bytes)=6192889856
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=361190
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:02:45,982 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:02:45,993 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-03 21:02:46,026 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:02:45, elapsed: 00:00:05
2020-05-03 21:03:51,075 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:03:51,416 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:03:51
2020-05-03 21:03:51,416 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200502192221
2020-05-03 21:03:52,385 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:03:52,386 INFO  mapreduce.Job - Running job: job_local906578223_0001
2020-05-03 21:03:53,392 INFO  mapreduce.Job - Job job_local906578223_0001 running in uber mode : false
2020-05-03 21:03:53,393 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:03:53,616 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:03:53,624 INFO  parse.ParseSegment - Parsed (794ms):https://www.apple.com/imac-pro/specs/
2020-05-03 21:03:53,707 INFO  parse.ParseSegment - Parsed (77ms):https://www.apple.com/imac/specs/
2020-05-03 21:03:53,771 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:03:53,838 INFO  parse.ParseSegment - Parsed (64ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:03:53,894 INFO  parse.ParseSegment - Parsed (54ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:03:53,957 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:03:54,013 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:03:54,234 INFO  parse.ParseSegment - Parsed (219ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:03:54,307 INFO  parse.ParseSegment - Parsed (71ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:03:54,397 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:03:54,444 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:03:54,445 INFO  parse.ParseSegment - Parsed (36ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:03:54,480 INFO  parse.ParseSegment - Parsed (33ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:03:54,523 INFO  parse.ParseSegment - Parsed (42ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:03:54,650 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:03:54,767 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:03:55,398 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:03:55,399 INFO  mapreduce.Job - Job job_local906578223_0001 completed successfully
2020-05-03 21:03:55,412 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4205255
		FILE: Number of bytes written=6208884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Map output bytes=410881
		Map output materialized bytes=410941
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=410941
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=78
		Total committed heap usage (bytes)=1171783680
	ParserStatus
		success=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=217979
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:03:55,425 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:03:55, elapsed: 00:00:04
2020-05-03 21:03:56,421 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:03:56,820 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-03 21:03:56
2020-05-03 21:03:56,821 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-03 21:03:56,821 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-03 21:03:56,821 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-03 21:03:56,821 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-03 21:03:56,821 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502190710
2020-05-03 21:03:56,822 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502192221
2020-05-03 21:03:56,823 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502180859
2020-05-03 21:03:56,823 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502190938
2020-05-03 21:03:57,655 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:03:57,656 INFO  mapreduce.Job - Running job: job_local443550480_0001
2020-05-03 21:03:58,665 INFO  mapreduce.Job - Job job_local443550480_0001 running in uber mode : false
2020-05-03 21:03:58,666 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:03:58,667 INFO  mapreduce.Job - Job job_local443550480_0001 completed successfully
2020-05-03 21:03:58,695 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=9417218
		FILE: Number of bytes written=13455131
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=58
		Map output records=28
		Map output bytes=2600
		Map output materialized bytes=2704
		Input split bytes=1328
		Combine input records=28
		Combine output records=28
		Reduce input groups=7
		Reduce shuffle bytes=2704
		Reduce input records=28
		Reduce output records=7
		Spilled Records=56
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=110
		Total committed heap usage (bytes)=4003987456
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146947
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:03:58,695 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-03 21:03:59,079 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:03:59,080 INFO  mapreduce.Job - Running job: job_local1851058655_0002
2020-05-03 21:03:59,333 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:03:59,403 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:04:00,085 INFO  mapreduce.Job - Job job_local1851058655_0002 running in uber mode : false
2020-05-03 21:04:00,085 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:04:00,086 INFO  mapreduce.Job - Job job_local1851058655_0002 completed successfully
2020-05-03 21:04:00,090 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6054186
		FILE: Number of bytes written=8984461
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=1300
		Map output materialized bytes=1340
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1340
		Reduce input records=14
		Reduce output records=7
		Spilled Records=28
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1017643008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1758
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:04:00,115 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-03 21:04:00, elapsed: 00:00:03
2020-05-03 21:04:01,223 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:04:01,720 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200502192221.
2020-05-03 21:04:01,723 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:04:01
2020-05-03 21:04:01,737 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 21:04:01,737 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 21:04:01,737 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 21:04:01,739 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:04:01,739 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:04:01,739 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200502192221
2020-05-03 21:04:02,681 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:04:02,683 INFO  mapreduce.Job - Running job: job_local243243317_0001
2020-05-03 21:04:03,156 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:03,591 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:03,688 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:03,695 INFO  mapreduce.Job - Job job_local243243317_0001 running in uber mode : false
2020-05-03 21:04:03,696 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:04:03,815 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:03,890 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:03,980 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:04,114 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:04,173 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:04,214 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:04:04,328 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:04:04,359 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:04:04,801 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:04:05,470 INFO  solr.SolrIndexWriter - Indexing 12/12 documents
2020-05-03 21:04:05,471 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:04:05,702 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:04:05,703 INFO  mapreduce.Job - Job job_local243243317_0001 completed successfully
2020-05-03 21:04:05,734 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13726165
		FILE: Number of bytes written=21154576
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2071
		Map output records=2071
		Map output bytes=710403
		Map output materialized bytes=714707
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=798
		Reduce shuffle bytes=714707
		Reduce input records=2071
		Reduce output records=12
		Spilled Records=4142
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=171
		Total committed heap usage (bytes)=6165626880
	IndexerStatus
		indexed (add/update)=12
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=361186
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:04:05,734 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:04:05,743 INFO  indexer.IndexingJob - Indexer:     12  indexed (add/update)
2020-05-03 21:04:05,772 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:04:05, elapsed: 00:00:04
2020-05-03 21:29:17,163 INFO  crawl.Injector - Injector: starting at 2020-05-03 21:29:17
2020-05-03 21:29:17,164 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-03 21:29:17,164 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-03 21:29:17,164 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-03 21:29:17,378 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:29:18,045 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-03 21:29:19,276 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:29:19,277 INFO  mapreduce.Job - Running job: job_local661448771_0001
2020-05-03 21:29:19,831 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-03 21:29:20,053 INFO  crawl.Injector - Injector: overwrite: false
2020-05-03 21:29:20,053 INFO  crawl.Injector - Injector: update: false
2020-05-03 21:29:20,288 INFO  mapreduce.Job - Job job_local661448771_0001 running in uber mode : false
2020-05-03 21:29:20,290 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:29:20,291 INFO  mapreduce.Job - Job job_local661448771_0001 completed successfully
2020-05-03 21:29:20,305 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1857060
		FILE: Number of bytes written=2984876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=694
		Map output materialized bytes=720
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=720
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=10
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1118
2020-05-03 21:29:20,316 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-03 21:29:20,316 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 10
2020-05-03 21:29:20,316 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-03 21:29:20,316 INFO  crawl.Injector - Injector: Total new urls injected: 10
2020-05-03 21:29:20,344 INFO  crawl.Injector - Injector: finished at 2020-05-03 21:29:20, elapsed: 00:00:03
2020-05-03 21:29:21,470 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:29:21,931 INFO  crawl.Generator - Generator: starting at 2020-05-03 21:29:21
2020-05-03 21:29:21,931 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-03 21:29:21,931 INFO  crawl.Generator - Generator: filtering: false
2020-05-03 21:29:21,931 INFO  crawl.Generator - Generator: normalizing: true
2020-05-03 21:29:21,934 INFO  crawl.Generator - Generator: topN: 50000
2020-05-03 21:29:22,751 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:29:22,752 INFO  mapreduce.Job - Running job: job_local1110055766_0001
2020-05-03 21:29:23,214 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 21:29:23,215 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 21:29:23,215 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 21:29:23,228 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-03 21:29:23,400 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-03 21:29:23,766 INFO  mapreduce.Job - Job job_local1110055766_0001 running in uber mode : false
2020-05-03 21:29:23,767 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:29:23,768 INFO  mapreduce.Job - Job job_local1110055766_0001 completed successfully
2020-05-03 21:29:23,784 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785369
		FILE: Number of bytes written=4496105
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=984
		Map output materialized bytes=196
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=196
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=941621248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=16
2020-05-03 21:29:23,784 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-03 21:29:23,791 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-03 21:29:24,796 INFO  crawl.Generator - Generator: segment: crawl/segments/20200503212924
2020-05-03 21:29:25,049 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:29:25,050 INFO  mapreduce.Job - Running job: job_local522132813_0002
2020-05-03 21:29:26,052 INFO  mapreduce.Job - Job job_local522132813_0002 running in uber mode : false
2020-05-03 21:29:26,052 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:29:26,052 INFO  mapreduce.Job - Job job_local522132813_0002 completed successfully
2020-05-03 21:29:26,056 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3714776
		FILE: Number of bytes written=5985126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=1348
		Map output materialized bytes=220
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=220
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=883949568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1192
	File Output Format Counters 
		Bytes Written=1090
2020-05-03 21:29:26,080 INFO  crawl.Generator - Generator: finished at 2020-05-03 21:29:26, elapsed: 00:00:04
2020-05-03 21:29:28,112 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-03 21:29:28
2020-05-03 21:29:28,113 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200503212924
2020-05-03 21:29:28,114 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588526968114  (2020-05-04 00:29:28)
2020-05-03 21:29:28,391 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:29:29,616 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:29:29,616 INFO  mapreduce.Job - Running job: job_local449798289_0001
2020-05-03 21:29:29,800 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-03 21:29:29,800 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-03 21:29:29,801 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-03 21:29:29,812 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 10 records hit by time limit : 0
2020-05-03 21:29:30,058 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,077 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,078 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,078 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:30,294 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-03 21:29:30,295 INFO  http.Http - http.proxy.host = null
2020-05-03 21:29:30,295 INFO  http.Http - http.proxy.port = 8080
2020-05-03 21:29:30,295 INFO  http.Http - http.proxy.exception.list = false
2020-05-03 21:29:30,295 INFO  http.Http - http.timeout = 30000
2020-05-03 21:29:30,295 INFO  http.Http - http.content.limit = -1
2020-05-03 21:29:30,295 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-03 21:29:30,295 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-03 21:29:30,295 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-03 21:29:30,295 INFO  http.Http - http.enable.cookie.header = true
2020-05-03 21:29:30,296 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,297 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,298 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,299 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,299 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,300 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,301 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,303 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,304 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,304 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,305 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,307 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,308 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,311 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,311 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,312 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,313 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,313 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,314 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,315 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,317 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,317 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,318 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,318 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,319 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,320 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,320 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,321 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,322 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,323 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,324 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,326 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,327 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,327 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,328 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,329 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,330 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,335 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,336 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,337 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,338 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,340 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,341 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,343 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,343 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,345 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,345 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,347 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,348 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,349 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,349 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,350 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,351 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,352 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,352 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,353 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,354 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,355 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,356 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,357 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,358 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,360 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,361 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,361 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,362 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,363 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,363 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,364 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,364 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,365 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,366 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,366 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,367 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,368 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,368 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,369 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,370 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,371 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,372 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,373 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,373 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,374 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,375 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,375 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,376 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,377 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,378 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,378 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,379 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,380 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,380 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,381 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,382 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,383 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,383 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,384 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:29:30,385 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:29:30,385 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-03 21:29:30,385 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-03 21:29:30,386 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-03 21:29:30,623 INFO  mapreduce.Job - Job job_local449798289_0001 running in uber mode : false
2020-05-03 21:29:30,624 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:29:31,393 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:32,394 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:33,395 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:34,395 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:35,396 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:36,397 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:37,399 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:38,400 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:29:39,004 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:39,402 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2020-05-03 21:29:39,696 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:40,355 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:40,407 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2020-05-03 21:29:41,361 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:41,408 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-03 21:29:42,408 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-03 21:29:42,648 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-03 21:29:43,412 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-03 21:29:44,417 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=48, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-03 21:29:44,856 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:45,410 INFO  fetcher.FetcherThread - FetcherThread 73 fetching https://www.apple.com/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:45,418 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588516185410
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueue -   now           = 1588516185418
2020-05-03 21:29:45,418 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:29:45,419 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-03 21:29:45,419 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-03 21:29:46,420 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-03 21:29:46,421 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 21:29:46,421 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 21:29:46,421 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 21:29:46,421 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 21:29:46,421 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 21:29:46,421 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588516185410
2020-05-03 21:29:46,422 INFO  fetcher.FetchItemQueue -   now           = 1588516186422
2020-05-03 21:29:46,422 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:29:46,422 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-03 21:29:46,422 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-03 21:29:47,119 INFO  fetcher.FetcherThread - FetcherThread 73 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:47,423 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588516187119
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   now           = 1588516187423
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-03 21:29:47,423 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/ipad-air/specs/
2020-05-03 21:29:48,345 INFO  fetcher.FetcherThread - FetcherThread 73 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:48,424 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-03 21:29:48,424 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 21:29:48,425 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 21:29:48,425 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 21:29:48,425 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 21:29:48,425 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 21:29:48,425 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588516188345
2020-05-03 21:29:48,425 INFO  fetcher.FetchItemQueue -   now           = 1588516188425
2020-05-03 21:29:48,425 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/ipad-air/specs/
2020-05-03 21:29:49,360 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-03 21:29:49,360 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://www.apple.com/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 21:29:49,360 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=49
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=48
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=46
2020-05-03 21:29:49,360 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=45
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-03 21:29:49,360 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-03 21:29:49,362 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=43
2020-05-03 21:29:49,360 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-03 21:29:49,362 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=42
2020-05-03 21:29:49,360 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-03 21:29:49,362 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=44
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=47
2020-05-03 21:29:49,361 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-03 21:29:49,363 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=40
2020-05-03 21:29:49,362 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=41
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=38
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=39
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=35
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=37
2020-05-03 21:29:49,379 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=36
2020-05-03 21:29:49,395 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-03 21:29:49,395 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-03 21:29:49,395 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-03 21:29:49,395 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=34
2020-05-03 21:29:49,395 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=32
2020-05-03 21:29:49,395 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=33
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=29
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=26
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=31
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-03 21:29:49,407 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=25
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-03 21:29:49,407 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=24
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=27
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=28
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=30
2020-05-03 21:29:49,406 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-03 21:29:49,408 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=22
2020-05-03 21:29:49,408 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=23
2020-05-03 21:29:49,409 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=21
2020-05-03 21:29:49,414 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-03 21:29:49,414 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-03 21:29:49,415 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=19
2020-05-03 21:29:49,414 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-03 21:29:49,415 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=20
2020-05-03 21:29:49,415 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=18
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=14
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-03 21:29:49,424 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=11
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-03 21:29:49,424 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=9
2020-05-03 21:29:49,424 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=9
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-03 21:29:49,424 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=8
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-03 21:29:49,425 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=7
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-03 21:29:49,425 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=6
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-03 21:29:49,425 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=5
2020-05-03 21:29:49,424 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=12
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=13
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=15
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=16
2020-05-03 21:29:49,426 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=4
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-03 21:29:49,426 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=3
2020-05-03 21:29:49,423 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=17
2020-05-03 21:29:49,427 INFO  fetcher.Fetcher - -activeThreads=3, spinWaiting=2, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-03 21:29:49,451 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-03 21:29:49,451 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=2
2020-05-03 21:29:49,762 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-03 21:29:49,762 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=1
2020-05-03 21:29:50,427 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-03 21:29:51,431 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-03 21:29:52,431 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-03 21:29:53,432 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-03 21:29:53,643 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-03 21:29:53,643 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=0
2020-05-03 21:29:54,432 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-03 21:29:54,432 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-03 21:29:54,666 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:29:55,666 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:29:55,667 INFO  mapreduce.Job - Job job_local449798289_0001 completed successfully
2020-05-03 21:29:55,687 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3263151
		FILE: Number of bytes written=5513199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=20
		Map output bytes=1158117
		Map output materialized bytes=185702
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=185702
		Reduce input records=20
		Reduce output records=20
		Spilled Records=40
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=975175680
	FetcherStatus
		bytes_downloaded=1148333
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1090
	File Output Format Counters 
		Bytes Written=193058
2020-05-03 21:29:55,687 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-03 21:29:55, elapsed: 00:00:27
2020-05-03 21:29:56,758 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:29:57,115 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:29:57
2020-05-03 21:29:57,116 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503212924
2020-05-03 21:29:57,991 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:29:57,992 INFO  mapreduce.Job - Running job: job_local946971531_0001
2020-05-03 21:29:58,997 INFO  mapreduce.Job - Job job_local946971531_0001 running in uber mode : false
2020-05-03 21:29:58,999 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:29:59,373 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:29:59,381 INFO  parse.ParseSegment - Parsed (938ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:29:59,451 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:29:59,512 INFO  parse.ParseSegment - Parsed (59ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:29:59,559 INFO  parse.ParseSegment - Parsed (45ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:29:59,604 INFO  parse.ParseSegment - Parsed (43ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:29:59,882 INFO  parse.ParseSegment - Parsed (276ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:29:59,945 INFO  parse.ParseSegment - Parsed (60ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:30:00,003 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:30:00,094 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:30:00,095 INFO  parse.ParseSegment - Parsed (44ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:30:00,128 INFO  parse.ParseSegment - Parsed (31ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:30:00,169 INFO  parse.ParseSegment - Parsed (39ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:30:00,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:30:00,392 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:30:00,509 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:30:00,584 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:30:01,008 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:01,008 INFO  mapreduce.Job - Job job_local946971531_0001 completed successfully
2020-05-03 21:30:01,025 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4645496
		FILE: Number of bytes written=6623790
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=357532
		Map output materialized bytes=89308
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=89308
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=74
		Total committed heap usage (bytes)=1596456960
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189736
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:30:01,037 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:30:01, elapsed: 00:00:03
2020-05-03 21:30:02,087 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:30:02,555 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-03 21:30:02
2020-05-03 21:30:02,555 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-03 21:30:02,555 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200503212924]
2020-05-03 21:30:02,556 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-03 21:30:02,556 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-03 21:30:02,556 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-03 21:30:02,556 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-03 21:30:02,558 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-03 21:30:03,387 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:30:03,388 INFO  mapreduce.Job - Running job: job_local1702952514_0001
2020-05-03 21:30:04,394 INFO  mapreduce.Job - Job job_local1702952514_0001 running in uber mode : false
2020-05-03 21:30:04,414 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:30:04,462 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 21:30:04,463 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 21:30:04,463 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 21:30:04,562 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 21:30:04,562 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 21:30:04,562 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 21:30:05,415 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:05,416 INFO  mapreduce.Job - Job job_local1702952514_0001 completed successfully
2020-05-03 21:30:05,434 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=7076108
		FILE: Number of bytes written=10590965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1030
		Map output records=1030
		Map output bytes=76189
		Map output materialized bytes=6230
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=6230
		Reduce input records=1030
		Reduce output records=662
		Spilled Records=2060
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=10
		db_unfetched=652
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=82072
	File Output Format Counters 
		Bytes Written=56565
2020-05-03 21:30:05,458 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-03 21:30:05, elapsed: 00:00:02
2020-05-03 21:30:06,656 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:30:07,038 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-03 21:30:07
2020-05-03 21:30:07,038 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-03 21:30:07,038 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-03 21:30:07,038 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-03 21:30:07,038 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-03 21:30:07,038 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200503212924
2020-05-03 21:30:07,951 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:30:07,952 INFO  mapreduce.Job - Running job: job_local1313515656_0001
2020-05-03 21:30:08,964 INFO  mapreduce.Job - Job job_local1313515656_0001 running in uber mode : false
2020-05-03 21:30:08,966 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:08,967 INFO  mapreduce.Job - Job job_local1313515656_0001 completed successfully
2020-05-03 21:30:08,981 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2826775
		FILE: Number of bytes written=4484305
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=332
		Combine input records=7
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=15222
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:30:08,981 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-03 21:30:09,279 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:30:09,280 INFO  mapreduce.Job - Running job: job_local2146194641_0002
2020-05-03 21:30:09,752 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:30:09,846 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:30:10,282 INFO  mapreduce.Job - Job job_local2146194641_0002 running in uber mode : false
2020-05-03 21:30:10,282 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:10,283 INFO  mapreduce.Job - Job job_local2146194641_0002 completed successfully
2020-05-03 21:30:10,285 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5623330
		FILE: Number of bytes written=8975128
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=1300
		Map output materialized bytes=1340
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1340
		Reduce input records=14
		Reduce output records=7
		Spilled Records=28
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1758
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:30:10,310 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-03 21:30:10, elapsed: 00:00:03
2020-05-03 21:30:11,372 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-03 21:30:11
2020-05-03 21:30:11,611 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:30:13,018 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:30:13,019 INFO  mapreduce.Job - Running job: job_local1920625767_0001
2020-05-03 21:30:14,054 INFO  mapreduce.Job - Job job_local1920625767_0001 running in uber mode : false
2020-05-03 21:30:14,056 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:14,057 INFO  mapreduce.Job - Job job_local1920625767_0001 completed successfully
2020-05-03 21:30:14,071 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2928530
		FILE: Number of bytes written=4493100
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=10
		Map output bytes=2644
		Map output materialized bytes=2686
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=2686
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=56000
	File Output Format Counters 
		Bytes Written=98
2020-05-03 21:30:14,075 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-03 21:30:14,075 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-03 21:30:14,398 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:30:14,398 INFO  mapreduce.Job - Running job: job_local866260492_0002
2020-05-03 21:30:15,401 INFO  mapreduce.Job - Job job_local866260492_0002 running in uber mode : false
2020-05-03 21:30:15,402 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:15,402 INFO  mapreduce.Job - Job job_local866260492_0002 completed successfully
2020-05-03 21:30:15,405 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7967669
		FILE: Number of bytes written=12248630
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=662
		Map output bytes=49560
		Map output materialized bytes=50912
		Input split bytes=450
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=50912
		Reduce input records=662
		Reduce output records=662
		Spilled Records=1324
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=56098
	File Output Format Counters 
		Bytes Written=56259
2020-05-03 21:30:15,422 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-03 21:30:15, elapsed: 00:00:04
2020-05-03 21:30:16,454 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:30:16,822 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503212924.
2020-05-03 21:30:16,825 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:30:16
2020-05-03 21:30:16,836 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-03 21:30:16,836 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-03 21:30:16,836 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-03 21:30:16,837 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:30:16,838 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:30:16,838 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503212924
2020-05-03 21:30:17,764 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:30:17,765 INFO  mapreduce.Job - Running job: job_local460257906_0001
2020-05-03 21:30:18,823 INFO  mapreduce.Job - Job job_local460257906_0001 running in uber mode : false
2020-05-03 21:30:18,825 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:30:19,494 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:30:19,528 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:30:19,796 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:30:20,378 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 21:30:20,381 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:30:20,833 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:20,834 INFO  mapreduce.Job - Job job_local460257906_0001 completed successfully
2020-05-03 21:30:20,858 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13132458
		FILE: Number of bytes written=20171719
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1709
		Map output records=1709
		Map output bytes=379597
		Map output materialized bytes=383135
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=383135
		Reduce input records=1709
		Reduce output records=10
		Spilled Records=3418
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=255
		Total committed heap usage (bytes)=4907859968
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=226493
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:30:20,858 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:30:20,867 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 21:30:20,889 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:30:20, elapsed: 00:00:04
2020-05-03 21:30:21,925 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-03 21:30:21
2020-05-03 21:30:22,158 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:30:23,380 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:30:23,380 INFO  mapreduce.Job - Running job: job_local2072717182_0001
2020-05-03 21:30:23,987 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:30:24,012 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:30:24,368 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-03 21:30:24,388 INFO  mapreduce.Job - Job job_local2072717182_0001 running in uber mode : false
2020-05-03 21:30:24,389 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:30:24,390 INFO  mapreduce.Job - Job job_local2072717182_0001 completed successfully
2020-05-03 21:30:24,404 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1966366
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=60
		Total committed heap usage (bytes)=477626368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=55906
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:30:24,420 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-03 21:30:24, elapsed: 00:00:02
2020-05-03 21:47:04,314 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:47:04,668 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:47:04
2020-05-03 21:47:04,669 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503212924
2020-05-03 21:47:05,615 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:47:05,616 INFO  mapreduce.Job - Running job: job_local1750129616_0001
2020-05-03 21:47:06,626 INFO  mapreduce.Job - Job job_local1750129616_0001 running in uber mode : false
2020-05-03 21:47:06,627 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:47:07,088 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:47:07,102 INFO  parse.ParseSegment - Parsed (1047ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:47:07,247 INFO  parse.ParseSegment - Parsed (137ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:47:07,366 INFO  parse.ParseSegment - Parsed (115ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:47:07,458 INFO  parse.ParseSegment - Parsed (87ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:47:07,545 INFO  parse.ParseSegment - Parsed (85ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:47:07,612 INFO  parse.ParseSegment - Parsed (65ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:47:07,703 INFO  parse.ParseSegment - Parsed (90ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:47:07,875 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:47:07,876 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:47:07,932 INFO  parse.ParseSegment - Parsed (55ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:47:08,001 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:47:08,125 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:47:08,248 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:47:08,635 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:47:08,636 INFO  mapreduce.Job - Job job_local1750129616_0001 completed successfully
2020-05-03 21:47:08,651 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4119650
		FILE: Number of bytes written=6206465
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=410452
		Map output materialized bytes=410504
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=410504
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=81
		Total committed heap usage (bytes)=1176502272
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189736
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:47:08,664 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:47:08, elapsed: 00:00:03
2020-05-03 21:47:09,690 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:47:10,095 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-03 21:47:10
2020-05-03 21:47:10,095 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-03 21:47:10,095 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-03 21:47:10,096 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-03 21:47:10,096 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-03 21:47:10,097 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200503212924
2020-05-03 21:47:10,099 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502190710
2020-05-03 21:47:10,099 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502192221
2020-05-03 21:47:10,100 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502180859
2020-05-03 21:47:10,100 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502190938
2020-05-03 21:47:10,970 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:47:10,971 INFO  mapreduce.Job - Running job: job_local1752527900_0001
2020-05-03 21:47:11,980 INFO  mapreduce.Job - Job job_local1752527900_0001 running in uber mode : false
2020-05-03 21:47:11,981 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:47:12,988 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:47:12,990 INFO  mapreduce.Job - Job job_local1752527900_0001 completed successfully
2020-05-03 21:47:13,013 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=11918438
		FILE: Number of bytes written=16491129
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=75
		Map output records=42
		Map output bytes=3900
		Map output materialized bytes=4044
		Input split bytes=1660
		Combine input records=42
		Combine output records=42
		Reduce input groups=7
		Reduce shuffle bytes=4044
		Reduce input records=42
		Reduce output records=7
		Spilled Records=84
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=114
		Total committed heap usage (bytes)=5155323904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196603
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:47:13,014 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-03 21:47:13,368 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:47:13,368 INFO  mapreduce.Job - Running job: job_local1535680855_0002
2020-05-03 21:47:13,691 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:47:13,782 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:47:14,373 INFO  mapreduce.Job - Job job_local1535680855_0002 running in uber mode : false
2020-05-03 21:47:14,374 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:47:14,374 INFO  mapreduce.Job - Job job_local1535680855_0002 completed successfully
2020-05-03 21:47:14,379 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6223513
		FILE: Number of bytes written=9002434
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=1300
		Map output materialized bytes=1340
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1340
		Reduce input records=14
		Reduce output records=7
		Spilled Records=28
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1014497280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1758
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:47:14,398 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-03 21:47:14, elapsed: 00:00:04
2020-05-03 21:47:15,486 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:47:15,988 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503212924.
2020-05-03 21:47:16,028 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:47:16
2020-05-03 21:47:16,043 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 21:47:16,043 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 21:47:16,043 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 21:47:16,044 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:47:16,044 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:47:16,044 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503212924
2020-05-03 21:47:16,964 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:47:16,965 INFO  mapreduce.Job - Running job: job_local274018366_0001
2020-05-03 21:47:17,454 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:17,957 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:17,975 INFO  mapreduce.Job - Job job_local274018366_0001 running in uber mode : false
2020-05-03 21:47:17,976 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:47:18,046 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:18,193 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:18,304 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:18,415 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:18,516 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:18,580 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:18,621 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:47:18,720 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:47:18,750 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:47:19,140 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:47:19,755 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 21:47:19,756 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:47:20,988 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:47:20,989 INFO  mapreduce.Job - Job job_local274018366_0001 completed successfully
2020-05-03 21:47:21,018 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13154661
		FILE: Number of bytes written=20367148
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=619931
		Map output materialized bytes=623519
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=623519
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=162
		Total committed heap usage (bytes)=6163529728
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=315095
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:47:21,019 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:47:21,024 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 21:47:21,068 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:47:21, elapsed: 00:00:05
2020-05-03 21:49:05,719 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:49:06,166 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:49:06
2020-05-03 21:49:06,167 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503212924
2020-05-03 21:49:07,230 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:49:07,231 INFO  mapreduce.Job - Running job: job_local783535272_0001
2020-05-03 21:49:08,243 INFO  mapreduce.Job - Job job_local783535272_0001 running in uber mode : false
2020-05-03 21:49:08,244 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:49:09,128 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:49:09,137 INFO  parse.ParseSegment - Parsed (1405ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:49:09,276 INFO  parse.ParseSegment - Parsed (117ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:49:09,375 INFO  parse.ParseSegment - Parsed (94ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:49:09,462 INFO  parse.ParseSegment - Parsed (85ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:49:09,561 INFO  parse.ParseSegment - Parsed (96ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:49:09,634 INFO  parse.ParseSegment - Parsed (71ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:49:09,728 INFO  parse.ParseSegment - Parsed (93ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:49:09,909 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:49:09,910 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:49:09,955 INFO  parse.ParseSegment - Parsed (44ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:49:10,046 INFO  parse.ParseSegment - Parsed (90ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:49:10,195 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:49:10,255 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:49:10,391 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:49:11,258 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:49:11,258 INFO  mapreduce.Job - Job job_local783535272_0001 completed successfully
2020-05-03 21:49:11,273 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4119650
		FILE: Number of bytes written=6198498
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=410452
		Map output materialized bytes=410504
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=410504
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=98
		Total committed heap usage (bytes)=1171783680
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189736
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:49:11,287 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:49:11, elapsed: 00:00:05
2020-05-03 21:49:12,349 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:49:12,762 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-03 21:49:12
2020-05-03 21:49:12,763 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-03 21:49:12,763 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-03 21:49:12,763 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-03 21:49:12,763 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-03 21:49:12,765 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200503212924
2020-05-03 21:49:12,767 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502190710
2020-05-03 21:49:12,768 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502192221
2020-05-03 21:49:12,768 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502180859
2020-05-03 21:49:12,769 INFO  crawl.LinkDb - LinkDb: adding segment: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200502190938
2020-05-03 21:49:14,058 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:49:14,059 INFO  mapreduce.Job - Running job: job_local2065391132_0001
2020-05-03 21:49:15,069 INFO  mapreduce.Job - Job job_local2065391132_0001 running in uber mode : false
2020-05-03 21:49:15,071 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:49:16,078 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:49:16,079 INFO  mapreduce.Job - Job job_local2065391132_0001 completed successfully
2020-05-03 21:49:16,102 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=11918438
		FILE: Number of bytes written=16491151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=75
		Map output records=42
		Map output bytes=3900
		Map output materialized bytes=4044
		Input split bytes=1660
		Combine input records=42
		Combine output records=42
		Reduce input groups=7
		Reduce shuffle bytes=4044
		Reduce input records=42
		Reduce output records=7
		Spilled Records=84
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=122
		Total committed heap usage (bytes)=5155323904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196603
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:49:16,102 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-03 21:49:16,390 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:49:16,391 INFO  mapreduce.Job - Running job: job_local1466358827_0002
2020-05-03 21:49:16,663 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:49:16,763 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:49:17,391 INFO  mapreduce.Job - Job job_local1466358827_0002 running in uber mode : false
2020-05-03 21:49:17,392 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:49:17,392 INFO  mapreduce.Job - Job job_local1466358827_0002 completed successfully
2020-05-03 21:49:17,397 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6223518
		FILE: Number of bytes written=9002449
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=1300
		Map output materialized bytes=1340
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1340
		Reduce input records=14
		Reduce output records=7
		Spilled Records=28
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1014497280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1758
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:49:17,425 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-03 21:49:17, elapsed: 00:00:04
2020-05-03 21:49:18,581 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:49:18,992 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503212924.
2020-05-03 21:49:18,994 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:49:18
2020-05-03 21:49:19,005 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 21:49:19,005 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 21:49:19,005 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 21:49:19,006 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:49:19,006 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:49:19,006 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503212924
2020-05-03 21:49:19,991 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:49:19,991 INFO  mapreduce.Job - Running job: job_local804003874_0001
2020-05-03 21:49:20,517 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:20,921 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,000 INFO  mapreduce.Job - Job job_local804003874_0001 running in uber mode : false
2020-05-03 21:49:21,001 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:49:21,008 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,162 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,241 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,332 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,416 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,462 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,500 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:49:21,639 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:49:21,669 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:49:22,111 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:49:22,789 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 21:49:22,790 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:49:24,013 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:49:24,014 INFO  mapreduce.Job - Job job_local804003874_0001 completed successfully
2020-05-03 21:49:24,032 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13156711
		FILE: Number of bytes written=20367128
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=619931
		Map output materialized bytes=623519
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=623519
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=167
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=315300
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:49:24,032 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:49:24,037 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 21:49:24,051 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:49:24, elapsed: 00:00:05
2020-05-03 21:52:31,848 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:52:32,307 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:52:32
2020-05-03 21:52:32,312 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503212924
2020-05-03 21:52:33,777 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:52:33,778 INFO  mapreduce.Job - Running job: job_local1780034450_0001
2020-05-03 21:52:34,825 INFO  mapreduce.Job - Job job_local1780034450_0001 running in uber mode : false
2020-05-03 21:52:34,826 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:52:35,474 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:52:35,483 INFO  parse.ParseSegment - Parsed (1148ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:52:35,657 INFO  parse.ParseSegment - Parsed (143ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:52:35,757 INFO  parse.ParseSegment - Parsed (97ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:52:35,844 INFO  parse.ParseSegment - Parsed (84ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:52:35,964 INFO  parse.ParseSegment - Parsed (117ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:52:36,032 INFO  parse.ParseSegment - Parsed (66ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:52:36,122 INFO  parse.ParseSegment - Parsed (88ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:52:36,302 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:52:36,303 INFO  parse.ParseSegment - Parsed (70ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:52:36,355 INFO  parse.ParseSegment - Parsed (50ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:52:36,421 INFO  parse.ParseSegment - Parsed (64ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:52:36,546 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:52:36,681 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:52:36,834 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:52:37,840 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:52:37,840 INFO  mapreduce.Job - Job job_local1780034450_0001 completed successfully
2020-05-03 21:52:37,857 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4119650
		FILE: Number of bytes written=6206550
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=410452
		Map output materialized bytes=410504
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=410504
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=80
		Total committed heap usage (bytes)=1171259392
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189736
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:52:37,872 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:52:37, elapsed: 00:00:05
2020-05-03 21:52:38,918 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:52:39,283 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503212924.
2020-05-03 21:52:39,285 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:52:39
2020-05-03 21:52:39,299 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 21:52:39,300 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 21:52:39,300 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 21:52:39,302 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:52:39,302 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:52:39,302 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503212924
2020-05-03 21:52:40,223 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:52:40,223 INFO  mapreduce.Job - Running job: job_local1051182664_0001
2020-05-03 21:52:40,675 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,024 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,104 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,230 INFO  mapreduce.Job - Job job_local1051182664_0001 running in uber mode : false
2020-05-03 21:52:41,231 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:52:41,231 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,325 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,480 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,616 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,670 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,714 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 21:52:41,821 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:52:41,850 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:52:42,256 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:52:42,982 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 21:52:42,982 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:52:44,242 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:52:44,243 INFO  mapreduce.Job - Job job_local1051182664_0001 completed successfully
2020-05-03 21:52:44,268 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13155511
		FILE: Number of bytes written=20394448
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=619931
		Map output materialized bytes=623519
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=623519
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=161
		Total committed heap usage (bytes)=6165102592
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=315180
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:52:44,269 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:52:44,277 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 21:52:44,299 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:52:44, elapsed: 00:00:04
2020-05-03 21:55:25,437 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:55:25,815 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:55:25
2020-05-03 21:55:25,815 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503212924
2020-05-03 21:55:26,358 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/crawl/segments/20200503212924/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:261)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:308)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:280)

2020-05-03 21:55:27,351 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:55:27,717 WARN  segment.SegmentChecker - Skipping segment: crawl/segments/20200503212924. Missing sub directories: parse_data, parse_text, crawl_parse
2020-05-03 21:55:27,719 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:55:27
2020-05-03 21:55:27,729 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 21:55:27,729 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 21:55:27,729 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 21:55:27,731 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:55:27,731 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:55:27,736 WARN  indexer.IndexerMapReduce - Ignoring linkDb for indexing, no linkDb found in path: crawl/linkdb
2020-05-03 21:55:28,047 ERROR indexer.IndexingJob - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/crawl/crawldb/current
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.indexer.IndexingJob.index(IndexingJob.java:144)
	at org.apache.nutch.indexer.IndexingJob.run(IndexingJob.java:231)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.indexer.IndexingJob.main(IndexingJob.java:240)

2020-05-03 21:55:28,048 ERROR indexer.IndexingJob - Indexer: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/Users/apple/apache/apache-nutch-1.16/crawl/crawldb/current
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:314)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:331)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:202)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.indexer.IndexingJob.index(IndexingJob.java:144)
	at org.apache.nutch.indexer.IndexingJob.run(IndexingJob.java:231)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.indexer.IndexingJob.main(IndexingJob.java:240)

2020-05-03 21:55:47,039 INFO  crawl.Injector - Injector: starting at 2020-05-03 21:55:47
2020-05-03 21:55:47,040 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-03 21:55:47,040 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-03 21:55:47,040 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-03 21:55:47,187 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:55:47,586 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-03 21:55:48,465 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:55:48,466 INFO  mapreduce.Job - Running job: job_local567020848_0001
2020-05-03 21:55:48,935 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-03 21:55:49,129 INFO  crawl.Injector - Injector: overwrite: false
2020-05-03 21:55:49,129 INFO  crawl.Injector - Injector: update: false
2020-05-03 21:55:49,477 INFO  mapreduce.Job - Job job_local567020848_0001 running in uber mode : false
2020-05-03 21:55:49,478 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:55:49,479 INFO  mapreduce.Job - Job job_local567020848_0001 completed successfully
2020-05-03 21:55:49,496 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1857060
		FILE: Number of bytes written=2984876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=694
		Map output materialized bytes=720
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=720
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=10
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1118
2020-05-03 21:55:49,508 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-03 21:55:49,508 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 10
2020-05-03 21:55:49,508 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-03 21:55:49,508 INFO  crawl.Injector - Injector: Total new urls injected: 10
2020-05-03 21:55:49,531 INFO  crawl.Injector - Injector: finished at 2020-05-03 21:55:49, elapsed: 00:00:02
2020-05-03 21:55:50,647 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:55:51,044 INFO  crawl.Generator - Generator: starting at 2020-05-03 21:55:51
2020-05-03 21:55:51,044 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-03 21:55:51,044 INFO  crawl.Generator - Generator: filtering: false
2020-05-03 21:55:51,044 INFO  crawl.Generator - Generator: normalizing: true
2020-05-03 21:55:51,046 INFO  crawl.Generator - Generator: topN: 50000
2020-05-03 21:55:51,881 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:55:51,882 INFO  mapreduce.Job - Running job: job_local331329179_0001
2020-05-03 21:55:52,556 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 21:55:52,556 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 21:55:52,556 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 21:55:52,567 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-03 21:55:52,771 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-03 21:55:52,887 INFO  mapreduce.Job - Job job_local331329179_0001 running in uber mode : false
2020-05-03 21:55:52,888 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:55:52,889 INFO  mapreduce.Job - Job job_local331329179_0001 completed successfully
2020-05-03 21:55:52,908 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785365
		FILE: Number of bytes written=4487856
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=984
		Map output materialized bytes=195
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=195
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=16
2020-05-03 21:55:52,908 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-03 21:55:52,913 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-03 21:55:53,915 INFO  crawl.Generator - Generator: segment: crawl/segments/20200503215553
2020-05-03 21:55:54,165 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:55:54,166 INFO  mapreduce.Job - Running job: job_local341381148_0002
2020-05-03 21:55:55,172 INFO  mapreduce.Job - Job job_local341381148_0002 running in uber mode : false
2020-05-03 21:55:55,172 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:55:55,173 INFO  mapreduce.Job - Job job_local341381148_0002 completed successfully
2020-05-03 21:55:55,177 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3714768
		FILE: Number of bytes written=5979632
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=1348
		Map output materialized bytes=218
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=218
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1192
	File Output Format Counters 
		Bytes Written=1090
2020-05-03 21:55:55,198 INFO  crawl.Generator - Generator: finished at 2020-05-03 21:55:55, elapsed: 00:00:04
2020-05-03 21:55:56,187 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-03 21:55:56
2020-05-03 21:55:56,187 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200503215553
2020-05-03 21:55:56,187 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588528556187  (2020-05-04 00:55:56)
2020-05-03 21:55:56,388 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:55:57,430 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:55:57,432 INFO  mapreduce.Job - Running job: job_local1163636135_0001
2020-05-03 21:55:57,636 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-03 21:55:57,636 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-03 21:55:57,636 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-03 21:55:57,645 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 10 records hit by time limit : 0
2020-05-03 21:55:57,935 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:57,959 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:57,962 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 21:55:57,963 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,170 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-03 21:55:58,172 INFO  http.Http - http.proxy.host = null
2020-05-03 21:55:58,172 INFO  http.Http - http.proxy.port = 8080
2020-05-03 21:55:58,172 INFO  http.Http - http.proxy.exception.list = false
2020-05-03 21:55:58,172 INFO  http.Http - http.timeout = 30000
2020-05-03 21:55:58,172 INFO  http.Http - http.content.limit = -1
2020-05-03 21:55:58,172 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-03 21:55:58,172 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-03 21:55:58,172 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-03 21:55:58,172 INFO  http.Http - http.enable.cookie.header = true
2020-05-03 21:55:58,177 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,178 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,179 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,179 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,180 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,190 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,191 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,192 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,199 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,199 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,201 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,201 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,202 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,203 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,206 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,214 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,214 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,220 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,222 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,222 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,223 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,224 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,224 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,227 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,228 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,229 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,230 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,230 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,231 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,231 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,232 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,232 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,233 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,233 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,234 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,234 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,234 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,235 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,235 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,236 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,236 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,236 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,237 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,237 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,243 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,245 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,245 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,246 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,246 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,247 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,247 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,248 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,249 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,250 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,251 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,252 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,252 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,253 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,253 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,254 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,259 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,260 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,261 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,262 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,262 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,263 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,263 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,264 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,267 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,268 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,268 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,269 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,274 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,275 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,277 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,278 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,278 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,279 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,279 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,279 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,280 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,280 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,283 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,284 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,284 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,285 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,285 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:55:58,286 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 21:55:58,286 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-03 21:55:58,287 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-03 21:55:58,287 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-03 21:55:58,440 INFO  mapreduce.Job - Job job_local1163636135_0001 running in uber mode : false
2020-05-03 21:55:58,441 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:55:59,291 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 21:56:00,089 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:00,296 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2020-05-03 21:56:01,302 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2020-05-03 21:56:01,807 INFO  fetcher.FetcherThread - FetcherThread 88 fetching https://www.apple.com/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:02,303 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2020-05-03 21:56:02,936 INFO  fetcher.FetcherThread - FetcherThread 88 fetching https://www.apple.com/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:03,305 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2020-05-03 21:56:04,142 INFO  fetcher.FetcherThread - FetcherThread 88 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:04,305 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-03 21:56:04,416 INFO  fetcher.FetcherThread - FetcherThread 88 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:04,797 INFO  fetcher.FetcherThread - FetcherThread 76 fetching https://www.apple.com/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:05,309 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-03 21:56:05,309 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 21:56:05,309 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 21:56:05,309 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 21:56:05,310 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 21:56:05,310 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 21:56:05,310 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588517764791
2020-05-03 21:56:05,310 INFO  fetcher.FetchItemQueue -   now           = 1588517765310
2020-05-03 21:56:05,310 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:56:05,310 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-03 21:56:05,310 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-03 21:56:06,215 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:06,314 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588517765909
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   now           = 1588517766316
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-xr/specs/
2020-05-03 21:56:06,316 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/ipad-air/specs/
2020-05-03 21:56:06,731 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:07,220 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 21:56:07,220 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-03 21:56:07,221 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=49
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=46
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=47
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=48
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=45
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-03 21:56:07,239 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-03 21:56:07,239 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-03 21:56:07,238 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-03 21:56:07,239 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=44
2020-05-03 21:56:07,239 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=43
2020-05-03 21:56:07,239 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=42
2020-05-03 21:56:07,239 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=41
2020-05-03 21:56:07,259 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-03 21:56:07,259 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=40
2020-05-03 21:56:07,259 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-03 21:56:07,259 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-03 21:56:07,260 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=39
2020-05-03 21:56:07,260 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=38
2020-05-03 21:56:07,270 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-03 21:56:07,270 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-03 21:56:07,270 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-03 21:56:07,270 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=34
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=32
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=36
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=35
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-03 21:56:07,273 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=31
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-03 21:56:07,273 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=30
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=33
2020-05-03 21:56:07,271 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=37
2020-05-03 21:56:07,277 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-03 21:56:07,278 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=29
2020-05-03 21:56:07,277 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-03 21:56:07,277 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-03 21:56:07,278 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=28
2020-05-03 21:56:07,278 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=27
2020-05-03 21:56:07,288 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-03 21:56:07,288 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=26
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=23
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=24
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=22
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-03 21:56:07,304 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=21
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-03 21:56:07,304 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=20
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=25
2020-05-03 21:56:07,305 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=19
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-03 21:56:07,305 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=18
2020-05-03 21:56:07,303 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-03 21:56:07,305 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=17
2020-05-03 21:56:07,314 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-03 21:56:07,314 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-03 21:56:07,315 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=16
2020-05-03 21:56:07,314 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-03 21:56:07,316 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=14
2020-05-03 21:56:07,315 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=15
2020-05-03 21:56:07,320 INFO  fetcher.Fetcher - -activeThreads=14, spinWaiting=13, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=12
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=13
2020-05-03 21:56:07,332 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=10
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-03 21:56:07,333 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=9
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-03 21:56:07,332 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=11
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-03 21:56:07,331 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-03 21:56:07,333 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=7
2020-05-03 21:56:07,333 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=6
2020-05-03 21:56:07,333 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=8
2020-05-03 21:56:07,340 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-03 21:56:07,340 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=5
2020-05-03 21:56:07,340 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-03 21:56:07,341 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=4
2020-05-03 21:56:07,340 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-03 21:56:07,341 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=3
2020-05-03 21:56:07,420 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-03 21:56:07,421 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=2
2020-05-03 21:56:07,522 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-03 21:56:07,523 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=1
2020-05-03 21:56:08,157 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-03 21:56:08,157 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=0
2020-05-03 21:56:08,321 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-03 21:56:08,322 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-03 21:56:08,547 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:56:09,552 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:09,553 INFO  mapreduce.Job - Job job_local1163636135_0001 completed successfully
2020-05-03 21:56:09,571 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3263161
		FILE: Number of bytes written=5521456
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=20
		Map output bytes=1158118
		Map output materialized bytes=185707
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=185707
		Reduce input records=20
		Reduce output records=20
		Spilled Records=40
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=83
		Total committed heap usage (bytes)=981467136
	FetcherStatus
		bytes_downloaded=1148333
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1090
	File Output Format Counters 
		Bytes Written=193089
2020-05-03 21:56:09,571 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-03 21:56:09, elapsed: 00:00:13
2020-05-03 21:56:10,859 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:56:11,222 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 21:56:11
2020-05-03 21:56:11,225 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503215553
2020-05-03 21:56:12,074 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:56:12,075 INFO  mapreduce.Job - Running job: job_local1627776487_0001
2020-05-03 21:56:13,115 INFO  mapreduce.Job - Job job_local1627776487_0001 running in uber mode : false
2020-05-03 21:56:13,116 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 21:56:13,842 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:56:13,852 INFO  parse.ParseSegment - Parsed (1255ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 21:56:13,988 INFO  parse.ParseSegment - Parsed (124ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 21:56:14,080 INFO  parse.ParseSegment - Parsed (88ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 21:56:14,155 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-11/specs/
2020-05-03 21:56:14,224 INFO  parse.ParseSegment - Parsed (67ms):https://www.apple.com/iphone-se/specs/
2020-05-03 21:56:14,283 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 21:56:14,382 INFO  parse.ParseSegment - Parsed (97ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 21:56:14,556 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 21:56:14,556 INFO  parse.ParseSegment - Parsed (62ms):https://www.apple.com/ipad-air/specs/
2020-05-03 21:56:14,600 INFO  parse.ParseSegment - Parsed (42ms):https://www.apple.com/macbook-air/specs/
2020-05-03 21:56:14,650 INFO  parse.ParseSegment - Parsed (48ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 21:56:14,776 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:56:14,896 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:56:15,010 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 21:56:15,075 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 21:56:15,123 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-03 21:56:16,126 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:16,126 INFO  mapreduce.Job - Job job_local1627776487_0001 completed successfully
2020-05-03 21:56:16,149 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4662604
		FILE: Number of bytes written=6696458
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=410453
		Map output materialized bytes=96636
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=96636
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=111
		Total committed heap usage (bytes)=1587019776
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189770
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:56:16,163 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 21:56:16, elapsed: 00:00:04
2020-05-03 21:56:17,510 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:56:17,902 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-03 21:56:17
2020-05-03 21:56:17,903 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-03 21:56:17,903 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200503215553]
2020-05-03 21:56:17,904 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-03 21:56:17,904 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-03 21:56:17,904 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-03 21:56:17,904 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-03 21:56:17,906 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-03 21:56:18,781 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:56:18,782 INFO  mapreduce.Job - Running job: job_local371266549_0001
2020-05-03 21:56:19,792 INFO  mapreduce.Job - Job job_local371266549_0001 running in uber mode : false
2020-05-03 21:56:19,793 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:56:19,811 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 21:56:19,812 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 21:56:19,812 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 21:56:20,060 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 21:56:20,060 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 21:56:20,060 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 21:56:20,797 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:20,798 INFO  mapreduce.Job - Job job_local371266549_0001 completed successfully
2020-05-03 21:56:20,823 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=7075716
		FILE: Number of bytes written=10571263
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1030
		Map output records=1030
		Map output bytes=76189
		Map output materialized bytes=6147
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=6147
		Reduce input records=1030
		Reduce output records=662
		Spilled Records=2060
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=10
		db_unfetched=652
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=82063
	File Output Format Counters 
		Bytes Written=56565
2020-05-03 21:56:20,850 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-03 21:56:20, elapsed: 00:00:02
2020-05-03 21:56:22,596 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:56:23,222 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-03 21:56:23
2020-05-03 21:56:23,225 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-03 21:56:23,226 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-03 21:56:23,227 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-03 21:56:23,227 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-03 21:56:23,228 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200503215553
2020-05-03 21:56:24,207 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:56:24,208 INFO  mapreduce.Job - Running job: job_local838060938_0001
2020-05-03 21:56:24,775 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:56:24,912 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 21:56:25,215 INFO  mapreduce.Job - Job job_local838060938_0001 running in uber mode : false
2020-05-03 21:56:25,216 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:25,217 INFO  mapreduce.Job - Job job_local838060938_0001 completed successfully
2020-05-03 21:56:25,231 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2892541
		FILE: Number of bytes written=4478329
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=332
		Combine input records=7
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=913833984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=37950
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 21:56:25,249 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-03 21:56:25, elapsed: 00:00:02
2020-05-03 21:56:26,239 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-03 21:56:26
2020-05-03 21:56:26,581 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:56:28,056 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:56:28,056 INFO  mapreduce.Job - Running job: job_local1940364818_0001
2020-05-03 21:56:29,065 INFO  mapreduce.Job - Job job_local1940364818_0001 running in uber mode : false
2020-05-03 21:56:29,067 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:29,068 INFO  mapreduce.Job - Job job_local1940364818_0001 completed successfully
2020-05-03 21:56:29,086 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2928530
		FILE: Number of bytes written=4493094
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=10
		Map output bytes=2644
		Map output materialized bytes=2686
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=2686
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=56000
	File Output Format Counters 
		Bytes Written=98
2020-05-03 21:56:29,094 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-03 21:56:29,094 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-03 21:56:29,426 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:56:29,427 INFO  mapreduce.Job - Running job: job_local589000094_0002
2020-05-03 21:56:30,431 INFO  mapreduce.Job - Job job_local589000094_0002 running in uber mode : false
2020-05-03 21:56:30,431 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:30,432 INFO  mapreduce.Job - Job job_local589000094_0002 completed successfully
2020-05-03 21:56:30,437 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7967660
		FILE: Number of bytes written=12248602
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=662
		Map output bytes=49560
		Map output materialized bytes=50912
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=50912
		Reduce input records=662
		Reduce output records=662
		Spilled Records=1324
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=56098
	File Output Format Counters 
		Bytes Written=56259
2020-05-03 21:56:30,459 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-03 21:56:30, elapsed: 00:00:04
2020-05-03 21:56:31,598 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:56:32,155 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503215553.
2020-05-03 21:56:32,159 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 21:56:32
2020-05-03 21:56:32,181 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-03 21:56:32,181 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-03 21:56:32,185 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-03 21:56:32,188 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 21:56:32,188 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 21:56:32,189 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503215553
2020-05-03 21:56:33,160 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:56:33,161 INFO  mapreduce.Job - Running job: job_local725251964_0001
2020-05-03 21:56:34,166 INFO  mapreduce.Job - Job job_local725251964_0001 running in uber mode : false
2020-05-03 21:56:34,168 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 21:56:34,536 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:56:34,573 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:56:34,986 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 21:56:35,566 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 21:56:35,566 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 21:56:36,173 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:36,174 INFO  mapreduce.Job - Job job_local725251964_0001 completed successfully
2020-05-03 21:56:36,199 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13394407
		FILE: Number of bytes written=20656207
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1709
		Map output records=1709
		Map output bytes=432518
		Map output materialized bytes=436056
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=436056
		Reduce input records=1709
		Reduce output records=10
		Spilled Records=3418
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=165
		Total committed heap usage (bytes)=7224164352
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=249212
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:56:36,200 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 21:56:36,208 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 21:56:36,238 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 21:56:36, elapsed: 00:00:04
2020-05-03 21:56:37,341 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-03 21:56:37
2020-05-03 21:56:37,595 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 21:56:38,773 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 21:56:38,774 INFO  mapreduce.Job - Running job: job_local136143277_0001
2020-05-03 21:56:39,379 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 21:56:39,398 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 21:56:39,724 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-03 21:56:39,780 INFO  mapreduce.Job - Job job_local136143277_0001 running in uber mode : false
2020-05-03 21:56:39,782 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 21:56:39,783 INFO  mapreduce.Job - Job job_local136143277_0001 completed successfully
2020-05-03 21:56:39,803 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1966366
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		Total committed heap usage (bytes)=479199232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=55906
	File Output Format Counters 
		Bytes Written=0
2020-05-03 21:56:39,826 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-03 21:56:39, elapsed: 00:00:02
2020-05-03 22:06:56,038 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:06:56,449 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 22:06:56
2020-05-03 22:06:56,450 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503215553
2020-05-03 22:06:57,455 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:06:57,456 INFO  mapreduce.Job - Running job: job_local666936019_0001
2020-05-03 22:06:58,464 INFO  mapreduce.Job - Job job_local666936019_0001 running in uber mode : false
2020-05-03 22:06:58,465 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 22:06:59,106 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:06:59,119 INFO  parse.ParseSegment - Parsed (1071ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 22:06:59,251 INFO  parse.ParseSegment - Parsed (123ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 22:06:59,351 INFO  parse.ParseSegment - Parsed (97ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 22:06:59,436 INFO  parse.ParseSegment - Parsed (82ms):https://www.apple.com/iphone-11/specs/
2020-05-03 22:06:59,505 INFO  parse.ParseSegment - Parsed (67ms):https://www.apple.com/iphone-se/specs/
2020-05-03 22:06:59,579 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 22:06:59,655 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 22:06:59,861 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:06:59,862 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/ipad-air/specs/
2020-05-03 22:06:59,898 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/macbook-air/specs/
2020-05-03 22:06:59,943 INFO  parse.ParseSegment - Parsed (43ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 22:07:00,059 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 22:07:00,191 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 22:07:00,473 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:07:00,473 INFO  mapreduce.Job - Job job_local666936019_0001 completed successfully
2020-05-03 22:07:00,492 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4113206
		FILE: Number of bytes written=6185689
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=407189
		Map output materialized bytes=407241
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=407241
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=85
		Total committed heap usage (bytes)=1170210816
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189770
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:07:00,508 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 22:07:00, elapsed: 00:00:04
2020-05-03 22:07:01,517 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:07:01,890 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503215553.
2020-05-03 22:07:01,894 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 22:07:01
2020-05-03 22:07:01,907 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 22:07:01,907 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 22:07:01,907 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 22:07:01,908 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 22:07:01,908 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 22:07:01,908 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503215553
2020-05-03 22:07:02,708 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:07:02,708 INFO  mapreduce.Job - Running job: job_local1265707133_0001
2020-05-03 22:07:03,235 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:03,685 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:03,716 INFO  mapreduce.Job - Job job_local1265707133_0001 running in uber mode : false
2020-05-03 22:07:03,718 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 22:07:03,781 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:03,990 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:04,140 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:04,370 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:04,460 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:04,515 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:04,551 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:07:04,675 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 22:07:04,710 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 22:07:05,163 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 22:07:05,804 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 22:07:05,805 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 22:07:06,726 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:07:06,727 INFO  mapreduce.Job - Job job_local1265707133_0001 completed successfully
2020-05-03 22:07:06,753 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13337539
		FILE: Number of bytes written=20657483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=664314
		Map output materialized bytes=667902
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=667902
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=172
		Total committed heap usage (bytes)=6194987008
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=334207
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:07:06,753 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 22:07:06,764 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 22:07:06,795 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 22:07:06, elapsed: 00:00:04
2020-05-03 22:08:42,195 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:08:42,539 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 22:08:42
2020-05-03 22:08:42,539 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503215553
2020-05-03 22:08:43,376 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:08:43,377 INFO  mapreduce.Job - Running job: job_local1618523355_0001
2020-05-03 22:08:44,383 INFO  mapreduce.Job - Job job_local1618523355_0001 running in uber mode : false
2020-05-03 22:08:44,384 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 22:08:44,849 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:08:44,861 INFO  parse.ParseSegment - Parsed (1012ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 22:08:44,983 INFO  parse.ParseSegment - Parsed (116ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 22:08:45,093 INFO  parse.ParseSegment - Parsed (107ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 22:08:45,169 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/iphone-11/specs/
2020-05-03 22:08:45,234 INFO  parse.ParseSegment - Parsed (63ms):https://www.apple.com/iphone-se/specs/
2020-05-03 22:08:45,293 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 22:08:45,367 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 22:08:45,541 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:08:45,542 INFO  parse.ParseSegment - Parsed (74ms):https://www.apple.com/ipad-air/specs/
2020-05-03 22:08:45,582 INFO  parse.ParseSegment - Parsed (39ms):https://www.apple.com/macbook-air/specs/
2020-05-03 22:08:45,634 INFO  parse.ParseSegment - Parsed (50ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 22:08:45,752 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 22:08:45,887 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 22:08:46,393 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:08:46,393 INFO  mapreduce.Job - Job job_local1618523355_0001 completed successfully
2020-05-03 22:08:46,408 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4130916
		FILE: Number of bytes written=6225147
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=416044
		Map output materialized bytes=416096
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=416096
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=78
		Total committed heap usage (bytes)=1166540800
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189770
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:08:46,423 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 22:08:46, elapsed: 00:00:03
2020-05-03 22:08:47,492 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:08:47,861 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503215553.
2020-05-03 22:08:47,863 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 22:08:47
2020-05-03 22:08:47,874 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 22:08:47,874 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 22:08:47,874 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 22:08:47,876 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 22:08:47,876 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 22:08:47,876 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503215553
2020-05-03 22:08:48,746 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:08:48,747 INFO  mapreduce.Job - Running job: job_local2034715969_0001
2020-05-03 22:08:49,244 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:49,592 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:49,665 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:49,758 INFO  mapreduce.Job - Job job_local2034715969_0001 running in uber mode : false
2020-05-03 22:08:49,759 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 22:08:49,884 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:50,035 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:50,158 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:50,247 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:50,290 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:50,322 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:08:50,435 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 22:08:50,468 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 22:08:51,028 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 22:08:51,980 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 22:08:51,980 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 22:08:52,769 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:08:52,771 INFO  mapreduce.Job - Job job_local2034715969_0001 completed successfully
2020-05-03 22:08:52,798 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13363313
		FILE: Number of bytes written=20719488
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=673169
		Map output materialized bytes=676757
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=676757
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=216
		Total committed heap usage (bytes)=6196559872
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=335451
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:08:52,798 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 22:08:52,809 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 22:08:52,823 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 22:08:52, elapsed: 00:00:04
2020-05-03 22:09:45,961 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:09:46,382 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 22:09:46
2020-05-03 22:09:46,382 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503215553
2020-05-03 22:09:47,346 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:09:47,347 INFO  mapreduce.Job - Running job: job_local200913762_0001
2020-05-03 22:09:48,353 INFO  mapreduce.Job - Job job_local200913762_0001 running in uber mode : false
2020-05-03 22:09:48,355 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 22:09:48,817 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:09:48,830 INFO  parse.ParseSegment - Parsed (1015ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 22:09:48,960 INFO  parse.ParseSegment - Parsed (113ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 22:09:49,072 INFO  parse.ParseSegment - Parsed (109ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 22:09:49,167 INFO  parse.ParseSegment - Parsed (93ms):https://www.apple.com/iphone-11/specs/
2020-05-03 22:09:49,261 INFO  parse.ParseSegment - Parsed (85ms):https://www.apple.com/iphone-se/specs/
2020-05-03 22:09:49,320 INFO  parse.ParseSegment - Parsed (57ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 22:09:49,390 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 22:09:49,545 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:09:49,546 INFO  parse.ParseSegment - Parsed (58ms):https://www.apple.com/ipad-air/specs/
2020-05-03 22:09:49,586 INFO  parse.ParseSegment - Parsed (39ms):https://www.apple.com/macbook-air/specs/
2020-05-03 22:09:49,636 INFO  parse.ParseSegment - Parsed (48ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 22:09:49,741 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 22:09:49,853 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 22:09:50,368 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:09:50,369 INFO  mapreduce.Job - Job job_local200913762_0001 completed successfully
2020-05-03 22:09:50,383 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4116192
		FILE: Number of bytes written=6191615
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=408682
		Map output materialized bytes=408734
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=408734
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=76
		Total committed heap usage (bytes)=1168113664
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189770
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:09:50,397 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 22:09:50, elapsed: 00:00:04
2020-05-03 22:09:51,419 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:09:51,778 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503215553.
2020-05-03 22:09:51,782 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 22:09:51
2020-05-03 22:09:51,794 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 22:09:51,794 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 22:09:51,794 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 22:09:51,795 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 22:09:51,795 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 22:09:51,795 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503215553
2020-05-03 22:09:52,656 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:09:52,657 INFO  mapreduce.Job - Running job: job_local1430641442_0001
2020-05-03 22:09:53,123 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:53,507 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:53,598 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:53,663 INFO  mapreduce.Job - Job job_local1430641442_0001 running in uber mode : false
2020-05-03 22:09:53,664 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 22:09:53,748 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:53,915 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:54,077 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:54,153 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:54,193 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:54,229 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:09:54,331 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 22:09:54,354 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 22:09:54,753 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 22:09:55,294 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 22:09:55,295 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 22:09:55,669 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:09:55,670 INFO  mapreduce.Job - Job job_local1430641442_0001 completed successfully
2020-05-03 22:09:55,692 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13346717
		FILE: Number of bytes written=20667934
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=665807
		Map output materialized bytes=669395
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=669395
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=162
		Total committed heap usage (bytes)=6194987008
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=335061
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:09:55,693 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 22:09:55,700 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 22:09:55,722 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 22:09:55, elapsed: 00:00:03
2020-05-03 22:55:58,985 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:55:59,954 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 22:55:59
2020-05-03 22:55:59,955 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503215553
2020-05-03 22:56:01,351 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:56:01,352 INFO  mapreduce.Job - Running job: job_local1598247646_0001
2020-05-03 22:56:02,363 INFO  mapreduce.Job - Job job_local1598247646_0001 running in uber mode : false
2020-05-03 22:56:02,364 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 22:56:03,762 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:56:03,776 INFO  parse.ParseSegment - Parsed (1883ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 22:56:03,999 INFO  parse.ParseSegment - Parsed (214ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 22:56:04,104 INFO  parse.ParseSegment - Parsed (100ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 22:56:04,184 INFO  parse.ParseSegment - Parsed (75ms):https://www.apple.com/iphone-11/specs/
2020-05-03 22:56:04,269 INFO  parse.ParseSegment - Parsed (82ms):https://www.apple.com/iphone-se/specs/
2020-05-03 22:56:04,446 INFO  parse.ParseSegment - Parsed (173ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 22:56:04,603 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-16/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 22:56:04,614 INFO  parse.ParseSegment - Parsed (165ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 22:56:04,830 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 22:56:04,831 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/ipad-air/specs/
2020-05-03 22:56:04,881 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-air/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 22:56:04,882 INFO  parse.ParseSegment - Parsed (49ms):https://www.apple.com/macbook-air/specs/
2020-05-03 22:56:04,962 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-13/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 22:56:04,963 INFO  parse.ParseSegment - Parsed (79ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 22:56:05,108 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 22:56:05,241 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 22:56:05,369 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 22:56:06,372 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:56:06,374 INFO  mapreduce.Job - Job job_local1598247646_0001 completed successfully
2020-05-03 22:56:06,400 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4112528
		FILE: Number of bytes written=6192770
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=406850
		Map output materialized bytes=406902
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=406902
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=142
		Total committed heap usage (bytes)=1118830592
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189770
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:56:06,419 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 22:56:06, elapsed: 00:00:06
2020-05-03 22:56:08,111 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 22:56:08,520 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503215553.
2020-05-03 22:56:08,523 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 22:56:08
2020-05-03 22:56:08,559 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 22:56:08,562 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 22:56:08,563 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 22:56:08,565 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 22:56:08,566 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 22:56:08,566 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503215553
2020-05-03 22:56:09,481 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 22:56:09,482 INFO  mapreduce.Job - Running job: job_local369768076_0001
2020-05-03 22:56:10,101 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:10,488 INFO  mapreduce.Job - Job job_local369768076_0001 running in uber mode : false
2020-05-03 22:56:10,489 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 22:56:10,512 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:10,606 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:10,836 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:10,963 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:11,140 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:11,221 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:11,264 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:11,298 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 22:56:11,444 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 22:56:11,476 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 22:56:12,039 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 22:56:12,798 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 22:56:12,799 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 22:56:13,497 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 22:56:13,499 INFO  mapreduce.Job - Job job_local369768076_0001 completed successfully
2020-05-03 22:56:13,523 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13337929
		FILE: Number of bytes written=20627790
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=663975
		Map output materialized bytes=667563
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=667563
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=158
		Total committed heap usage (bytes)=6191841280
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=334247
	File Output Format Counters 
		Bytes Written=0
2020-05-03 22:56:13,524 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 22:56:13,532 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 22:56:13,556 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 22:56:13, elapsed: 00:00:05
2020-05-03 23:00:30,508 INFO  crawl.Injector - Injector: starting at 2020-05-03 23:00:30
2020-05-03 23:00:30,508 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-03 23:00:30,508 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-03 23:00:30,509 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-03 23:00:30,754 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:00:31,355 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-03 23:00:32,452 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:00:32,453 INFO  mapreduce.Job - Running job: job_local1334924388_0001
2020-05-03 23:00:33,069 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-03 23:00:33,229 INFO  crawl.Injector - Injector: overwrite: false
2020-05-03 23:00:33,229 INFO  crawl.Injector - Injector: update: false
2020-05-03 23:00:33,468 INFO  mapreduce.Job - Job job_local1334924388_0001 running in uber mode : false
2020-05-03 23:00:33,469 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:00:33,470 INFO  mapreduce.Job - Job job_local1334924388_0001 completed successfully
2020-05-03 23:00:33,497 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3056215
		FILE: Number of bytes written=4743630
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=672
		Map output records=672
		Map output bytes=50254
		Map output materialized bytes=51620
		Input split bytes=592
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=51620
		Reduce input records=672
		Reduce output records=662
		Spilled Records=1344
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=913833984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=10
		urls_merged=10
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=56259
2020-05-03 23:00:33,523 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-03 23:00:33,523 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 10
2020-05-03 23:00:33,523 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 10
2020-05-03 23:00:33,523 INFO  crawl.Injector - Injector: Total new urls injected: 0
2020-05-03 23:00:33,650 INFO  crawl.Injector - Injector: finished at 2020-05-03 23:00:33, elapsed: 00:00:03
2020-05-03 23:00:34,905 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:00:35,493 INFO  crawl.Generator - Generator: starting at 2020-05-03 23:00:35
2020-05-03 23:00:35,493 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-03 23:00:35,493 INFO  crawl.Generator - Generator: filtering: false
2020-05-03 23:00:35,493 INFO  crawl.Generator - Generator: normalizing: true
2020-05-03 23:00:35,495 INFO  crawl.Generator - Generator: topN: 50000
2020-05-03 23:00:36,586 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:00:36,588 INFO  mapreduce.Job - Running job: job_local1955852942_0001
2020-05-03 23:00:37,138 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 23:00:37,138 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 23:00:37,138 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 23:00:37,145 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-03 23:00:37,453 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-03 23:00:37,595 INFO  mapreduce.Job - Job job_local1955852942_0001 running in uber mode : false
2020-05-03 23:00:37,596 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-03 23:00:37,609 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-03 23:00:38,597 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:00:38,598 INFO  mapreduce.Job - Job job_local1955852942_0001 completed successfully
2020-05-03 23:00:38,614 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2967395
		FILE: Number of bytes written=4660321
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=652
		Map output bytes=66174
		Map output materialized bytes=4430
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=4430
		Reduce input records=652
		Reduce output records=0
		Spilled Records=1304
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=805306368
	Generator
		SCHEDULE_REJECTED=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=55906
	File Output Format Counters 
		Bytes Written=16
2020-05-03 23:00:38,614 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-03 23:00:38,621 INFO  crawl.Generator - Generator:     10  SCHEDULE_REJECTED
2020-05-03 23:00:38,623 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-03 23:00:39,627 INFO  crawl.Generator - Generator: segment: crawl/segments/20200503230039
2020-05-03 23:00:40,053 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:00:40,054 INFO  mapreduce.Job - Running job: job_local337423516_0002
2020-05-03 23:00:41,059 INFO  mapreduce.Job - Job job_local337423516_0002 running in uber mode : false
2020-05-03 23:00:41,060 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:00:41,060 INFO  mapreduce.Job - Job job_local337423516_0002 completed successfully
2020-05-03 23:00:41,065 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5992906
		FILE: Number of bytes written=9312535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=652
		Map output records=652
		Map output bytes=91924
		Map output materialized bytes=7281
		Input split bytes=366
		Combine input records=0
		Combine output records=0
		Reduce input groups=652
		Reduce shuffle bytes=7281
		Reduce input records=652
		Reduce output records=652
		Spilled Records=1304
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1332215808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=72870
	File Output Format Counters 
		Bytes Written=67432
2020-05-03 23:00:41,152 INFO  crawl.Generator - Generator: finished at 2020-05-03 23:00:41, elapsed: 00:00:05
2020-05-03 23:00:42,327 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-03 23:00:42
2020-05-03 23:00:42,328 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200503230039
2020-05-03 23:00:42,329 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588532442329  (2020-05-04 02:00:42)
2020-05-03 23:00:42,630 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:00:43,940 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:00:43,941 INFO  mapreduce.Job - Running job: job_local1603487480_0001
2020-05-03 23:00:44,547 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-03 23:00:44,547 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-03 23:00:44,547 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-03 23:00:44,655 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 652 records hit by time limit : 0
2020-05-03 23:00:44,949 INFO  mapreduce.Job - Job job_local1603487480_0001 running in uber mode : false
2020-05-03 23:00:44,951 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 23:00:45,190 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,215 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,216 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com.cn/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:45,465 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-03 23:00:45,466 INFO  http.Http - http.proxy.host = null
2020-05-03 23:00:45,467 INFO  http.Http - http.proxy.port = 8080
2020-05-03 23:00:45,467 INFO  http.Http - http.proxy.exception.list = false
2020-05-03 23:00:45,467 INFO  http.Http - http.timeout = 30000
2020-05-03 23:00:45,467 INFO  http.Http - http.content.limit = -1
2020-05-03 23:00:45,467 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-03 23:00:45,467 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-03 23:00:45,467 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-03 23:00:45,467 INFO  http.Http - http.enable.cookie.header = true
2020-05-03 23:00:45,467 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,468 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,468 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://www.icloud.com/ (queue crawl delay=1ms)
2020-05-03 23:00:45,469 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,469 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,469 INFO  fetcher.FetcherThread - FetcherThread 41 fetching https://appleid.apple.com/us/ (queue crawl delay=1ms)
2020-05-03 23:00:45,470 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,472 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,472 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://support.apple.com/ (queue crawl delay=1ms)
2020-05-03 23:00:45,472 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,474 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,474 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.itunes.com/download (queue crawl delay=1ms)
2020-05-03 23:00:45,476 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,479 INFO  fetcher.FetcherThread - FetcherThread 44 fetching https://www.apple.com/befr/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:45,480 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,480 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,482 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,482 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,484 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,485 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,486 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,487 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,499 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,501 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,502 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,503 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,504 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,505 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,506 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,506 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,507 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,508 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,508 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,509 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,509 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,510 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,510 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,511 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,512 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,513 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,516 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,517 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,520 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,521 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,521 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,522 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,522 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,524 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,524 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,526 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,526 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,529 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,529 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,530 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,531 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,533 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,638 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,639 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,640 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,641 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,641 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,642 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,642 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,643 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,644 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,646 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,646 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,647 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,648 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,649 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,650 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,653 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,653 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,654 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,655 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,656 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,667 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,668 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,669 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,670 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,670 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,671 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,672 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,673 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,674 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,675 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,675 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,676 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,677 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,677 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,679 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,681 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,682 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,682 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,683 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,684 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,685 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,686 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,687 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:00:45,687 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:00:45,693 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-03 23:00:45,696 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-03 23:00:45,696 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-03 23:00:46,399 INFO  fetcher.FetcherThread - FetcherThread 40 fetching https://support.apple.com/kb/HT3939 (queue crawl delay=1ms)
2020-05-03 23:00:46,645 INFO  fetcher.FetcherThread - FetcherThread 44 fetching https://support.apple.com/kb/HT209044 (queue crawl delay=1ms)
2020-05-03 23:00:46,646 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-03 23:00:46,646 INFO  fetcher.FetcherThread - FetcherThread 70 fetching https://www.apple.com/id/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:46,698 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=44, fetchQueues.totalSize=643, fetchQueues.getQueueCount=5
2020-05-03 23:00:46,877 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-03 23:00:47,678 INFO  fetcher.FetcherThread - FetcherThread 70 fetching https://www.apple.com/il/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:47,703 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=46, fetchQueues.totalSize=642, fetchQueues.getQueueCount=4
2020-05-03 23:00:48,152 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-03 23:00:48,703 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=642, fetchQueues.getQueueCount=1
2020-05-03 23:00:48,881 INFO  fetcher.FetcherThread - FetcherThread 44 fetching https://www.apple.com/in/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:49,186 INFO  fetcher.FetcherThread - FetcherThread 79 fetching https://www.apple.com/ie/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:49,708 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=640, fetchQueues.getQueueCount=1
2020-05-03 23:00:50,085 INFO  fetcher.FetcherThread - FetcherThread 79 fetching https://www.apple.com/cz/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:50,711 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=639, fetchQueues.getQueueCount=1
2020-05-03 23:00:51,154 INFO  fetcher.FetcherThread - FetcherThread 68 fetching https://www.apple.com/me/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:51,712 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=638, fetchQueues.getQueueCount=1
2020-05-03 23:00:52,280 INFO  fetcher.FetcherThread - FetcherThread 70 fetching https://www.apple.com/bh/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:52,712 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=637, fetchQueues.getQueueCount=1
2020-05-03 23:00:53,433 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/apple-music/ (queue crawl delay=1ms)
2020-05-03 23:00:53,713 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=636, fetchQueues.getQueueCount=1
2020-05-03 23:00:53,721 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/apple-card/ (queue crawl delay=1ms)
2020-05-03 23:00:54,011 INFO  fetcher.FetcherThread - FetcherThread 47 fetching https://www.apple.com/jp/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:54,708 INFO  fetcher.FetcherThread - FetcherThread 84 fetching https://www.apple.com/us/shop/goto/account (queue crawl delay=1ms)
2020-05-03 23:00:54,714 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=633, fetchQueues.getQueueCount=1
2020-05-03 23:00:55,623 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-03 23:00:55,640 INFO  fetcher.FetcherThread - FetcherThread 79 fetching https://www.apple.com/hk/en/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:55,714 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=632, fetchQueues.getQueueCount=1
2020-05-03 23:00:56,003 INFO  fetcher.FetcherThread - FetcherThread 45 fetching https://www.apple.com/kw-ar/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:56,716 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=631, fetchQueues.getQueueCount=1
2020-05-03 23:00:56,755 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/us/shop/goto/payment_plan (queue crawl delay=1ms)
2020-05-03 23:00:56,971 INFO  mapreduce.Job -  map 67% reduce 0%
2020-05-03 23:00:57,175 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-03 23:00:57,176 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/li/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:57,717 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=629, fetchQueues.getQueueCount=1
2020-05-03 23:00:57,914 INFO  fetcher.FetcherThread - FetcherThread 79 fetching https://www.apple.com/today/camp/ (queue crawl delay=1ms)
2020-05-03 23:00:58,676 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/cf/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:58,719 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=627, fetchQueues.getQueueCount=1
2020-05-03 23:00:59,419 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/gn/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:00:59,719 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=626, fetchQueues.getQueueCount=1
2020-05-03 23:01:00,645 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/us/shop/goto/iphone/iphone_upgrade_program (queue crawl delay=1ms)
2020-05-03 23:01:00,720 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=625, fetchQueues.getQueueCount=1
2020-05-03 23:01:01,074 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2020-05-03 23:01:01,075 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/in/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:01,721 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=624, fetchQueues.getQueueCount=1
2020-05-03 23:01:02,036 INFO  fetcher.FetcherThread - FetcherThread 42 fetching https://www.apple.com/il/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:02,698 INFO  fetcher.FetcherThread - FetcherThread 74 fetching https://www.apple.com/kr/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:02,722 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=622, fetchQueues.getQueueCount=1
2020-05-03 23:01:03,724 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=50, fetchQueues.totalSize=622, fetchQueues.getQueueCount=1
2020-05-03 23:01:03,735 INFO  fetcher.FetcherThread - FetcherThread 47 fetching https://www.apple.com/th/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:04,725 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=621, fetchQueues.getQueueCount=1
2020-05-03 23:01:05,091 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/mt/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:05,726 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=620, fetchQueues.getQueueCount=1
2020-05-03 23:01:06,047 INFO  fetcher.FetcherThread - FetcherThread 46 fetching https://www.apple.com/ca/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:06,726 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=619, fetchQueues.getQueueCount=1
2020-05-03 23:01:06,838 INFO  fetcher.FetcherThread - FetcherThread 46 fetching https://www.apple.com/hk/en/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:07,564 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/ke/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:07,727 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=617, fetchQueues.getQueueCount=1
2020-05-03 23:01:08,732 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=617, fetchQueues.getQueueCount=1
2020-05-03 23:01:08,739 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/kw-ar/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:09,733 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=616, fetchQueues.getQueueCount=1
2020-05-03 23:01:09,915 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/retail/geniusbar/ (queue crawl delay=1ms)
2020-05-03 23:01:10,685 INFO  fetcher.FetcherThread - FetcherThread 79 fetching https://www.apple.com/mg/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:10,735 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=614, fetchQueues.getQueueCount=1
2020-05-03 23:01:11,611 INFO  fetcher.FetcherThread - FetcherThread 61 fetching https://www.apple.com/bh/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:11,741 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=613, fetchQueues.getQueueCount=1
2020-05-03 23:01:12,382 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/mk/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:12,745 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=612, fetchQueues.getQueueCount=1
2020-05-03 23:01:13,420 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/au/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:13,749 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=611, fetchQueues.getQueueCount=1
2020-05-03 23:01:14,369 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://www.apple.com/ml/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:14,752 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=610, fetchQueues.getQueueCount=1
2020-05-03 23:01:15,612 INFO  fetcher.FetcherThread - FetcherThread 57 fetching https://www.apple.com/jp/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:15,753 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=609, fetchQueues.getQueueCount=1
2020-05-03 23:01:16,725 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/lt/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:16,755 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=608, fetchQueues.getQueueCount=1
2020-05-03 23:01:17,758 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/id/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:17,758 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=607, fetchQueues.getQueueCount=1
2020-05-03 23:01:18,029 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/cl/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:18,762 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=606, fetchQueues.getQueueCount=1
2020-05-03 23:01:18,771 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/gn/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:19,515 INFO  fetcher.FetcherThread - FetcherThread 66 fetching https://www.apple.com/in/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:19,765 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=604, fetchQueues.getQueueCount=1
2020-05-03 23:01:20,488 INFO  fetcher.FetcherThread - FetcherThread 64 fetching https://www.apple.com/ml/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:20,767 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=603, fetchQueues.getQueueCount=1
2020-05-03 23:01:21,542 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/chfr/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:21,772 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=602, fetchQueues.getQueueCount=1
2020-05-03 23:01:22,777 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=602, fetchQueues.getQueueCount=1
2020-05-03 23:01:23,084 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/kr/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:23,783 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=601, fetchQueues.getQueueCount=1
2020-05-03 23:01:24,789 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=601, fetchQueues.getQueueCount=1
2020-05-03 23:01:25,790 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=601, fetchQueues.getQueueCount=1
2020-05-03 23:01:26,112 INFO  fetcher.FetcherThread - FetcherThread 46 fetching https://www.apple.com/mt/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:26,795 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=600, fetchQueues.getQueueCount=1
2020-05-03 23:01:27,089 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/bh-ar/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:37,697 INFO  crawl.Injector - Injector: starting at 2020-05-03 23:01:37
2020-05-03 23:01:37,700 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2020-05-03 23:01:37,700 INFO  crawl.Injector - Injector: urlDir: urls
2020-05-03 23:01:37,701 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2020-05-03 23:01:37,887 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:01:38,294 INFO  crawl.Injector - Injecting seed URL file file:/Users/apple/apache/apache-nutch-1.16/urls/seed.txt
2020-05-03 23:01:39,405 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:01:39,406 INFO  mapreduce.Job - Running job: job_local132751060_0001
2020-05-03 23:01:40,012 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2020-05-03 23:01:40,233 INFO  crawl.Injector - Injector: overwrite: false
2020-05-03 23:01:40,233 INFO  crawl.Injector - Injector: update: false
2020-05-03 23:01:40,413 INFO  mapreduce.Job - Job job_local132751060_0001 running in uber mode : false
2020-05-03 23:01:40,414 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:01:40,416 INFO  mapreduce.Job - Job job_local132751060_0001 completed successfully
2020-05-03 23:01:40,428 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1857060
		FILE: Number of bytes written=2984876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=694
		Map output materialized bytes=720
		Input split bytes=283
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=720
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=10
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=1118
2020-05-03 23:01:40,440 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2020-05-03 23:01:40,440 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 10
2020-05-03 23:01:40,440 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2020-05-03 23:01:40,441 INFO  crawl.Injector - Injector: Total new urls injected: 10
2020-05-03 23:01:40,460 INFO  crawl.Injector - Injector: finished at 2020-05-03 23:01:40, elapsed: 00:00:02
2020-05-03 23:01:41,538 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:01:41,916 INFO  crawl.Generator - Generator: starting at 2020-05-03 23:01:41
2020-05-03 23:01:41,916 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2020-05-03 23:01:41,916 INFO  crawl.Generator - Generator: filtering: false
2020-05-03 23:01:41,916 INFO  crawl.Generator - Generator: normalizing: true
2020-05-03 23:01:41,919 INFO  crawl.Generator - Generator: topN: 50000
2020-05-03 23:01:42,739 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:01:42,740 INFO  mapreduce.Job - Running job: job_local2013340084_0001
2020-05-03 23:01:43,210 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 23:01:43,211 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 23:01:43,211 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 23:01:43,219 INFO  regex.RegexURLNormalizer - can't find rules for scope 'partition', using default
2020-05-03 23:01:43,405 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2020-05-03 23:01:43,746 INFO  mapreduce.Job - Job job_local2013340084_0001 running in uber mode : false
2020-05-03 23:01:43,747 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:01:43,748 INFO  mapreduce.Job - Job job_local2013340084_0001 completed successfully
2020-05-03 23:01:43,768 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2785365
		FILE: Number of bytes written=4496100
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=984
		Map output materialized bytes=195
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=195
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=805306368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=16
2020-05-03 23:01:43,768 INFO  crawl.Generator - Generator: number of items rejected during selection:
2020-05-03 23:01:43,775 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2020-05-03 23:01:44,775 INFO  crawl.Generator - Generator: segment: crawl/segments/20200503230144
2020-05-03 23:01:45,025 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:01:45,025 INFO  mapreduce.Job - Running job: job_local333995740_0002
2020-05-03 23:01:46,025 INFO  mapreduce.Job - Job job_local333995740_0002 running in uber mode : false
2020-05-03 23:01:46,026 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:01:46,026 INFO  mapreduce.Job - Job job_local333995740_0002 completed successfully
2020-05-03 23:01:46,030 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3714768
		FILE: Number of bytes written=5985120
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=1348
		Map output materialized bytes=218
		Input split bytes=183
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=218
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=747634688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1192
	File Output Format Counters 
		Bytes Written=1090
2020-05-03 23:01:46,056 INFO  crawl.Generator - Generator: finished at 2020-05-03 23:01:46, elapsed: 00:00:04
2020-05-03 23:01:47,062 INFO  fetcher.Fetcher - Fetcher: starting at 2020-05-03 23:01:47
2020-05-03 23:01:47,063 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20200503230144
2020-05-03 23:01:47,064 INFO  fetcher.Fetcher - Fetcher Timelimit set for : 1588532507063  (2020-05-04 02:01:47)
2020-05-03 23:01:47,282 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:01:48,421 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:01:48,422 INFO  mapreduce.Job - Running job: job_local78458089_0001
2020-05-03 23:01:48,600 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2020-05-03 23:01:48,600 INFO  fetcher.Fetcher - Fetcher: threads: 50
2020-05-03 23:01:48,600 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2020-05-03 23:01:48,616 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 10 records hit by time limit : 0
2020-05-03 23:01:48,899 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:48,918 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:48,920 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:48,920 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-mini/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:48,922 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:48,924 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,145 INFO  protocol.RobotRulesParser - robots.txt whitelist not configured.
2020-05-03 23:01:49,148 INFO  http.Http - http.proxy.host = null
2020-05-03 23:01:49,149 INFO  http.Http - http.proxy.port = 8080
2020-05-03 23:01:49,149 INFO  http.Http - http.proxy.exception.list = false
2020-05-03 23:01:49,149 INFO  http.Http - http.timeout = 30000
2020-05-03 23:01:49,149 INFO  http.Http - http.content.limit = -1
2020-05-03 23:01:49,149 INFO  http.Http - http.agent = nutch/Nutch-1.16
2020-05-03 23:01:49,149 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2020-05-03 23:01:49,149 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2020-05-03 23:01:49,149 INFO  http.Http - http.enable.cookie.header = true
2020-05-03 23:01:49,154 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,155 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,158 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,159 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,160 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,161 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,162 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,163 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,168 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,168 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,170 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,171 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,172 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,172 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,173 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,174 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,175 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,176 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,177 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,178 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,179 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,180 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,183 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,184 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,186 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,189 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,191 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,192 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,193 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,194 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,195 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,196 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,197 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,200 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,201 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,203 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,204 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,204 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,205 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,206 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,208 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,209 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,210 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,211 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,211 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,212 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,212 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,217 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,218 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,219 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,220 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,220 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,222 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,223 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,225 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,226 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,226 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,227 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,227 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,228 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,229 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,230 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,231 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,233 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,234 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,234 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,235 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,236 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,240 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,240 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,243 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,244 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,246 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,324 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,325 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,331 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,338 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,339 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,340 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,340 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,343 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,344 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,344 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,345 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,346 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,347 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,354 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,355 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,357 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:01:49,357 INFO  fetcher.FetcherThread - FetcherThread 35 Using queue mode : byHost
2020-05-03 23:01:49,358 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2020-05-03 23:01:49,358 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2020-05-03 23:01:49,358 INFO  fetcher.Fetcher - fetcher.maxNum.threads can't be < than 50 : using 50 instead
2020-05-03 23:01:49,431 INFO  mapreduce.Job - Job job_local78458089_0001 running in uber mode : false
2020-05-03 23:01:49,432 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 23:01:50,365 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2020-05-03 23:01:50,770 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/ipad-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:51,062 INFO  fetcher.FetcherThread - FetcherThread 39 fetching https://www.apple.com/macbook-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:51,366 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2020-05-03 23:01:51,757 INFO  fetcher.FetcherThread - FetcherThread 78 fetching https://www.apple.com/macbook-pro-13/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:52,369 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2020-05-03 23:01:53,047 INFO  fetcher.FetcherThread - FetcherThread 78 fetching https://www.apple.com/iphone-11/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:53,371 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2020-05-03 23:01:53,840 INFO  fetcher.FetcherThread - FetcherThread 80 fetching https://www.apple.com/iphone-se/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:54,372 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2020-05-03 23:01:54,372 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588521713795
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   now           = 1588521714373
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/macbook-pro-16/specs/
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-11-pro/specs/
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/iphone-xr/specs/
2020-05-03 23:01:54,373 INFO  fetcher.FetchItemQueue -   3. https://www.apple.com/ipad-air/specs/
2020-05-03 23:01:55,028 INFO  fetcher.FetcherThread - FetcherThread 80 fetching https://www.apple.com/macbook-pro-16/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:55,374 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2020-05-03 23:01:55,374 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 23:01:55,374 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 23:01:55,374 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 23:01:55,374 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 23:01:55,375 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 23:01:55,375 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588521715028
2020-05-03 23:01:55,375 INFO  fetcher.FetchItemQueue -   now           = 1588521715375
2020-05-03 23:01:55,375 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/iphone-11-pro/specs/
2020-05-03 23:01:55,375 INFO  fetcher.FetchItemQueue -   1. https://www.apple.com/iphone-xr/specs/
2020-05-03 23:01:55,375 INFO  fetcher.FetchItemQueue -   2. https://www.apple.com/ipad-air/specs/
2020-05-03 23:01:55,774 INFO  fetcher.FetcherThread - FetcherThread 80 fetching https://www.apple.com/iphone-11-pro/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:56,183 INFO  fetcher.FetcherThread - FetcherThread 43 fetching https://www.apple.com/iphone-xr/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:56,376 INFO  fetcher.Fetcher - -activeThreads=50, spinWaiting=49, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueues - * queue: www.apple.com
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueue -   crawlDelay    = 1
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1588521716003
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueue -   now           = 1588521716376
2020-05-03 23:01:56,376 INFO  fetcher.FetchItemQueue -   0. https://www.apple.com/ipad-air/specs/
2020-05-03 23:01:56,502 INFO  fetcher.FetcherThread - FetcherThread 80 fetching https://www.apple.com/ipad-air/specs/ (queue crawl delay=1ms)
2020-05-03 23:01:56,684 INFO  fetcher.FetcherThread - FetcherThread 42 has no more work available
2020-05-03 23:01:56,684 INFO  fetcher.FetcherThread - FetcherThread 44 has no more work available
2020-05-03 23:01:56,684 INFO  fetcher.FetcherThread - FetcherThread 44 -finishing thread FetcherThread, activeThreads=48
2020-05-03 23:01:56,684 INFO  fetcher.FetcherThread - FetcherThread 45 has no more work available
2020-05-03 23:01:56,684 INFO  fetcher.FetcherThread - FetcherThread 42 -finishing thread FetcherThread, activeThreads=49
2020-05-03 23:01:56,684 INFO  fetcher.FetcherThread - FetcherThread 41 has no more work available
2020-05-03 23:01:56,685 INFO  fetcher.FetcherThread - FetcherThread 45 -finishing thread FetcherThread, activeThreads=47
2020-05-03 23:01:56,685 INFO  fetcher.FetcherThread - FetcherThread 41 -finishing thread FetcherThread, activeThreads=46
2020-05-03 23:01:56,690 INFO  fetcher.FetcherThread - FetcherThread 48 has no more work available
2020-05-03 23:01:56,690 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2020-05-03 23:01:56,691 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=44
2020-05-03 23:01:56,691 INFO  fetcher.FetcherThread - FetcherThread 48 -finishing thread FetcherThread, activeThreads=45
2020-05-03 23:01:56,692 INFO  fetcher.FetcherThread - FetcherThread 46 has no more work available
2020-05-03 23:01:56,692 INFO  fetcher.FetcherThread - FetcherThread 46 -finishing thread FetcherThread, activeThreads=43
2020-05-03 23:01:56,690 INFO  fetcher.FetcherThread - FetcherThread 47 has no more work available
2020-05-03 23:01:56,692 INFO  fetcher.FetcherThread - FetcherThread 47 -finishing thread FetcherThread, activeThreads=42
2020-05-03 23:01:56,704 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2020-05-03 23:01:56,705 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=41
2020-05-03 23:01:56,704 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2020-05-03 23:01:56,705 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=40
2020-05-03 23:01:56,707 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2020-05-03 23:01:56,707 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=39
2020-05-03 23:01:56,707 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2020-05-03 23:01:56,707 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2020-05-03 23:01:56,708 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=37
2020-05-03 23:01:56,707 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2020-05-03 23:01:56,708 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=37
2020-05-03 23:01:56,708 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=36
2020-05-03 23:01:56,707 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2020-05-03 23:01:56,708 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=35
2020-05-03 23:01:56,721 INFO  fetcher.FetcherThread - FetcherThread 60 has no more work available
2020-05-03 23:01:56,722 INFO  fetcher.FetcherThread - FetcherThread 60 -finishing thread FetcherThread, activeThreads=34
2020-05-03 23:01:56,721 INFO  fetcher.FetcherThread - FetcherThread 59 has no more work available
2020-05-03 23:01:56,722 INFO  fetcher.FetcherThread - FetcherThread 59 -finishing thread FetcherThread, activeThreads=33
2020-05-03 23:01:56,721 INFO  fetcher.FetcherThread - FetcherThread 61 has no more work available
2020-05-03 23:01:56,721 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2020-05-03 23:01:56,722 INFO  fetcher.FetcherThread - FetcherThread 61 -finishing thread FetcherThread, activeThreads=32
2020-05-03 23:01:56,722 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=31
2020-05-03 23:01:56,721 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2020-05-03 23:01:56,722 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=30
2020-05-03 23:01:56,727 INFO  fetcher.FetcherThread - FetcherThread 65 has no more work available
2020-05-03 23:01:56,727 INFO  fetcher.FetcherThread - FetcherThread 65 -finishing thread FetcherThread, activeThreads=29
2020-05-03 23:01:56,727 INFO  fetcher.FetcherThread - FetcherThread 64 has no more work available
2020-05-03 23:01:56,728 INFO  fetcher.FetcherThread - FetcherThread 64 -finishing thread FetcherThread, activeThreads=28
2020-05-03 23:01:56,727 INFO  fetcher.FetcherThread - FetcherThread 63 has no more work available
2020-05-03 23:01:56,728 INFO  fetcher.FetcherThread - FetcherThread 63 -finishing thread FetcherThread, activeThreads=27
2020-05-03 23:01:56,727 INFO  fetcher.FetcherThread - FetcherThread 62 has no more work available
2020-05-03 23:01:56,728 INFO  fetcher.FetcherThread - FetcherThread 62 -finishing thread FetcherThread, activeThreads=26
2020-05-03 23:01:56,755 INFO  fetcher.FetcherThread - FetcherThread 68 has no more work available
2020-05-03 23:01:56,755 INFO  fetcher.FetcherThread - FetcherThread 69 has no more work available
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 39 has no more work available
2020-05-03 23:01:56,755 INFO  fetcher.FetcherThread - FetcherThread 70 has no more work available
2020-05-03 23:01:56,755 INFO  fetcher.FetcherThread - FetcherThread 66 has no more work available
2020-05-03 23:01:56,755 INFO  fetcher.FetcherThread - FetcherThread 67 has no more work available
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 69 -finishing thread FetcherThread, activeThreads=24
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 67 -finishing thread FetcherThread, activeThreads=20
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 76 has no more work available
2020-05-03 23:01:56,755 INFO  fetcher.FetcherThread - FetcherThread 73 has no more work available
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 68 -finishing thread FetcherThread, activeThreads=25
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 77 has no more work available
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 75 has no more work available
2020-05-03 23:01:56,757 INFO  fetcher.FetcherThread - FetcherThread 75 -finishing thread FetcherThread, activeThreads=16
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 74 has no more work available
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 71 has no more work available
2020-05-03 23:01:56,757 INFO  fetcher.FetcherThread - FetcherThread 71 -finishing thread FetcherThread, activeThreads=15
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 76 -finishing thread FetcherThread, activeThreads=19
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 72 has no more work available
2020-05-03 23:01:56,758 INFO  fetcher.FetcherThread - FetcherThread 72 -finishing thread FetcherThread, activeThreads=13
2020-05-03 23:01:56,757 INFO  fetcher.FetcherThread - FetcherThread 74 -finishing thread FetcherThread, activeThreads=14
2020-05-03 23:01:56,757 INFO  fetcher.FetcherThread - FetcherThread 77 -finishing thread FetcherThread, activeThreads=17
2020-05-03 23:01:56,757 INFO  fetcher.FetcherThread - FetcherThread 73 -finishing thread FetcherThread, activeThreads=18
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 39 -finishing thread FetcherThread, activeThreads=23
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 66 -finishing thread FetcherThread, activeThreads=21
2020-05-03 23:01:56,756 INFO  fetcher.FetcherThread - FetcherThread 70 -finishing thread FetcherThread, activeThreads=22
2020-05-03 23:01:56,775 INFO  fetcher.FetcherThread - FetcherThread 79 has no more work available
2020-05-03 23:01:56,775 INFO  fetcher.FetcherThread - FetcherThread 79 -finishing thread FetcherThread, activeThreads=12
2020-05-03 23:01:56,800 INFO  fetcher.FetcherThread - FetcherThread 78 has no more work available
2020-05-03 23:01:56,800 INFO  fetcher.FetcherThread - FetcherThread 78 -finishing thread FetcherThread, activeThreads=11
2020-05-03 23:01:56,860 INFO  fetcher.FetcherThread - FetcherThread 81 has no more work available
2020-05-03 23:01:56,860 INFO  fetcher.FetcherThread - FetcherThread 81 -finishing thread FetcherThread, activeThreads=10
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 86 has no more work available
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 82 has no more work available
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 85 has no more work available
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 85 -finishing thread FetcherThread, activeThreads=7
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 84 has no more work available
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 82 -finishing thread FetcherThread, activeThreads=8
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 84 -finishing thread FetcherThread, activeThreads=6
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 83 has no more work available
2020-05-03 23:01:56,873 INFO  fetcher.FetcherThread - FetcherThread 83 -finishing thread FetcherThread, activeThreads=5
2020-05-03 23:01:56,872 INFO  fetcher.FetcherThread - FetcherThread 86 -finishing thread FetcherThread, activeThreads=9
2020-05-03 23:01:56,882 INFO  fetcher.FetcherThread - FetcherThread 87 has no more work available
2020-05-03 23:01:56,882 INFO  fetcher.FetcherThread - FetcherThread 87 -finishing thread FetcherThread, activeThreads=4
2020-05-03 23:01:56,882 INFO  fetcher.FetcherThread - FetcherThread 88 has no more work available
2020-05-03 23:01:56,882 INFO  fetcher.FetcherThread - FetcherThread 88 -finishing thread FetcherThread, activeThreads=3
2020-05-03 23:01:56,939 INFO  fetcher.FetcherThread - FetcherThread 40 has no more work available
2020-05-03 23:01:56,939 INFO  fetcher.FetcherThread - FetcherThread 40 -finishing thread FetcherThread, activeThreads=2
2020-05-03 23:01:56,972 INFO  fetcher.FetcherThread - FetcherThread 43 has no more work available
2020-05-03 23:01:56,972 INFO  fetcher.FetcherThread - FetcherThread 43 -finishing thread FetcherThread, activeThreads=1
2020-05-03 23:01:57,273 INFO  fetcher.FetcherThread - FetcherThread 80 has no more work available
2020-05-03 23:01:57,273 INFO  fetcher.FetcherThread - FetcherThread 80 -finishing thread FetcherThread, activeThreads=0
2020-05-03 23:01:57,377 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2020-05-03 23:01:57,377 INFO  fetcher.Fetcher - -activeThreads=0
2020-05-03 23:01:57,450 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 23:01:58,451 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:01:58,451 INFO  mapreduce.Job - Job job_local78458089_0001 completed successfully
2020-05-03 23:01:58,470 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3263141
		FILE: Number of bytes written=5505006
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=20
		Map output bytes=1158118
		Map output materialized bytes=185697
		Input split bytes=165
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=185697
		Reduce input records=20
		Reduce output records=20
		Spilled Records=40
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=91
		Total committed heap usage (bytes)=967311360
	FetcherStatus
		bytes_downloaded=1148333
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1090
	File Output Format Counters 
		Bytes Written=193052
2020-05-03 23:01:58,470 INFO  fetcher.Fetcher - Fetcher: finished at 2020-05-03 23:01:58, elapsed: 00:00:11
2020-05-03 23:01:59,584 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:01:59,937 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 23:01:59
2020-05-03 23:01:59,937 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503230144
2020-05-03 23:02:00,744 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:00,745 INFO  mapreduce.Job - Running job: job_local299226370_0001
2020-05-03 23:02:01,758 INFO  mapreduce.Job - Job job_local299226370_0001 running in uber mode : false
2020-05-03 23:02:01,759 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 23:02:02,287 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 23:02:02,301 INFO  parse.ParseSegment - Parsed (1077ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 23:02:02,437 INFO  parse.ParseSegment - Parsed (128ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 23:02:02,545 INFO  parse.ParseSegment - Parsed (103ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 23:02:02,639 INFO  parse.ParseSegment - Parsed (89ms):https://www.apple.com/iphone-11/specs/
2020-05-03 23:02:02,738 INFO  parse.ParseSegment - Parsed (96ms):https://www.apple.com/iphone-se/specs/
2020-05-03 23:02:02,812 INFO  parse.ParseSegment - Parsed (71ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 23:02:02,894 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-16/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 23:02:02,899 INFO  parse.ParseSegment - Parsed (85ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 23:02:03,090 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 23:02:03,091 INFO  parse.ParseSegment - Parsed (68ms):https://www.apple.com/ipad-air/specs/
2020-05-03 23:02:03,125 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-air/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 23:02:03,125 INFO  parse.ParseSegment - Parsed (33ms):https://www.apple.com/macbook-air/specs/
2020-05-03 23:02:03,173 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-13/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 23:02:03,174 INFO  parse.ParseSegment - Parsed (46ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 23:02:03,293 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:02:03,417 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 23:02:03,537 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:02:03,612 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 23:02:03,769 INFO  mapreduce.Job -  map 100% reduce 50%
2020-05-03 23:02:04,769 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:04,770 INFO  mapreduce.Job - Job job_local299226370_0001 completed successfully
2020-05-03 23:02:04,786 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4660372
		FILE: Number of bytes written=6680024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=406850
		Map output materialized bytes=95943
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=95943
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=81
		Total committed heap usage (bytes)=1594884096
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189734
	File Output Format Counters 
		Bytes Written=0
2020-05-03 23:02:04,797 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 23:02:04, elapsed: 00:00:04
2020-05-03 23:02:05,880 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:02:06,283 INFO  crawl.CrawlDb - CrawlDb update: starting at 2020-05-03 23:02:06
2020-05-03 23:02:06,284 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2020-05-03 23:02:06,284 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20200503230144]
2020-05-03 23:02:06,284 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2020-05-03 23:02:06,284 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2020-05-03 23:02:06,284 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2020-05-03 23:02:06,284 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2020-05-03 23:02:06,288 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2020-05-03 23:02:07,122 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:07,123 INFO  mapreduce.Job - Running job: job_local1001627545_0001
2020-05-03 23:02:08,129 INFO  mapreduce.Job - Job job_local1001627545_0001 running in uber mode : false
2020-05-03 23:02:08,130 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 23:02:08,335 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 23:02:08,335 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 23:02:08,335 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 23:02:08,437 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2020-05-03 23:02:08,437 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2020-05-03 23:02:08,437 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2020-05-03 23:02:09,132 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:09,133 INFO  mapreduce.Job - Job job_local1001627545_0001 completed successfully
2020-05-03 23:02:09,151 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=7077192
		FILE: Number of bytes written=10593362
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1030
		Map output records=1030
		Map output bytes=76189
		Map output materialized bytes=6493
		Input split bytes=805
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=6493
		Reduce input records=1030
		Reduce output records=662
		Spilled Records=2060
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=3775922176
	CrawlDB status
		db_fetched=10
		db_unfetched=652
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=82057
	File Output Format Counters 
		Bytes Written=56565
2020-05-03 23:02:09,174 INFO  crawl.CrawlDb - CrawlDb update: finished at 2020-05-03 23:02:09, elapsed: 00:00:02
2020-05-03 23:02:10,368 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:02:10,742 INFO  crawl.LinkDb - LinkDb: starting at 2020-05-03 23:02:10
2020-05-03 23:02:10,742 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2020-05-03 23:02:10,742 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2020-05-03 23:02:10,742 INFO  crawl.LinkDb - LinkDb: URL filter: true
2020-05-03 23:02:10,742 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2020-05-03 23:02:10,743 INFO  crawl.LinkDb - LinkDb: adding segment: crawl/segments/20200503230144
2020-05-03 23:02:11,567 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:11,567 INFO  mapreduce.Job - Running job: job_local2099344349_0001
2020-05-03 23:02:12,572 INFO  mapreduce.Job - Job job_local2099344349_0001 running in uber mode : false
2020-05-03 23:02:12,574 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:12,575 INFO  mapreduce.Job - Job job_local2099344349_0001 completed successfully
2020-05-03 23:02:12,591 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2889207
		FILE: Number of bytes written=4484311
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=7
		Map output bytes=650
		Map output materialized bytes=676
		Input split bytes=332
		Combine input records=7
		Combine output records=7
		Reduce input groups=7
		Reduce shuffle bytes=676
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=36602
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 23:02:12,591 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2020-05-03 23:02:12,869 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:12,869 INFO  mapreduce.Job - Running job: job_local1505928587_0002
2020-05-03 23:02:13,203 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 23:02:13,283 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2020-05-03 23:02:13,870 INFO  mapreduce.Job - Job job_local1505928587_0002 running in uber mode : false
2020-05-03 23:02:13,870 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:13,871 INFO  mapreduce.Job - Job job_local1505928587_0002 completed successfully
2020-05-03 23:02:13,874 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5687475
		FILE: Number of bytes written=8975137
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=1300
		Map output materialized bytes=1340
		Input split bytes=295
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=1340
		Reduce input records=14
		Reduce output records=7
		Spilled Records=28
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1648361472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1758
	File Output Format Counters 
		Bytes Written=1109
2020-05-03 23:02:13,896 INFO  crawl.LinkDb - LinkDb: finished at 2020-05-03 23:02:13, elapsed: 00:00:03
2020-05-03 23:02:14,855 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-03 23:02:14
2020-05-03 23:02:15,109 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:02:16,282 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:16,283 INFO  mapreduce.Job - Running job: job_local1496669736_0001
2020-05-03 23:02:17,292 INFO  mapreduce.Job - Job job_local1496669736_0001 running in uber mode : false
2020-05-03 23:02:17,293 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:17,294 INFO  mapreduce.Job - Job job_local1496669736_0001 completed successfully
2020-05-03 23:02:17,314 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2928530
		FILE: Number of bytes written=4493094
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=10
		Map output bytes=2644
		Map output materialized bytes=2686
		Input split bytes=294
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=2686
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1016070144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=56000
	File Output Format Counters 
		Bytes Written=98
2020-05-03 23:02:17,321 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-03 23:02:17,321 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-03 23:02:17,607 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:17,607 INFO  mapreduce.Job - Running job: job_local330027963_0002
2020-05-03 23:02:18,608 INFO  mapreduce.Job - Job job_local330027963_0002 running in uber mode : false
2020-05-03 23:02:18,608 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:18,609 INFO  mapreduce.Job - Job job_local330027963_0002 completed successfully
2020-05-03 23:02:18,615 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=7967660
		FILE: Number of bytes written=12248602
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=662
		Map output bytes=49560
		Map output materialized bytes=50912
		Input split bytes=449
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=50912
		Reduce input records=662
		Reduce output records=662
		Spilled Records=1324
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2443706368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=56098
	File Output Format Counters 
		Bytes Written=56259
2020-05-03 23:02:18,640 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-03 23:02:18, elapsed: 00:00:03
2020-05-03 23:02:19,967 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:02:20,372 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503230144.
2020-05-03 23:02:20,375 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 23:02:20
2020-05-03 23:02:20,456 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2020-05-03 23:02:20,456 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2020-05-03 23:02:20,534 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2020-05-03 23:02:20,535 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 23:02:20,535 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 23:02:20,535 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503230144
2020-05-03 23:02:21,743 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:21,745 INFO  mapreduce.Job - Running job: job_local768414273_0001
2020-05-03 23:02:22,836 INFO  mapreduce.Job - Job job_local768414273_0001 running in uber mode : false
2020-05-03 23:02:22,838 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 23:02:23,620 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 23:02:23,667 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 23:02:24,028 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 23:02:24,724 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 23:02:24,731 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 23:02:25,851 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:25,852 INFO  mapreduce.Job - Job job_local768414273_0001 completed successfully
2020-05-03 23:02:25,876 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13378520
		FILE: Number of bytes written=20629362
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1709
		Map output records=1709
		Map output bytes=428915
		Map output materialized bytes=432453
		Input split bytes=1615
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=432453
		Reduce input records=1709
		Reduce output records=10
		Spilled Records=3418
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=247
		Total committed heap usage (bytes)=4899471360
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=247858
	File Output Format Counters 
		Bytes Written=0
2020-05-03 23:02:25,876 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 23:02:25,893 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 23:02:25,913 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 23:02:25, elapsed: 00:00:05
2020-05-03 23:02:26,871 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-03 23:02:26
2020-05-03 23:02:27,106 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:02:28,330 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:02:28,331 INFO  mapreduce.Job - Running job: job_local759616156_0001
2020-05-03 23:02:29,008 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 23:02:29,031 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 23:02:29,342 INFO  mapreduce.Job - Job job_local759616156_0001 running in uber mode : false
2020-05-03 23:02:29,344 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 23:02:29,431 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-03 23:02:30,345 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:02:30,347 INFO  mapreduce.Job - Job job_local759616156_0001 completed successfully
2020-05-03 23:02:30,366 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1966366
		FILE: Number of bytes written=2980388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=66
		Total committed heap usage (bytes)=477102080
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=55906
	File Output Format Counters 
		Bytes Written=0
2020-05-03 23:02:30,385 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-03 23:02:30, elapsed: 00:00:03
2020-05-03 23:05:32,248 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:05:32,587 INFO  parse.ParseSegment - ParseSegment: starting at 2020-05-03 23:05:32
2020-05-03 23:05:32,587 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20200503230144
2020-05-03 23:05:33,544 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:05:33,545 INFO  mapreduce.Job - Running job: job_local70606512_0001
2020-05-03 23:05:34,553 INFO  mapreduce.Job - Job job_local70606512_0001 running in uber mode : false
2020-05-03 23:05:34,553 INFO  mapreduce.Job -  map 0% reduce 0%
2020-05-03 23:05:35,012 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 23:05:35,021 INFO  parse.ParseSegment - Parsed (1029ms):https://www.apple.com/ipad-mini/specs/
2020-05-03 23:05:35,153 INFO  parse.ParseSegment - Parsed (115ms):https://www.apple.com/ipad-pro/specs/
2020-05-03 23:05:35,258 INFO  parse.ParseSegment - Parsed (95ms):https://www.apple.com/iphone-11-pro/specs/
2020-05-03 23:05:35,358 INFO  parse.ParseSegment - Parsed (98ms):https://www.apple.com/iphone-11/specs/
2020-05-03 23:05:35,441 INFO  parse.ParseSegment - Parsed (81ms):https://www.apple.com/iphone-se/specs/
2020-05-03 23:05:35,505 INFO  parse.ParseSegment - Parsed (61ms):https://www.apple.com/iphone-xr/specs/
2020-05-03 23:05:35,575 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-16/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 23:05:35,579 INFO  parse.ParseSegment - Parsed (72ms):https://www.apple.com/macbook-pro-16/specs/
2020-05-03 23:05:35,746 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2020-05-03 23:05:35,747 INFO  parse.ParseSegment - Parsed (64ms):https://www.apple.com/ipad-air/specs/
2020-05-03 23:05:35,783 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-air/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 23:05:35,784 INFO  parse.ParseSegment - Parsed (35ms):https://www.apple.com/macbook-air/specs/
2020-05-03 23:05:35,838 WARN  nutch.ExtractorParseFilter - Exception on parsing https://www.apple.com/macbook-pro-13/specs/
java.lang.IllegalArgumentException: String must not be empty
	at org.jsoup.helper.Validate.notEmpty(Validate.java:92)
	at org.jsoup.select.QueryParser.byId(QueryParser.java:202)
	at org.jsoup.select.QueryParser.findElements(QueryParser.java:144)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:53)
	at org.jsoup.select.QueryParser.parse(QueryParser.java:39)
	at org.jsoup.select.Selector.<init>(Selector.java:81)
	at org.jsoup.select.Selector.select(Selector.java:94)
	at org.jsoup.nodes.Element.select(Element.java:252)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:31)
	at ir.co.bayan.simorq.zal.extractor.evaluation.CssEvaluator.evaluate(CssEvaluator.java:17)
	at ir.co.bayan.simorq.zal.extractor.model.Expr.extract(Expr.java:31)
	at ir.co.bayan.simorq.zal.extractor.model.Text.extract(Text.java:22)
	at ir.co.bayan.simorq.zal.extractor.model.FunctionHolder.extract(FunctionHolder.java:30)
	at ir.co.bayan.simorq.zal.extractor.model.Fragment.extractFields(Fragment.java:64)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:267)
	at ir.co.bayan.simorq.zal.extractor.model.Document.extract(Document.java:252)
	at ir.co.bayan.simorq.zal.extractor.core.ExtractEngine.extract(ExtractEngine.java:114)
	at ir.co.bayan.simorq.zal.extractor.nutch.ExtractorParseFilter.filter(ExtractorParseFilter.java:39)
	at org.apache.nutch.parse.HtmlParseFilters.filter(HtmlParseFilters.java:45)
	at org.apache.nutch.parse.html.HtmlParser.getParse(HtmlParser.java:256)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:34)
	at org.apache.nutch.parse.ParseCallable.call(ParseCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
2020-05-03 23:05:35,839 INFO  parse.ParseSegment - Parsed (53ms):https://www.apple.com/macbook-pro-13/specs/
2020-05-03 23:05:35,957 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2020-05-03 23:05:36,084 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2020-05-03 23:05:36,561 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:05:36,562 INFO  mapreduce.Job - Job job_local70606512_0001 completed successfully
2020-05-03 23:05:36,576 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=4112438
		FILE: Number of bytes written=6176529
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Map output bytes=406850
		Map output materialized bytes=406902
		Input split bytes=326
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=406902
		Reduce input records=10
		Reduce output records=10
		Spilled Records=20
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=75
		Total committed heap usage (bytes)=1173356544
	ParserStatus
		success=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=189734
	File Output Format Counters 
		Bytes Written=0
2020-05-03 23:05:36,589 INFO  parse.ParseSegment - ParseSegment: finished at 2020-05-03 23:05:36, elapsed: 00:00:03
2020-05-03 23:05:37,584 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:05:37,959 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20200503230144.
2020-05-03 23:05:37,961 INFO  indexer.IndexingJob - Indexer: starting at 2020-05-03 23:05:37
2020-05-03 23:05:37,970 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2020-05-03 23:05:37,970 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2020-05-03 23:05:37,970 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2020-05-03 23:05:37,971 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2020-05-03 23:05:37,972 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2020-05-03 23:05:37,972 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20200503230144
2020-05-03 23:05:38,840 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:05:38,841 INFO  mapreduce.Job - Running job: job_local96232751_0001
2020-05-03 23:05:39,290 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:39,689 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:39,770 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:39,851 INFO  mapreduce.Job - Job job_local96232751_0001 running in uber mode : false
2020-05-03 23:05:39,853 INFO  mapreduce.Job -  map 22% reduce 0%
2020-05-03 23:05:39,919 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:40,024 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:40,183 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:40,251 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:40,294 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:40,329 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2020-05-03 23:05:40,450 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 23:05:40,479 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 23:05:40,855 INFO  mapreduce.Job -  map 100% reduce 0%
2020-05-03 23:05:40,920 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a string value of one of the following "cloud"  or│http                            │
│            │"http". The values represent CloudSolrServer or HttpSolrServer respectively.                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should be indexed. Multiple URL  can  be  provided│http://localhost:8983/solr/nutch│
│            │using comma as a delimiter. When the value of type property is cloud,  the  URL  should  not  include  any│                                │
│            │collections or cores; just the root Solr path.                                                            │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of type property is cloud.                      │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a single update  batch.  Decrease  when  handling  very│1000                            │
│            │large documents to prevent Nutch from running out of memory. Note: It does not explicitly trigger a server│                                │
│            │side commit.                                                                                              │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be written. If it is empty no field will be used.     │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use  the  username  and  password│false                           │
│            │properties to configure your credentials.                                                                 │                                │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                                              │dev-user                        │
├────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                                              │SolrRocks                       │
└────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2020-05-03 23:05:41,545 INFO  solr.SolrIndexWriter - Indexing 10/10 documents
2020-05-03 23:05:41,546 INFO  solr.SolrIndexWriter - Deleting 0 documents
2020-05-03 23:05:41,857 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:05:41,858 INFO  mapreduce.Job - Job job_local96232751_0001 completed successfully
2020-05-03 23:05:41,886 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=13332397
		FILE: Number of bytes written=20590040
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1723
		Map output records=1723
		Map output bytes=662240
		Map output materialized bytes=665828
		Input split bytes=1453
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=665828
		Reduce input records=1723
		Reduce output records=10
		Spilled Records=3446
		Shuffled Maps =9
		Failed Shuffles=0
		Merged Map outputs=9
		GC time elapsed (ms)=164
		Total committed heap usage (bytes)=6194462720
	IndexerStatus
		indexed (add/update)=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=333711
	File Output Format Counters 
		Bytes Written=0
2020-05-03 23:05:41,886 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2020-05-03 23:05:41,899 INFO  indexer.IndexingJob - Indexer:     10  indexed (add/update)
2020-05-03 23:05:41,933 INFO  indexer.IndexingJob - Indexer: finished at 2020-05-03 23:05:41, elapsed: 00:00:03
2020-05-03 23:07:09,642 INFO  crawl.DeduplicationJob - DeduplicationJob: starting at 2020-05-03 23:07:09
2020-05-03 23:07:09,908 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:07:11,260 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:07:11,261 INFO  mapreduce.Job - Running job: job_local2040473025_0001
2020-05-03 23:07:12,272 INFO  mapreduce.Job - Job job_local2040473025_0001 running in uber mode : false
2020-05-03 23:07:12,273 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:07:12,274 INFO  mapreduce.Job - Job job_local2040473025_0001 completed successfully
2020-05-03 23:07:12,293 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1971714
		FILE: Number of bytes written=2997196
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=10
		Map output bytes=2644
		Map output materialized bytes=2680
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=2680
		Reduce input records=10
		Reduce output records=0
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=55906
	File Output Format Counters 
		Bytes Written=98
2020-05-03 23:07:12,301 INFO  crawl.DeduplicationJob - Deduplication: 0 documents marked as duplicates
2020-05-03 23:07:12,301 INFO  crawl.DeduplicationJob - Deduplication: Updating status of duplicate urls into crawl db.
2020-05-03 23:07:12,621 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:07:12,622 INFO  mapreduce.Job - Running job: job_local1440652131_0002
2020-05-03 23:07:13,627 INFO  mapreduce.Job - Job job_local1440652131_0002 running in uber mode : false
2020-05-03 23:07:13,628 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:07:13,628 INFO  mapreduce.Job - Job job_local1440652131_0002 completed successfully
2020-05-03 23:07:13,632 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6018362
		FILE: Number of bytes written=9239217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=662
		Map output bytes=49560
		Map output materialized bytes=50906
		Input split bytes=303
		Combine input records=0
		Combine output records=0
		Reduce input groups=662
		Reduce shuffle bytes=50906
		Reduce input records=662
		Reduce output records=662
		Spilled Records=1324
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1332215808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=56004
	File Output Format Counters 
		Bytes Written=56259
2020-05-03 23:07:13,652 INFO  crawl.DeduplicationJob - Deduplication finished at 2020-05-03 23:07:13, elapsed: 00:00:03
2020-05-03 23:07:14,576 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-03 23:07:14
2020-05-03 23:07:14,890 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:07:16,102 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:07:16,103 INFO  mapreduce.Job - Running job: job_local1463738583_0001
2020-05-03 23:07:16,709 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 23:07:16,734 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 23:07:17,108 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-03 23:07:17,109 INFO  mapreduce.Job - Job job_local1463738583_0001 running in uber mode : false
2020-05-03 23:07:17,111 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:07:18,114 INFO  mapreduce.Job - Job job_local1463738583_0001 completed successfully
2020-05-03 23:07:18,129 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1966366
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=62
		Total committed heap usage (bytes)=475529216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=55906
	File Output Format Counters 
		Bytes Written=0
2020-05-03 23:07:18,146 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-03 23:07:18, elapsed: 00:00:03
2020-05-03 23:07:35,937 INFO  indexer.CleaningJob - CleaningJob: starting at 2020-05-03 23:07:35
2020-05-03 23:07:36,179 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-05-03 23:07:37,446 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2020-05-03 23:07:37,447 INFO  mapreduce.Job - Running job: job_local1341501695_0001
2020-05-03 23:07:38,010 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2020-05-03 23:07:38,043 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2020-05-03 23:07:38,351 INFO  indexer.CleaningJob - CleaningJob: deleted a total of 0 documents
2020-05-03 23:07:38,452 INFO  mapreduce.Job - Job job_local1341501695_0001 running in uber mode : false
2020-05-03 23:07:38,454 INFO  mapreduce.Job -  map 100% reduce 100%
2020-05-03 23:07:38,455 INFO  mapreduce.Job - Job job_local1341501695_0001 completed successfully
2020-05-03 23:07:38,471 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1966366
		FILE: Number of bytes written=2985836
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=662
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=147
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=55
		Total committed heap usage (bytes)=477102080
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=55906
	File Output Format Counters 
		Bytes Written=0
2020-05-03 23:07:38,489 INFO  indexer.CleaningJob - CleaningJob: finished at 2020-05-03 23:07:38, elapsed: 00:00:02
